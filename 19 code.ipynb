{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from mne.filter import resample, filter_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lspopt import spectrogram_lspopt\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "\n",
    "import logging\n",
    "LOGGING_TYPES = dict(DEBUG=logging.DEBUG, INFO=logging.INFO, WARNING=logging.WARNING,\n",
    "                     ERROR=logging.ERROR, CRITICAL=logging.CRITICAL)\n",
    "logger = logging.getLogger('yasa')\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypno</th>\n",
       "      <th>df_feat</th>\n",
       "      <th>eeg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P18_N3 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N3 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P18_N2 R</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N2 R.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P17_N2 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P17_N2 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      hypno  \\\n",
       "name                                                          \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "\n",
       "                       df_feat  \\\n",
       "name                             \n",
       "P18_N3 L  feature/P18_N3 L.csv   \n",
       "P18_N2 R  feature/P18_N2 R.csv   \n",
       "P17_N2 L  feature/P17_N2 L.csv   \n",
       "\n",
       "                                                        eeg  \n",
       "name                                                         \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load reference_df     \n",
    "reference_df = pd.read_csv(\"reference_df.csv\", index_col=\"name\")\n",
    "reference_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>sb</th>\n",
       "      <th>ag</th>\n",
       "      <th>sg</th>\n",
       "      <th>lziv</th>\n",
       "      <th>iqr</th>\n",
       "      <th>bs</th>\n",
       "      <th>ta_b</th>\n",
       "      <th>gs</th>\n",
       "      <th>alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>mean_psd</th>\n",
       "      <th>E</th>\n",
       "      <th>WEn</th>\n",
       "      <th>ds</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>diffEnt</th>\n",
       "      <th>renyi</th>\n",
       "      <th>skew</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_classif</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiSqr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ab   sb   ag   sg  lziv  iqr   bs  ta_b    gs  alpha  ...  \\\n",
       "method_name                                                         ...   \n",
       "f_classif    2.0  1.0  3.0  4.0   6.0  9.0  7.0   5.0  15.0    8.0  ...   \n",
       "chiSqr       1.0  2.0  4.0  8.0   7.0  6.0  9.0  12.0   3.0   10.0  ...   \n",
       "\n",
       "             median  mean_psd     E   WEn    ds  mean_distance  diffEnt  \\\n",
       "method_name                                                               \n",
       "f_classif      61.0      64.0  66.0  62.0  71.0           63.0     67.0   \n",
       "chiSqr         69.0      66.0  65.0  70.0  62.0           71.0     68.0   \n",
       "\n",
       "             renyi  skew  mean  \n",
       "method_name                     \n",
       "f_classif     69.0  72.0  73.0  \n",
       "chiSqr        67.0  72.0  73.0  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv    \n",
    "rankings_df = pd.read_csv(\"rankings_df aug.csv\", index_col=\"method_name\")\n",
    "rankings_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on 60 nights, test of 1 night\n",
    "(1560*60 x 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import kruskal\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>> train recordings (index): \n",
      "[32 42 14 34 13 24 23 47 36  4 48 41 22 37 17 29 10 53  2 43 25  5 19 55\n",
      "  8 16 56 60 52 27 11 46 12 39  7 44 45  3 26 33 51 30 57  1 54  0  6 35\n",
      " 20 58]\n",
      ">>>>>>>> test recordings: \n",
      "[28 40 31 49 15  9 50 38 59 18 21]\n"
     ]
    }
   ],
   "source": [
    "idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "idx_train_recordings = idx_all_recordings[:-11]\n",
    "idx_test_recordings = idx_all_recordings[-11:]\n",
    "print(\">>>>>>>> train recordings (index): \")\n",
    "print(idx_train_recordings)\n",
    "print(\">>>>>>>> test recordings: \")\n",
    "print(idx_test_recordings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset to train and test + shuffle each night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(110073, 50) y=(110073,)\n",
      "Test set: X=(10199, 50) y=(10199,)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(test_prop=0.2, n_feat=40):\n",
    "\n",
    "    idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "    idx_train_recordings = idx_all_recordings[: -int(test_prop * 61)]\n",
    "    idx_test_recordings = idx_all_recordings[-int(test_prop * 61) :]\n",
    "    # print(\">>>>>>>> train recordings (index): \")\n",
    "    # print(idx_train_recordings)\n",
    "    # print(\">>>>>>>> test recordings: \")\n",
    "    # print(idx_test_recordings)\n",
    "\n",
    "    df_feat_X_train = np.array([])\n",
    "    df_feat_X_test = np.array([])\n",
    "    hypno_y_train = np.array([])\n",
    "    hypno_y_test = np.array([])\n",
    "\n",
    "    columns = rankings_df.columns[:n_feat]  # for selecting top n_feat columns\n",
    "\n",
    "    # to loop over all recording files:\n",
    "    for i in idx_train_recordings:\n",
    "        ### to load augmented hypnos for train:\n",
    "        name = reference_df.iloc[i].name\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        ### to load features of augmented eeg for train:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top n_feat ranks columns\n",
    "        df_feat = df_feat[columns]\n",
    "\n",
    "        ### shuffle X\n",
    "        permut = np.random.permutation(df_feat.shape[0])\n",
    "        df_feat = df_feat.iloc[permut]\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_train_recordings[0]:\n",
    "            df_feat_X_train = df_feat.to_numpy()\n",
    "        else:\n",
    "            df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "        ### shuffle y\n",
    "        hypno_30s = hypno_30s[permut]\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "    for i in idx_test_recordings:\n",
    "        ### to load features for test:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        ### to load labels for test:\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top n_feat ranks columns\n",
    "        df_feat = df_feat[columns].to_numpy()\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_test_recordings[0]:\n",
    "            df_feat_X_test = df_feat\n",
    "        else:\n",
    "            df_feat_X_test = np.vstack([df_feat_X_test, df_feat])\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_test = np.append(hypno_y_test, hypno_30s)\n",
    "\n",
    "    print(f\"Train set: X={df_feat_X_train.shape} y={hypno_y_train.shape}\")\n",
    "    print(f\"Test set: X={df_feat_X_test.shape} y={hypno_y_test.shape}\")\n",
    "\n",
    "    ### To standardize all dataset including train and test, after train/test split\n",
    "    # Generate a numpy array including all epochs:\n",
    "    df_feat_all = np.array([])\n",
    "\n",
    "    # # to loop over all recording files:\n",
    "    # for i in range(len(reference_df)):\n",
    "    #     ### to load augmented hypno:\n",
    "    #     name = reference_df.iloc[i].name\n",
    "    #     hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    #     hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    #     hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    #     ### to load features for augmented eeg:\n",
    "    #     df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    #     df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    #     df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    #     df_feat = df_feat.replace(\n",
    "    #         [np.inf, -np.inf], 0\n",
    "    #     )  # Replacing infinite values in features\n",
    "\n",
    "    #     ### select top 25 ranks columns\n",
    "    #     df_feat = df_feat[columns]\n",
    "\n",
    "    #     ### to load features for train: append df_feat to df_feat_X_train\n",
    "    #     if i == 0:\n",
    "    #         df_feat_all = df_feat.to_numpy()\n",
    "    #     else:\n",
    "    #         df_feat_all = np.vstack([df_feat_all, df_feat.to_numpy()])\n",
    "\n",
    "    # print(f\"All: {df_feat_all.shape}\")\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # we will standardize the columns in dataset before we feed them to a classifier\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(df_feat_X_train)  # first fit all the dataset\n",
    "    X_train_std = sc.transform(df_feat_X_train)  # then transform train\n",
    "    X_test_std = sc.transform(df_feat_X_test)  # and test\n",
    "\n",
    "    return X_train_std, X_test_std, hypno_y_train, hypno_y_test\n",
    "\n",
    "\n",
    "X_train_std, X_test_std, y_train, y_test = train_test_split(0.1, n_feat=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified examples: 1952\n",
      "Accuracy: 0.809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", C=10, random_state=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print(\"Misclassified examples: %d\" % (y_test != y_pred).sum())\n",
    "print(\"Accuracy: %.3f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def confmat_f(confmat):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va=\"center\", ha=\"center\")\n",
    "    ax.set(\n",
    "        xticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        xticks=range(5),\n",
    "        yticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        yticks=range(5),\n",
    "    )\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.xaxis.labelpad = 15\n",
    "    ax.xaxis.set_tick_params(labeltop=True)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion Matrix\", y=-0.1)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"confmat.png\")\n",
    "    # plt.savefig(\"confmat.svg\")\n",
    "    plt.show()\n",
    "\n",
    "### Using:\n",
    "# report = classification_report(y_test, y_pred)\n",
    "# print(report)\n",
    "\n",
    "# confmat = confusion_matrix(y_test, y_pred)\n",
    "# confmat_f(confmat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(106994, 5) y=(106994,)\n",
      "Test set: X=(13278, 5) y=(13278,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.69      0.62      1733\n",
      "         1.0       0.45      0.18      0.26      2623\n",
      "         2.0       0.62      0.47      0.53      2861\n",
      "         3.0       0.59      0.75      0.66      2941\n",
      "         4.0       0.59      0.80      0.68      3120\n",
      "\n",
      "    accuracy                           0.58     13278\n",
      "   macro avg       0.56      0.58      0.55     13278\n",
      "weighted avg       0.57      0.58      0.55     13278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108545, 10) y=(108545,)\n",
      "Test set: X=(11727, 10) y=(11727,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.71      0.75      1978\n",
      "         1.0       0.51      0.49      0.50      1954\n",
      "         2.0       0.70      0.70      0.70      2411\n",
      "         3.0       0.85      0.90      0.88      2588\n",
      "         4.0       0.79      0.83      0.81      2796\n",
      "\n",
      "    accuracy                           0.74     11727\n",
      "   macro avg       0.73      0.73      0.73     11727\n",
      "weighted avg       0.74      0.74      0.74     11727\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108298, 15) y=(108298,)\n",
      "Test set: X=(11974, 15) y=(11974,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.75      0.67      1218\n",
      "         1.0       0.58      0.51      0.54      1965\n",
      "         2.0       0.84      0.69      0.76      2814\n",
      "         3.0       0.83      0.90      0.86      2826\n",
      "         4.0       0.82      0.88      0.85      3151\n",
      "\n",
      "    accuracy                           0.77     11974\n",
      "   macro avg       0.74      0.75      0.74     11974\n",
      "weighted avg       0.77      0.77      0.76     11974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(107687, 20) y=(107687,)\n",
      "Test set: X=(12585, 20) y=(12585,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.70      0.73      1890\n",
      "         1.0       0.56      0.39      0.46      2200\n",
      "         2.0       0.74      0.78      0.76      2717\n",
      "         3.0       0.88      0.91      0.89      2856\n",
      "         4.0       0.75      0.89      0.81      2922\n",
      "\n",
      "    accuracy                           0.75     12585\n",
      "   macro avg       0.74      0.73      0.73     12585\n",
      "weighted avg       0.74      0.75      0.75     12585\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108546, 25) y=(108546,)\n",
      "Test set: X=(11726, 25) y=(11726,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71      1684\n",
      "         1.0       0.58      0.55      0.56      1978\n",
      "         2.0       0.77      0.71      0.74      2580\n",
      "         3.0       0.86      0.90      0.88      2714\n",
      "         4.0       0.80      0.90      0.85      2770\n",
      "\n",
      "    accuracy                           0.77     11726\n",
      "   macro avg       0.75      0.75      0.75     11726\n",
      "weighted avg       0.76      0.77      0.76     11726\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(106935, 30) y=(106935,)\n",
      "Test set: X=(13337, 30) y=(13337,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.71      0.72      2019\n",
      "         1.0       0.60      0.44      0.51      2302\n",
      "         2.0       0.72      0.66      0.69      2804\n",
      "         3.0       0.79      0.87      0.83      3020\n",
      "         4.0       0.75      0.89      0.82      3192\n",
      "\n",
      "    accuracy                           0.73     13337\n",
      "   macro avg       0.72      0.72      0.71     13337\n",
      "weighted avg       0.73      0.73      0.73     13337\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108028, 35) y=(108028,)\n",
      "Test set: X=(12244, 35) y=(12244,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.73      0.75      1396\n",
      "         1.0       0.65      0.53      0.59      2322\n",
      "         2.0       0.79      0.76      0.78      2834\n",
      "         3.0       0.89      0.89      0.89      2860\n",
      "         4.0       0.75      0.90      0.82      2832\n",
      "\n",
      "    accuracy                           0.78     12244\n",
      "   macro avg       0.77      0.76      0.76     12244\n",
      "weighted avg       0.77      0.78      0.77     12244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(109030, 40) y=(109030,)\n",
      "Test set: X=(11242, 40) y=(11242,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.58      0.67      1891\n",
      "         1.0       0.59      0.54      0.56      1836\n",
      "         2.0       0.73      0.78      0.76      2371\n",
      "         3.0       0.88      0.84      0.86      2595\n",
      "         4.0       0.70      0.87      0.78      2549\n",
      "\n",
      "    accuracy                           0.74     11242\n",
      "   macro avg       0.74      0.72      0.73     11242\n",
      "weighted avg       0.75      0.74      0.74     11242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(107545, 45) y=(107545,)\n",
      "Test set: X=(12727, 45) y=(12727,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.67      0.73      2025\n",
      "         1.0       0.57      0.51      0.54      2294\n",
      "         2.0       0.72      0.80      0.76      2566\n",
      "         3.0       0.91      0.90      0.90      2860\n",
      "         4.0       0.80      0.89      0.85      2982\n",
      "\n",
      "    accuracy                           0.77     12727\n",
      "   macro avg       0.76      0.75      0.76     12727\n",
      "weighted avg       0.77      0.77      0.77     12727\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108721, 50) y=(108721,)\n",
      "Test set: X=(11551, 50) y=(11551,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.65      0.71      1445\n",
      "         1.0       0.56      0.46      0.50      2066\n",
      "         2.0       0.74      0.76      0.75      2516\n",
      "         3.0       0.89      0.87      0.88      2722\n",
      "         4.0       0.73      0.89      0.80      2802\n",
      "\n",
      "    accuracy                           0.75     11551\n",
      "   macro avg       0.74      0.73      0.73     11551\n",
      "weighted avg       0.75      0.75      0.74     11551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(107545, 55) y=(107545,)\n",
      "Test set: X=(12727, 55) y=(12727,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.74      0.76      1777\n",
      "         1.0       0.66      0.45      0.53      2408\n",
      "         2.0       0.78      0.75      0.76      2787\n",
      "         3.0       0.90      0.92      0.91      2890\n",
      "         4.0       0.71      0.93      0.80      2865\n",
      "\n",
      "    accuracy                           0.77     12727\n",
      "   macro avg       0.77      0.76      0.75     12727\n",
      "weighted avg       0.77      0.77      0.76     12727\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(107708, 60) y=(107708,)\n",
      "Test set: X=(12564, 60) y=(12564,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.73      0.77      2229\n",
      "         1.0       0.61      0.52      0.56      2088\n",
      "         2.0       0.78      0.77      0.77      2603\n",
      "         3.0       0.89      0.94      0.91      2681\n",
      "         4.0       0.78      0.88      0.82      2963\n",
      "\n",
      "    accuracy                           0.78     12564\n",
      "   macro avg       0.77      0.77      0.77     12564\n",
      "weighted avg       0.78      0.78      0.78     12564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108750, 65) y=(108750,)\n",
      "Test set: X=(11522, 65) y=(11522,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.58      0.67      1570\n",
      "         1.0       0.64      0.63      0.63      1796\n",
      "         2.0       0.71      0.79      0.75      2605\n",
      "         3.0       0.89      0.82      0.85      2858\n",
      "         4.0       0.77      0.88      0.82      2693\n",
      "\n",
      "    accuracy                           0.76     11522\n",
      "   macro avg       0.76      0.74      0.74     11522\n",
      "weighted avg       0.77      0.76      0.76     11522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108330, 70) y=(108330,)\n",
      "Test set: X=(11942, 70) y=(11942,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.69      0.73      1973\n",
      "         1.0       0.63      0.60      0.62      2147\n",
      "         2.0       0.76      0.69      0.73      2485\n",
      "         3.0       0.81      0.85      0.83      2577\n",
      "         4.0       0.77      0.88      0.82      2760\n",
      "\n",
      "    accuracy                           0.75     11942\n",
      "   macro avg       0.75      0.74      0.74     11942\n",
      "weighted avg       0.75      0.75      0.75     11942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(106580, 72) y=(106580,)\n",
      "Test set: X=(13692, 72) y=(13692,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.66      0.71      2112\n",
      "         1.0       0.61      0.44      0.51      2533\n",
      "         2.0       0.74      0.78      0.76      2891\n",
      "         3.0       0.88      0.92      0.90      3004\n",
      "         4.0       0.74      0.90      0.81      3152\n",
      "\n",
      "    accuracy                           0.76     13692\n",
      "   macro avg       0.75      0.74      0.74     13692\n",
      "weighted avg       0.75      0.76      0.75     13692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_48572/1141120079.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    }
   ],
   "source": [
    "# This cell took 5 hours to execute \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "n_feat_arr = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 72]\n",
    "accuracy_arr = np.array([])\n",
    "confmat_arr = []\n",
    "report_arr = []\n",
    "\n",
    "for i, n_feat in enumerate(n_feat_arr):\n",
    "    # To split dataset into train/test set:\n",
    "    X_train_std, X_test_std, y_train, y_test = train_test_split(test_prop=0.1, n_feat=n_feat)\n",
    "    # To initiate model\n",
    "    svm = SVC(kernel=\"rbf\", C=10, random_state=1)\n",
    "    # To fit the model to train set:\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    # To predit on the test set:\n",
    "    y_pred = svm.predict(X_test_std)\n",
    "    # To print results\n",
    "    print\n",
    "    (\n",
    "        f\"Fold {i}, {n_feat} features => Misclassified: {(y_test != y_pred).sum()}, Acc.: {accuracy_score(y_test, y_pred)}\"\n",
    "    )\n",
    "    # To append accuracy to array\n",
    "    accuracy_arr = np.append(accuracy_arr, accuracy_score(y_test, y_pred))\n",
    "    # to save report and confmat\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    confmat = confusion_matrix(y_test, y_pred)\n",
    "    report_arr.append(report)\n",
    "    confmat_arr.append(confmat)\n",
    "    print(report)\n",
    "    confmat_f(confmat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a file \n",
    "# textfile = open(\"report_arr hyperparam feat_num.txt\", \"w\")\n",
    "# for element in report_arr:\n",
    "#     textfile.write(element + \",\\n\")\n",
    "# textfile.close()\n",
    "\n",
    "# load results from that file\n",
    "f = open(\"report_arr hyperparam feat_num.txt\")\n",
    "p = ('').join(f.readlines()).split(',\\n')[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a file \n",
    "# np.savetxt(\n",
    "#     \"confmat_arr hyperparam feat_num.csv\",\n",
    "#     np.array(confmat_arr).reshape((3, -1)),\n",
    "#     delimiter=\",\",\n",
    "# )\n",
    "\n",
    "# load results from that file\n",
    "p = np.loadtxt(\"confmat_arr hyperparam feat_num.csv\", delimiter=',')\n",
    "p = p.reshape(15,5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_i: [precision  recall   f1-score   support]\n",
    "x = report_arr[0].split('0.0')[1].split(\"\\n\")[0].split(\"   \")\n",
    "class_0 = np.array([i.strip() for i in list(filter(None, x))])\n",
    "for j in range(1,15):\n",
    "    x = report_arr[j].split('0.0')[1].split(\"\\n\")[0].split(\"   \")\n",
    "    class_0 = np.vstack([class_0,np.array([i.strip() for i in list(filter(None, x))])])\n",
    "class_0 = class_0.astype('float')\n",
    "class_0 = class_0*100\n",
    "\n",
    "x = report_arr[0].split('0.0')[1].split(\"\\n\")[1].split(\"   \")\n",
    "class_1 = np.array([i.strip() for i in list(filter(None, x))])\n",
    "for j in range(1,15):\n",
    "    x = report_arr[j].split('0.0')[1].split(\"\\n\")[1].split(\"   \")\n",
    "    class_1 = np.vstack([class_1,np.array([i.strip() for i in list(filter(None, x))])])\n",
    "class_1 = class_1[:,1:]\n",
    "class_1 = class_1.astype('float')\n",
    "class_1 = class_1*100\n",
    "\n",
    "x = report_arr[0].split('0.0')[1].split(\"\\n\")[2].split(\"   \")\n",
    "class_2 = np.array([i.strip() for i in list(filter(None, x))])\n",
    "for j in range(1,15):\n",
    "    x = report_arr[j].split('0.0')[1].split(\"\\n\")[2].split(\"   \")\n",
    "    class_2 = np.vstack([class_2,np.array([i.strip() for i in list(filter(None, x))])])\n",
    "class_2 = class_2[:,1:]\n",
    "class_2 = class_2.astype('float')\n",
    "class_2 = class_2*100\n",
    "\n",
    "x = report_arr[0].split('0.0')[1].split(\"\\n\")[3].split(\"   \")\n",
    "class_3 = np.array([i.strip() for i in list(filter(None, x))])\n",
    "for j in range(1,15):\n",
    "    x = report_arr[j].split('0.0')[1].split(\"\\n\")[3].split(\"   \")\n",
    "    class_3 = np.vstack([class_3,np.array([i.strip() for i in list(filter(None, x))])])\n",
    "class_3 = class_3[:,1:]\n",
    "class_3 = class_3.astype('float')\n",
    "class_3 = class_3*100\n",
    "\n",
    "x = report_arr[0].split('0.0')[1].split(\"\\n\")[4].split(\"   \")\n",
    "class_4 = np.array([i.strip() for i in list(filter(None, x))])\n",
    "for j in range(1,15):\n",
    "    x = report_arr[j].split('0.0')[1].split(\"\\n\")[4].split(\"   \")\n",
    "    class_4 = np.vstack([class_4,np.array([i.strip() for i in list(filter(None, x))])])\n",
    "class_4 = class_4[:,1:]\n",
    "class_4 = class_4.astype('float')\n",
    "class_4 = class_4*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1,figsize=(10, 5), sharex=True)\n",
    "ylabel = [\"Precision\",\"Recall\",\"F1-score\"]\n",
    "for i in range(3):\n",
    "    ax[i].plot(n_feat_arr,class_0[:,i], label=\"Wake\", color=\"tomato\")\n",
    "    ax[i].plot(n_feat_arr,class_0[:,i],'o', color=\"red\")\n",
    "    ax[i].plot(n_feat_arr,class_1[:,i], label=\"N1\", color=\"gold\")\n",
    "    ax[i].plot(n_feat_arr,class_1[:,i],'o', color=\"goldenrod\")\n",
    "    ax[i].plot(n_feat_arr,class_2[:,i], label=\"N2\", color=\"limegreen\")\n",
    "    ax[i].plot(n_feat_arr,class_2[:,i],'o', color=\"olivedrab\")\n",
    "    ax[i].plot(n_feat_arr,class_3[:,i], label=\"N3\", color=\"dodgerblue\")\n",
    "    ax[i].plot(n_feat_arr,class_3[:,i],'o', color=\"royalblue\")\n",
    "    ax[i].plot(n_feat_arr,class_4[:,i], label=\"REM\", color=\"mediumslateblue\")\n",
    "    ax[i].plot(n_feat_arr,class_4[:,i],'o', color=\"darkviolet\")\n",
    "    ax[i].set(ylim=[25,100 ], xticks=n_feat_arr)\n",
    "    ax[i].grid(alpha=0.4)\n",
    "    ax[i].set(ylabel=ylabel[i])\n",
    "plt.xlabel('Number of top features')\n",
    "ax[1].legend()\n",
    "# ax[1].legend(loc=(1.01,0.05))\n",
    "ax[0].set(title=\"SVM RBF C=10 performance metrics with different number of features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('svm performace metrics plot.png')\n",
    "plt.savefig('svm performace metrics plot.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29925ef40>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108244, 40) y=(108244,)\n",
      "Test set: X=(12028, 40) y=(12028,)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(test_prop=0.2):\n",
    "\n",
    "    idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "    idx_train_recordings = idx_all_recordings[: -int(test_prop * 61)]\n",
    "    idx_test_recordings = idx_all_recordings[-int(test_prop * 61) :]\n",
    "    # print(\">>>>>>>> train recordings (index): \")\n",
    "    # print(idx_train_recordings)\n",
    "    # print(\">>>>>>>> test recordings: \")\n",
    "    # print(idx_test_recordings)\n",
    "\n",
    "    df_feat_X_train = np.array([])\n",
    "    df_feat_X_test = np.array([])\n",
    "    hypno_y_train = np.array([])\n",
    "    hypno_y_test = np.array([])\n",
    "\n",
    "    columns = rankings_df.columns[:40]  # for selecting top columns\n",
    "\n",
    "    # to loop over all recording files:\n",
    "    for i in idx_train_recordings:\n",
    "        ### to load augmented hypnos for train:\n",
    "        name = reference_df.iloc[i].name\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        ### to load features of augmented eeg for train:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top 25 ranks columns\n",
    "        df_feat = df_feat[columns]\n",
    "\n",
    "        ### shuffle X\n",
    "        permut = np.random.permutation(df_feat.shape[0])\n",
    "        df_feat = df_feat.iloc[permut]\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_train_recordings[0]:\n",
    "            df_feat_X_train = df_feat.to_numpy()\n",
    "        else:\n",
    "            df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "        ### shuffle y\n",
    "        hypno_30s = hypno_30s[permut]\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "    for i in idx_test_recordings:\n",
    "        ### to load features for test:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        ### to load labels for test:\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top 25 ranks columns\n",
    "        df_feat = df_feat[columns].to_numpy()\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_test_recordings[0]:\n",
    "            df_feat_X_test = df_feat\n",
    "        else:\n",
    "            df_feat_X_test = np.vstack([df_feat_X_test, df_feat])\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_test = np.append(hypno_y_test, hypno_30s)\n",
    "\n",
    "    print(f\"Train set: X={df_feat_X_train.shape} y={hypno_y_train.shape}\")\n",
    "    print(f\"Test set: X={df_feat_X_test.shape} y={hypno_y_test.shape}\")\n",
    "\n",
    "    return df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test\n",
    "\n",
    "df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test = train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 100.0)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(n_feat_arr)):\n",
    "    # print(feat_n)\n",
    "    ax.plot(i, int(confmat_arr[i][0, 0] / np.sum(confmat_arr[i][:, 0]) * 100), 'o', color='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune C parameter with learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", C=10))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10).split(df_feat_X_train, hypno_y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(df_feat_X_train[train], hypno_y_train[train])\n",
    "    score = pipe_lr.score(df_feat_X_train[test], hypno_y_train[test])\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\n",
    "        f\"Fold: {k+1:02d}, \"\n",
    "        f\"Class distr.: {np.bincount(hypno_y_train[train].astype(int))}, \"\n",
    "        f\"Acc.: {score:.3f}\"\n",
    "    )\n",
    "\n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f\"\\nCV accuracy: {mean_acc:.3f} +/- {std_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(scores, c=\"darkturquoise\")\n",
    "plt.plot(range(len(scores)), scores, \"s\", c=\"darkslategrey\")\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([-0.5, len(scores) - 0.5])\n",
    "plt.grid()\n",
    "plt.title(f\"Stratified 10-fold CV to estimate accuracy: {mean_acc:.3f} +/- {std_acc:.3f} \")\n",
    "plt.xticks(range(len(scores)))\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"10-fold CV C2.svg\")\n",
    "# plt.savefig(\"10-fold CV C2.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_arr = np.array([])\n",
    "acc_test_arr = np.array([])\n",
    "\n",
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "for i in range(len(param_range)):\n",
    "    # train/test datasets\n",
    "    df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test = train_test_split()\n",
    "\n",
    "    # standardize the columns\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(df_feat_all)  # first fit all the dataset\n",
    "    X_train_std = sc.transform(df_feat_X_train)  # then transform train\n",
    "    X_test_std = sc.transform(df_feat_X_test)  # and test\n",
    "\n",
    "    # train the classifier\n",
    "    svm = SVC(kernel=\"rbf\", C=param_range[i])\n",
    "    svm.fit(X_train_std, hypno_y_train)\n",
    "    y_pred = svm.predict(X_test_std)\n",
    "    print(\"Misclassified examples: %d\" % (hypno_y_test != y_pred).sum())\n",
    "    print(\"Accuracy: %.3f\" % accuracy_score(hypno_y_test, y_pred))\n",
    "    acc_train = accuracy_score(hypno_y_test, y_pred)\n",
    "\n",
    "    acc_train_arr = np.append(acc_train_arr, acc_train)\n",
    "\n",
    "    print(f\"Gridsearch {i}: C= {param_range[i]}, Acc.: {np.round(acc_train,3):03d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(param_range, acc_train_arr, \"--\", color=\"yellowgreen\", linewidth=2)\n",
    "plt.plot(param_range, acc_train_arr, \"s\", color=\"darkolivegreen\")\n",
    "plt.grid()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Parameter C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Tuning C hyperparameter, C=10 is optimum\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('hyperparam C.svg')\n",
    "# plt.savefig('hyperparam C.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_arr = acc_train_arr[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9461a3eb0cbef873800a78c94f0b6f375dc71a03d464463d7b611af82b6cd16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
