{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Implementation (code 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from mne.filter import resample, filter_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lspopt import spectrogram_lspopt\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "\n",
    "import logging\n",
    "LOGGING_TYPES = dict(DEBUG=logging.DEBUG, INFO=logging.INFO, WARNING=logging.WARNING,\n",
    "                     ERROR=logging.ERROR, CRITICAL=logging.CRITICAL)\n",
    "logger = logging.getLogger('yasa')\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypno</th>\n",
       "      <th>df_feat</th>\n",
       "      <th>eeg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P18_N3 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N3 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P18_N2 R</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N2 R.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P17_N2 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P17_N2 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      hypno  \\\n",
       "name                                                          \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "\n",
       "                       df_feat  \\\n",
       "name                             \n",
       "P18_N3 L  feature/P18_N3 L.csv   \n",
       "P18_N2 R  feature/P18_N2 R.csv   \n",
       "P17_N2 L  feature/P17_N2 L.csv   \n",
       "\n",
       "                                                        eeg  \n",
       "name                                                         \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load reference_df     \n",
    "reference_df = pd.read_csv(\"reference_df.csv\", index_col=\"name\")\n",
    "reference_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>sb</th>\n",
       "      <th>ag</th>\n",
       "      <th>sg</th>\n",
       "      <th>lziv</th>\n",
       "      <th>iqr</th>\n",
       "      <th>bs</th>\n",
       "      <th>ta_b</th>\n",
       "      <th>gs</th>\n",
       "      <th>alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>mean_psd</th>\n",
       "      <th>E</th>\n",
       "      <th>WEn</th>\n",
       "      <th>ds</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>diffEnt</th>\n",
       "      <th>renyi</th>\n",
       "      <th>skew</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_classif</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiSqr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ab   sb   ag   sg  lziv  iqr   bs  ta_b    gs  alpha  ...  \\\n",
       "method_name                                                         ...   \n",
       "f_classif    2.0  1.0  3.0  4.0   6.0  9.0  7.0   5.0  15.0    8.0  ...   \n",
       "chiSqr       1.0  2.0  4.0  8.0   7.0  6.0  9.0  12.0   3.0   10.0  ...   \n",
       "\n",
       "             median  mean_psd     E   WEn    ds  mean_distance  diffEnt  \\\n",
       "method_name                                                               \n",
       "f_classif      61.0      64.0  66.0  62.0  71.0           63.0     67.0   \n",
       "chiSqr         69.0      66.0  65.0  70.0  62.0           71.0     68.0   \n",
       "\n",
       "             renyi  skew  mean  \n",
       "method_name                     \n",
       "f_classif     69.0  72.0  73.0  \n",
       "chiSqr        67.0  72.0  73.0  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv    \n",
    "rankings_df = pd.read_csv(\"rankings_df aug.csv\", index_col=\"method_name\")\n",
    "rankings_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sleep stage distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to see id's\n",
    "idx = reference_df.index.to_list()\n",
    "\n",
    "epochs_count = 0\n",
    "hypno_30s_all = np.array([])\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in range(0, len(reference_df)):\n",
    "    # To load information of each night:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "    # to append current hypno to array of all hypnos - to plotting histogram later:\n",
    "    hypno_30s_all = np.append(hypno_30s_all, hypno_30s)\n",
    "    # count the number of epochs\n",
    "    epochs_count += len(hypno_30s)\n",
    "\n",
    "print(f\"{epochs_count} epochs available across {len(idx)} recordings.\")\n",
    "\n",
    "# plotting histogram of classes in all hypnos:\n",
    "stages, counts = np.unique(hypno_30s_all, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.bar(stages, counts, color=\"blueviolet\")\n",
    "ax.set(xticks=np.arange(0, 4 + 1, 1), xticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"])\n",
    "ax.tick_params(axis=\"x\", labelsize=13, labelrotation=20, labelcolor=\"green\", width=3)\n",
    "ax.tick_params(axis=\"y\", labelsize=13, labelrotation=20, labelcolor=\"orangered\")\n",
    "plt.xlabel(\"Sleep stage\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(f\"Sleep stages for {epochs_count} epochs across {len(idx)} recordings\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"stage_distribution_count aug.svg\")\n",
    "# plt.savefig(\"stage_distribution_count aug.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import kruskal\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on 60 nights, test of 1 night\n",
    "(1560*60 x 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>> train recordings (index): \n",
      "[28 53 26 41 54 46 47 43  6 36 25 18 19 31 44 16  1 30 39 49 45  5 24 59\n",
      " 40 35 32 23 34 12 17 33 10 57  4  7  3  2 38  0 37 52 20 60 42 15 58 21\n",
      " 51 29]\n",
      ">>>>>>>> test recordings: \n",
      "[22 56 11 50 48 14 27  8 55  9 13]\n"
     ]
    }
   ],
   "source": [
    "idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "idx_train_recordings = idx_all_recordings[:-11]\n",
    "idx_test_recordings = idx_all_recordings[-11:]\n",
    "print(\">>>>>>>> train recordings (index): \")\n",
    "print(idx_train_recordings)\n",
    "print(\">>>>>>>> test recordings: \")\n",
    "print(idx_test_recordings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset to train and test + shuffle each night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_X_train = np.array([])\n",
    "df_feat_X_test = np.array([])\n",
    "hypno_y_train = np.array([])\n",
    "hypno_y_test = np.array([])\n",
    "\n",
    "# columns = rankings_df.columns[:40]  # for selecting top columns\n",
    "# read top features from file\n",
    "with open('top_features_correlation_90.txt', 'r') as f:\n",
    "    columns = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in idx_train_recordings:\n",
    "    ### to load augmented hypnos for train:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    ### to load features of augmented eeg for train:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns]\n",
    "\n",
    "    ### shuffle X\n",
    "    permut = np.random.permutation(df_feat.shape[0])\n",
    "    df_feat = df_feat.iloc[permut]\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == idx_train_recordings[0]:\n",
    "        df_feat_X_train = df_feat.to_numpy()\n",
    "    else:\n",
    "        df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "    ### shuffle y\n",
    "    hypno_30s = hypno_30s[permut]\n",
    "\n",
    "    ### to load labels for train: append hypno to hypno_y_train\n",
    "    hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "\n",
    "for i in idx_test_recordings:\n",
    "    ### to load features for test:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    ### to load labels for test:\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns].to_numpy()\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == idx_test_recordings[0]:\n",
    "        df_feat_X_test = df_feat\n",
    "    else:\n",
    "        df_feat_X_test = np.vstack([df_feat_X_test, df_feat])\n",
    "\n",
    "    ### to load labels for train: append hypno to hypno_y_train\n",
    "    hypno_y_test = np.append(hypno_y_test, hypno_30s)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Train set: X={df_feat_X_train.shape} y={hypno_y_train.shape}\"\n",
    ")\n",
    "print(f\"Test set: X={df_feat_X_test.shape} y={hypno_y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a numpy array including all epochs \n",
    "\n",
    "To standardize all dataset including train and test, after train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_all = np.array([])\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in range(len(reference_df)):\n",
    "    ### to load augmented hypno:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    ### to load features for augmented eeg:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns]\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == 0:\n",
    "        df_feat_all = df_feat.to_numpy()\n",
    "    else:\n",
    "        df_feat_all = np.vstack([df_feat_all, df_feat.to_numpy()])\n",
    "\n",
    "print(df_feat_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# we will standardize the columns in dataset before we feed them to a classifier\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(df_feat_all) # first fit all the dataset\n",
    "# X_train_std = sc.transform(df_feat_X_train) # then transform train \n",
    "# X_test_std = sc.transform(df_feat_X_test) # and test\n",
    "\n",
    "# svm = SVC(kernel=\"rbf\")\n",
    "# svm.fit(X_train_std, hypno_y_train)\n",
    "# y_pred = svm.predict(X_test_std)\n",
    "# print(\"Misclassified examples: %d\" % (hypno_y_test != y_pred).sum())\n",
    "# print(\"Accuracy: %.3f\" % accuracy_score(hypno_y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate classification metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confmat_f(confmat):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va=\"center\", ha=\"center\")\n",
    "    ax.set(\n",
    "        xticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        xticks=range(5),\n",
    "        yticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        yticks=range(5),\n",
    "    )\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.xaxis.labelpad = 15\n",
    "    ax.xaxis.set_tick_params(labeltop=True)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion Matrix\", y=-0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confmat.png\")\n",
    "    plt.savefig(\"confmat.svg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "report = classification_report(hypno_y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "confmat = confusion_matrix(hypno_y_test, y_pred)\n",
    "confmat_f(confmat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune C parameter with learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(109128, 46) y=(109128,)\n",
      "Test set: X=(11144, 46) y=(11144,)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(test_prop=0.2):\n",
    "\n",
    "    idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "    idx_train_recordings = idx_all_recordings[: -int(test_prop * 61)]\n",
    "    idx_test_recordings = idx_all_recordings[-int(test_prop * 61) :]\n",
    "    # print(\">>>>>>>> train recordings (index): \")\n",
    "    # print(idx_train_recordings)\n",
    "    # print(\">>>>>>>> test recordings: \")\n",
    "    # print(idx_test_recordings)\n",
    "\n",
    "    df_feat_X_train = np.array([])\n",
    "    df_feat_X_test = np.array([])\n",
    "    hypno_y_train = np.array([])\n",
    "    hypno_y_test = np.array([])\n",
    "\n",
    "    # columns = rankings_df.columns[:40]  # for selecting top columns\n",
    "    # read top features from file\n",
    "    with open('top_features_correlation_90.txt', 'r') as f:\n",
    "        columns = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    # to loop over all recording files:\n",
    "    for i in idx_train_recordings:\n",
    "        ### to load augmented hypnos for train:\n",
    "        name = reference_df.iloc[i].name\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        ### to load features of augmented eeg for train:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top 25 ranks columns\n",
    "        df_feat = df_feat[columns]\n",
    "\n",
    "        ### shuffle X\n",
    "        permut = np.random.permutation(df_feat.shape[0])\n",
    "        df_feat = df_feat.iloc[permut]\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_train_recordings[0]:\n",
    "            df_feat_X_train = df_feat.to_numpy()\n",
    "        else:\n",
    "            df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "        ### shuffle y\n",
    "        hypno_30s = hypno_30s[permut]\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "    for i in idx_test_recordings:\n",
    "        ### to load features for test:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        ### to load labels for test:\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top 25 ranks columns\n",
    "        df_feat = df_feat[columns].to_numpy()\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_test_recordings[0]:\n",
    "            df_feat_X_test = df_feat\n",
    "        else:\n",
    "            df_feat_X_test = np.vstack([df_feat_X_test, df_feat])\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_test = np.append(hypno_y_test, hypno_30s)\n",
    "\n",
    "    print(f\"Train set: X={df_feat_X_train.shape} y={hypno_y_train.shape}\")\n",
    "    print(f\"Test set: X={df_feat_X_test.shape} y={hypno_y_test.shape}\")\n",
    "\n",
    "    return df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test\n",
    "\n",
    "df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test = train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", C=10))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10).split(df_feat_X_train, hypno_y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(df_feat_X_train[train], hypno_y_train[train])\n",
    "    score = pipe_lr.score(df_feat_X_train[test], hypno_y_train[test])\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\n",
    "        f\"Fold: {k+1:02d}, \"\n",
    "        f\"Class distr.: {np.bincount(hypno_y_train[train].astype(int))}, \"\n",
    "        f\"Acc.: {score:.3f}\"\n",
    "    )\n",
    "\n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f\"\\nCV accuracy: {mean_acc:.3f} +/- {std_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(scores, c=\"darkturquoise\")\n",
    "plt.plot(range(len(scores)), scores, \"s\", c=\"darkslategrey\")\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([-0.5, len(scores) - 0.5])\n",
    "plt.grid()\n",
    "plt.title(f\"Stratified 10-fold CV to estimate accuracy: {mean_acc:.3f} +/- {std_acc:.3f} \")\n",
    "plt.xticks(range(len(scores)))\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"10-fold CV C2.svg\")\n",
    "# plt.savefig(\"10-fold CV C2.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_arr = np.array([])\n",
    "acc_test_arr = np.array([])\n",
    "\n",
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "for i in range(len(param_range)):\n",
    "    # train/test datasets\n",
    "    df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test = train_test_split()\n",
    "\n",
    "    # standardize the columns\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(df_feat_all)  # first fit all the dataset\n",
    "    X_train_std = sc.transform(df_feat_X_train)  # then transform train\n",
    "    X_test_std = sc.transform(df_feat_X_test)  # and test\n",
    "\n",
    "    # train the classifier\n",
    "    svm = SVC(kernel=\"rbf\", C=param_range[i])\n",
    "    svm.fit(X_train_std, hypno_y_train)\n",
    "    y_pred = svm.predict(X_test_std)\n",
    "    print(\"Misclassified examples: %d\" % (hypno_y_test != y_pred).sum())\n",
    "    print(\"Accuracy: %.3f\" % accuracy_score(hypno_y_test, y_pred))\n",
    "    acc_train = accuracy_score(hypno_y_test, y_pred)\n",
    "\n",
    "    acc_train_arr = np.append(acc_train_arr, acc_train)\n",
    "\n",
    "    print(f\"Gridsearch {i}: C= {param_range[i]}, Acc.: {np.round(acc_train,3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(param_range, acc_train_arr, \"--\", color=\"yellowgreen\", linewidth=2)\n",
    "plt.plot(param_range, acc_train_arr, \"s\", color=\"darkolivegreen\")\n",
    "plt.grid()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Parameter C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Tuning C hyperparameter, C=10 is optimum\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('hyperparam C.svg')\n",
    "# plt.savefig('hyperparam C.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_arr = acc_train_arr[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9461a3eb0cbef873800a78c94f0b6f375dc71a03d464463d7b611af82b6cd16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
