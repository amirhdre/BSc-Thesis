{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from mne.filter import resample, filter_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lspopt import spectrogram_lspopt\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "\n",
    "import logging\n",
    "LOGGING_TYPES = dict(DEBUG=logging.DEBUG, INFO=logging.INFO, WARNING=logging.WARNING,\n",
    "                     ERROR=logging.ERROR, CRITICAL=logging.CRITICAL)\n",
    "logger = logging.getLogger('yasa')\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypno</th>\n",
       "      <th>df_feat</th>\n",
       "      <th>eeg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P18_N3 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N3 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P18_N2 R</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N2 R.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P17_N2 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P17_N2 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      hypno  \\\n",
       "name                                                          \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "\n",
       "                       df_feat  \\\n",
       "name                             \n",
       "P18_N3 L  feature/P18_N3 L.csv   \n",
       "P18_N2 R  feature/P18_N2 R.csv   \n",
       "P17_N2 L  feature/P17_N2 L.csv   \n",
       "\n",
       "                                                        eeg  \n",
       "name                                                         \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load reference_df     \n",
    "reference_df = pd.read_csv(\"reference_df.csv\", index_col=\"name\")\n",
    "reference_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iqr</th>\n",
       "      <th>ab</th>\n",
       "      <th>ag</th>\n",
       "      <th>sb</th>\n",
       "      <th>sg</th>\n",
       "      <th>bs</th>\n",
       "      <th>ta_b</th>\n",
       "      <th>gs</th>\n",
       "      <th>ga</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>ts</th>\n",
       "      <th>da</th>\n",
       "      <th>dfa</th>\n",
       "      <th>std_psd</th>\n",
       "      <th>ds</th>\n",
       "      <th>dt</th>\n",
       "      <th>katz</th>\n",
       "      <th>mean_psd</th>\n",
       "      <th>mean_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_classif</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiSqr</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             iqr    ab    ag    sb    sg    bs  ta_b    gs    ga   std  ...  \\\n",
       "method_name                                                             ...   \n",
       "f_classif    9.0   2.0   3.0   1.0   4.0   7.0   5.0  15.0  26.0  39.0  ...   \n",
       "MI           1.0  19.0  18.0  22.0  27.0  24.0  23.0  28.0  17.0   2.0  ...   \n",
       "chiSqr       6.0   1.0   4.0   2.0   8.0   9.0  12.0   3.0   5.0  13.0  ...   \n",
       "\n",
       "             mean    ts    da   dfa  std_psd    ds    dt  katz  mean_psd  \\\n",
       "method_name                                                                \n",
       "f_classif    73.0  54.0  68.0  45.0     60.0  71.0  65.0  56.0      64.0   \n",
       "MI           14.0  52.0  47.0  70.0     65.0  50.0  63.0  72.0      68.0   \n",
       "chiSqr       73.0  61.0  58.0  60.0     54.0  62.0  63.0  64.0      66.0   \n",
       "\n",
       "             mean_distance  \n",
       "method_name                 \n",
       "f_classif             63.0  \n",
       "MI                    73.0  \n",
       "chiSqr                71.0  \n",
       "\n",
       "[3 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv    \n",
    "rankings_df = pd.read_csv(\"rankings_df aug.csv\", index_col=\"method_name\")\n",
    "rankings_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120272 epochs available across 61 recordings.\n"
     ]
    }
   ],
   "source": [
    "### to see id's\n",
    "idx = reference_df.index.to_list()\n",
    "\n",
    "epochs_count = 0\n",
    "hypno_30s_all = np.array([])\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in range(0, len(reference_df)):\n",
    "    # To load information of each night:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "    # to append current hypno to array of all hypnos - to plotting histogram later:\n",
    "    hypno_30s_all = np.append(hypno_30s_all, hypno_30s)\n",
    "    # count the number of epochs\n",
    "    epochs_count += len(hypno_30s)\n",
    "\n",
    "print(f\"{epochs_count} epochs available across {len(idx)} recordings.\")\n",
    "\n",
    "# plotting histogram of classes in all hypnos:\n",
    "stages, counts = np.unique(hypno_30s_all, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.bar(stages, counts, color=\"blueviolet\")\n",
    "ax.set(xticks=np.arange(0, 4 + 1, 1), xticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"])\n",
    "ax.tick_params(axis=\"x\", labelsize=13, labelrotation=20, labelcolor=\"green\", width=3)\n",
    "ax.tick_params(axis=\"y\", labelsize=13, labelrotation=20, labelcolor=\"orangered\")\n",
    "plt.xlabel(\"Sleep stage\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(f\"Sleep stages for {epochs_count} epochs across {len(idx)} recordings\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"stage_distribution_count aug.svg\")\n",
    "plt.savefig(\"stage_distribution_count aug.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to load augmented hypno:\n",
    "name = reference_df.iloc[0].name\n",
    "hypno_30s_loc = reference_df.iloc[0].hypno\n",
    "hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "### to load features for augmented eeg:\n",
    "df_feat_loc = reference_df.iloc[0].df_feat\n",
    "df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "### to load augmented eeg:\n",
    "eeg_loc = reference_df.iloc[0].eeg\n",
    "eeg_loc = eeg_loc.split(\".\")[0] + \" aug.txt\"\n",
    "data = np.loadtxt(eeg_loc, delimiter=\",\")  # took ~7 seconds # this is filtered data actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import kruskal\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on 60 nights, test of 1 night\n",
    "(1560*60 x 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train recordings (index): \n",
      "[ 3 26 11 16 35 19 44 28  0 37 17 43 33 60 46 39  2 25 34 51 22 48 24  8\n",
      " 57 38 53 54 41 30 29 55 36 56 40 58 50  5 20 14 10 45  7 52 18  1 42  6\n",
      " 12 49 15 32 23 21  9 47 31 13 59  4]\n",
      "test recordings: \n",
      "27\n"
     ]
    }
   ],
   "source": [
    "idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "idx_train_recordings = idx_all_recordings[0:-1]\n",
    "idx_test_recordings = idx_all_recordings[-1]\n",
    "print(\"train recordings (index): \")\n",
    "print(idx_train_recordings)\n",
    "print(\"test recordings: \")\n",
    "print(idx_test_recordings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(118258, 40) y=((118258, 40), (118258,))\n",
      "Test set: (2014, 40) y=((2014, 40), (2014,))\n"
     ]
    }
   ],
   "source": [
    "df_feat_X_train = np.array([])\n",
    "df_feat_X_test = np.array([])\n",
    "hypno_y_train = np.array([])\n",
    "hypno_y_test = np.array([])\n",
    "\n",
    "columns = rankings_df.columns[:40]  # for selecting top columns\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in idx_train_recordings:\n",
    "    ### to load augmented hypno:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    ### to load features for augmented eeg:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns]\n",
    "\n",
    "    ### shuffle X\n",
    "    permut = np.random.permutation(df_feat.shape[0])\n",
    "    df_feat = df_feat.iloc[permut]\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == idx_train_recordings[0]:\n",
    "        df_feat_X_train = df_feat.to_numpy()\n",
    "    else:\n",
    "        df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "    ### shuffle y\n",
    "    hypno_30s = hypno_30s[permut]\n",
    "\n",
    "    ### to load labels for train: append hypno to hypno_y_train\n",
    "    hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "\n",
    "### to load features for test:\n",
    "df_feat_loc = reference_df.iloc[idx_test_recordings].df_feat\n",
    "df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "df_feat_X_test = df_feat[columns].to_numpy()\n",
    "\n",
    "### to load labels for test:\n",
    "hypno_30s_loc = reference_df.iloc[idx_test_recordings].hypno\n",
    "hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "hypno_y_test = hypno_30s\n",
    "\n",
    "print(\n",
    "    f\"Train set: X={df_feat_X_train.shape} y={df_feat_X_train.shape, hypno_y_train.shape}\"\n",
    ")\n",
    "print(f\"Test set: {df_feat_X_test.shape} y={df_feat_X_test.shape, hypno_y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120272, 40)\n"
     ]
    }
   ],
   "source": [
    "df_feat_all = np.array([])\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in range(len(reference_df)):\n",
    "    ### to load augmented hypno:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    ### to load features for augmented eeg:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns]\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == 0:\n",
    "        df_feat_all = df_feat.to_numpy()\n",
    "    else:\n",
    "        df_feat_all = np.vstack([df_feat_all, df_feat.to_numpy()])\n",
    "\n",
    "print(df_feat_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# we will standardize the columns in dataset before we feed them to a classifier\n",
    "sc = StandardScaler()\n",
    "sc.fit(df_feat_all)\n",
    "X_train_std = sc.transform(df_feat_X_train)\n",
    "X_test_std = sc.transform(df_feat_X_test)\n",
    "\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "svm.fit(X_train_std, hypno_y_train)\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print(\"Misclassified examples: %d\" % (hypno_y_test != y_pred).sum())\n",
    "print(\"Accuracy: %.3f\" % accuracy_score(hypno_y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(hypno_y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_TP(y_true, y_pred):\n",
    "    # counts the number of true positives (y_true = 1, y_pred = 1)\n",
    "    return sum((y_true == 1) & (y_pred == 1))\n",
    "\n",
    "\n",
    "def find_FN(y_true, y_pred):\n",
    "    # counts the number of false negatives (y_true = 1, y_pred = 0)\n",
    "    return  # your code here\n",
    "\n",
    "\n",
    "def find_FP(y_true, y_pred):\n",
    "    # counts the number of false positives (y_true = 0, y_pred = 1)\n",
    "    return  # your code here\n",
    "\n",
    "\n",
    "def find_TN(y_true, y_pred):\n",
    "    # counts the number of true negatives (y_true = 0, y_pred = 0)\n",
    "    return  # your code here\n",
    "\n",
    "\n",
    "print(\"TP:\", find_TP((hypno_y_test, y_pred)))\n",
    "print(\"FN:\", find_FN((hypno_y_test, y_pred)))\n",
    "print(\"FP:\", find_FP((hypno_y_test, y_pred)))\n",
    "print(\"TN:\", find_TN((hypno_y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(118258, 40) y=((118258, 40), (118258,))\n",
      "Test set: (2014, 40) y=((2014, 40), (2014,))\n"
     ]
    }
   ],
   "source": [
    "df_feat_X_train = np.array([])\n",
    "df_feat_X_test = np.array([])\n",
    "hypno_y_train = np.array([])\n",
    "hypno_y_test = np.array([])\n",
    "\n",
    "columns = rankings_df.columns[:40]  # for selecting top columns\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in idx_train_recordings:\n",
    "    ### to load augmented hypno:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    ### to load features for augmented eeg:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns]\n",
    "\n",
    "    ### shuffle X\n",
    "    permut = np.random.permutation(df_feat.shape[0])\n",
    "    df_feat = df_feat.iloc[permut]\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == idx_train_recordings[0]:\n",
    "        df_feat_X_train = df_feat.to_numpy()\n",
    "    else:\n",
    "        df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "    ### shuffle y\n",
    "    hypno_30s = hypno_30s[permut]\n",
    "\n",
    "    ### to load labels for train: append hypno to hypno_y_train\n",
    "    hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "\n",
    "### to load features for test:\n",
    "df_feat_loc = reference_df.iloc[idx_test_recordings].df_feat\n",
    "df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "df_feat_X_test = df_feat[columns].to_numpy()\n",
    "\n",
    "### to load labels for test:\n",
    "hypno_30s_loc = reference_df.iloc[idx_test_recordings].hypno\n",
    "hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "hypno_y_test = hypno_30s\n",
    "\n",
    "print(\n",
    "    f\"Train set: X={df_feat_X_train.shape} y={df_feat_X_train.shape, hypno_y_train.shape}\"\n",
    ")\n",
    "print(f\"Test set: {df_feat_X_test.shape} y={df_feat_X_test.shape, hypno_y_test.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9461a3eb0cbef873800a78c94f0b6f375dc71a03d464463d7b611af82b6cd16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
