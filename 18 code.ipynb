{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from mne.filter import resample, filter_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lspopt import spectrogram_lspopt\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "\n",
    "import logging\n",
    "LOGGING_TYPES = dict(DEBUG=logging.DEBUG, INFO=logging.INFO, WARNING=logging.WARNING,\n",
    "                     ERROR=logging.ERROR, CRITICAL=logging.CRITICAL)\n",
    "logger = logging.getLogger('yasa')\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypno</th>\n",
       "      <th>df_feat</th>\n",
       "      <th>eeg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P18_N3 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N3 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P18_N2 R</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N2 R.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P17_N2 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P17_N2 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      hypno  \\\n",
       "name                                                          \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "\n",
       "                       df_feat  \\\n",
       "name                             \n",
       "P18_N3 L  feature/P18_N3 L.csv   \n",
       "P18_N2 R  feature/P18_N2 R.csv   \n",
       "P17_N2 L  feature/P17_N2 L.csv   \n",
       "\n",
       "                                                        eeg  \n",
       "name                                                         \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load reference_df     \n",
    "reference_df = pd.read_csv(\"reference_df.csv\", index_col=\"name\")\n",
    "reference_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iqr</th>\n",
       "      <th>ab</th>\n",
       "      <th>ag</th>\n",
       "      <th>sb</th>\n",
       "      <th>sg</th>\n",
       "      <th>bs</th>\n",
       "      <th>ta_b</th>\n",
       "      <th>gs</th>\n",
       "      <th>ga</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>ts</th>\n",
       "      <th>da</th>\n",
       "      <th>dfa</th>\n",
       "      <th>std_psd</th>\n",
       "      <th>ds</th>\n",
       "      <th>dt</th>\n",
       "      <th>katz</th>\n",
       "      <th>mean_psd</th>\n",
       "      <th>mean_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_classif</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiSqr</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             iqr    ab    ag    sb    sg    bs  ta_b    gs    ga   std  ...  \\\n",
       "method_name                                                             ...   \n",
       "f_classif    9.0   2.0   3.0   1.0   4.0   7.0   5.0  15.0  26.0  39.0  ...   \n",
       "MI           1.0  19.0  18.0  22.0  27.0  24.0  23.0  28.0  17.0   2.0  ...   \n",
       "chiSqr       6.0   1.0   4.0   2.0   8.0   9.0  12.0   3.0   5.0  13.0  ...   \n",
       "\n",
       "             mean    ts    da   dfa  std_psd    ds    dt  katz  mean_psd  \\\n",
       "method_name                                                                \n",
       "f_classif    73.0  54.0  68.0  45.0     60.0  71.0  65.0  56.0      64.0   \n",
       "MI           14.0  52.0  47.0  70.0     65.0  50.0  63.0  72.0      68.0   \n",
       "chiSqr       73.0  61.0  58.0  60.0     54.0  62.0  63.0  64.0      66.0   \n",
       "\n",
       "             mean_distance  \n",
       "method_name                 \n",
       "f_classif             63.0  \n",
       "MI                    73.0  \n",
       "chiSqr                71.0  \n",
       "\n",
       "[3 rows x 73 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv    \n",
    "rankings_df = pd.read_csv(\"rankings_df aug.csv\", index_col=\"method_name\")\n",
    "rankings_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sleep stage distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120272 epochs available across 61 recordings.\n"
     ]
    }
   ],
   "source": [
    "### to see id's\n",
    "idx = reference_df.index.to_list()\n",
    "\n",
    "epochs_count = 0\n",
    "hypno_30s_all = np.array([])\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in range(0, len(reference_df)):\n",
    "    # To load information of each night:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "    # to append current hypno to array of all hypnos - to plotting histogram later:\n",
    "    hypno_30s_all = np.append(hypno_30s_all, hypno_30s)\n",
    "    # count the number of epochs\n",
    "    epochs_count += len(hypno_30s)\n",
    "\n",
    "print(f\"{epochs_count} epochs available across {len(idx)} recordings.\")\n",
    "\n",
    "# plotting histogram of classes in all hypnos:\n",
    "stages, counts = np.unique(hypno_30s_all, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.bar(stages, counts, color=\"blueviolet\")\n",
    "ax.set(xticks=np.arange(0, 4 + 1, 1), xticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"])\n",
    "ax.tick_params(axis=\"x\", labelsize=13, labelrotation=20, labelcolor=\"green\", width=3)\n",
    "ax.tick_params(axis=\"y\", labelsize=13, labelrotation=20, labelcolor=\"orangered\")\n",
    "plt.xlabel(\"Sleep stage\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(f\"Sleep stages for {epochs_count} epochs across {len(idx)} recordings\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"stage_distribution_count aug.svg\")\n",
    "# plt.savefig(\"stage_distribution_count aug.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import kruskal\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on 60 nights, test of 1 night\n",
    "(1560*60 x 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>> train recordings (index): \n",
      "[39 32 15 27 52 41 19 49  5 60 55  8 26 40 10 16 18 30 42 58 31 34 25 11\n",
      " 36 22 23 59  1 14 44  2 37 57  4 38  7 33 54  6  0 43 56 47 17 45 51 35\n",
      " 24 21]\n",
      ">>>>>>>> test recordings: \n",
      "[28  9 20 46  3 53 29 50 12 13 48]\n"
     ]
    }
   ],
   "source": [
    "idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "idx_train_recordings = idx_all_recordings[:-11]\n",
    "idx_test_recordings = idx_all_recordings[-11:]\n",
    "print(\">>>>>>>> train recordings (index): \")\n",
    "print(idx_train_recordings)\n",
    "print(\">>>>>>>> test recordings: \")\n",
    "print(idx_test_recordings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset to train and test + shuffle each night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(97206, 40) y=(97206,)\n",
      "Test set: X=(23066, 40) y=(23066,)\n"
     ]
    }
   ],
   "source": [
    "df_feat_X_train = np.array([])\n",
    "df_feat_X_test = np.array([])\n",
    "hypno_y_train = np.array([])\n",
    "hypno_y_test = np.array([])\n",
    "\n",
    "columns = rankings_df.columns[:40]  # for selecting top columns\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in idx_train_recordings:\n",
    "    ### to load augmented hypnos for train:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    ### to load features of augmented eeg for train:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns]\n",
    "\n",
    "    ### shuffle X\n",
    "    permut = np.random.permutation(df_feat.shape[0])\n",
    "    df_feat = df_feat.iloc[permut]\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == idx_train_recordings[0]:\n",
    "        df_feat_X_train = df_feat.to_numpy()\n",
    "    else:\n",
    "        df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "    ### shuffle y\n",
    "    hypno_30s = hypno_30s[permut]\n",
    "\n",
    "    ### to load labels for train: append hypno to hypno_y_train\n",
    "    hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "\n",
    "for i in idx_test_recordings:\n",
    "    ### to load features for test:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    ### to load labels for test:\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns].to_numpy()\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == idx_test_recordings[0]:\n",
    "        df_feat_X_test = df_feat\n",
    "    else:\n",
    "        df_feat_X_test = np.vstack([df_feat_X_test, df_feat])\n",
    "\n",
    "    ### to load labels for train: append hypno to hypno_y_train\n",
    "    hypno_y_test = np.append(hypno_y_test, hypno_30s)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Train set: X={df_feat_X_train.shape} y={hypno_y_train.shape}\"\n",
    ")\n",
    "print(f\"Test set: X={df_feat_X_test.shape} y={hypno_y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a numpy array including all epochs \n",
    "\n",
    "To standardize all dataset including train and test, after train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120272, 40)\n"
     ]
    }
   ],
   "source": [
    "df_feat_all = np.array([])\n",
    "\n",
    "# to loop over all recording files:\n",
    "for i in range(len(reference_df)):\n",
    "    ### to load augmented hypno:\n",
    "    name = reference_df.iloc[i].name\n",
    "    hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "    hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "    ### to load features for augmented eeg:\n",
    "    df_feat_loc = reference_df.iloc[i].df_feat\n",
    "    df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "    df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "    df_feat = df_feat.replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )  # Replacing infinite values in features\n",
    "\n",
    "    ### select top 25 ranks columns\n",
    "    df_feat = df_feat[columns]\n",
    "\n",
    "    ### to load features for train: append df_feat to df_feat_X_train\n",
    "    if i == 0:\n",
    "        df_feat_all = df_feat.to_numpy()\n",
    "    else:\n",
    "        df_feat_all = np.vstack([df_feat_all, df_feat.to_numpy()])\n",
    "\n",
    "print(df_feat_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified examples: 5055\n",
      "Accuracy: 0.781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# we will standardize the columns in dataset before we feed them to a classifier\n",
    "sc = StandardScaler()\n",
    "sc.fit(df_feat_all) # first fit all the dataset\n",
    "X_train_std = sc.transform(df_feat_X_train) # then transform train \n",
    "X_test_std = sc.transform(df_feat_X_test) # and test\n",
    "\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "svm.fit(X_train_std, hypno_y_train)\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print(\"Misclassified examples: %d\" % (hypno_y_test != y_pred).sum())\n",
    "print(\"Accuracy: %.3f\" % accuracy_score(hypno_y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate classification metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.59      0.64      3393\n",
      "         1.0       0.60      0.43      0.50      4270\n",
      "         2.0       0.58      0.77      0.66      5576\n",
      "         3.0       0.86      0.76      0.81      5906\n",
      "         4.0       0.75      0.83      0.79      6037\n",
      "\n",
      "    accuracy                           0.70     25182\n",
      "   macro avg       0.70      0.68      0.68     25182\n",
      "weighted avg       0.71      0.70      0.70     25182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_26925/2803695133.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    }
   ],
   "source": [
    "def confmat_f(confmat):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va=\"center\", ha=\"center\")\n",
    "    ax.set(\n",
    "        xticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        xticks=range(5),\n",
    "        yticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        yticks=range(5),\n",
    "    )\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.xaxis.labelpad = 15\n",
    "    ax.xaxis.set_tick_params(labeltop=True)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion Matrix\", y=-0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confmat.png\")\n",
    "    plt.savefig(\"confmat.svg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "report = classification_report(hypno_y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "confmat = confusion_matrix(hypno_y_test, y_pred)\n",
    "confmat_f(confmat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune C parameter with learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(108244, 40) y=(108244,)\n",
      "Test set: X=(12028, 40) y=(12028,)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(test_prop=0.2):\n",
    "\n",
    "    idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "    idx_train_recordings = idx_all_recordings[: -int(test_prop * 61)]\n",
    "    idx_test_recordings = idx_all_recordings[-int(test_prop * 61) :]\n",
    "    # print(\">>>>>>>> train recordings (index): \")\n",
    "    # print(idx_train_recordings)\n",
    "    # print(\">>>>>>>> test recordings: \")\n",
    "    # print(idx_test_recordings)\n",
    "\n",
    "    df_feat_X_train = np.array([])\n",
    "    df_feat_X_test = np.array([])\n",
    "    hypno_y_train = np.array([])\n",
    "    hypno_y_test = np.array([])\n",
    "\n",
    "    columns = rankings_df.columns[:40]  # for selecting top columns\n",
    "\n",
    "    # to loop over all recording files:\n",
    "    for i in idx_train_recordings:\n",
    "        ### to load augmented hypnos for train:\n",
    "        name = reference_df.iloc[i].name\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        ### to load features of augmented eeg for train:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top 25 ranks columns\n",
    "        df_feat = df_feat[columns]\n",
    "\n",
    "        ### shuffle X\n",
    "        permut = np.random.permutation(df_feat.shape[0])\n",
    "        df_feat = df_feat.iloc[permut]\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_train_recordings[0]:\n",
    "            df_feat_X_train = df_feat.to_numpy()\n",
    "        else:\n",
    "            df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "        ### shuffle y\n",
    "        hypno_30s = hypno_30s[permut]\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "    for i in idx_test_recordings:\n",
    "        ### to load features for test:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        ### to load labels for test:\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top 25 ranks columns\n",
    "        df_feat = df_feat[columns].to_numpy()\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_test_recordings[0]:\n",
    "            df_feat_X_test = df_feat\n",
    "        else:\n",
    "            df_feat_X_test = np.vstack([df_feat_X_test, df_feat])\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_test = np.append(hypno_y_test, hypno_30s)\n",
    "\n",
    "    print(f\"Train set: X={df_feat_X_train.shape} y={hypno_y_train.shape}\")\n",
    "    print(f\"Test set: X={df_feat_X_test.shape} y={hypno_y_test.shape}\")\n",
    "\n",
    "    return df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test\n",
    "\n",
    "df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test = train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", C=10))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10).split(df_feat_X_train, hypno_y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(df_feat_X_train[train], hypno_y_train[train])\n",
    "    score = pipe_lr.score(df_feat_X_train[test], hypno_y_train[test])\n",
    "    scores.append(score)\n",
    "\n",
    "    print(\n",
    "        f\"Fold: {k+1:02d}, \"\n",
    "        f\"Class distr.: {np.bincount(hypno_y_train[train].astype(int))}, \"\n",
    "        f\"Acc.: {score:.3f}\"\n",
    "    )\n",
    "\n",
    "mean_acc = np.mean(scores)\n",
    "std_acc = np.std(scores)\n",
    "print(f\"\\nCV accuracy: {mean_acc:.3f} +/- {std_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(scores, c=\"darkturquoise\")\n",
    "plt.plot(range(len(scores)), scores, \"s\", c=\"darkslategrey\")\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([-0.5, len(scores) - 0.5])\n",
    "plt.grid()\n",
    "plt.title(f\"Stratified 10-fold CV to estimate accuracy: {mean_acc:.3f} +/- {std_acc:.3f} \")\n",
    "plt.xticks(range(len(scores)))\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"10-fold CV C1.svg\")\n",
    "# plt.savefig(\"10-fold CV C1.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: X=(97372, 40) y=(97372,)\n",
      "Test set: X=(22900, 40) y=(22900,)\n",
      "Misclassified examples: 6930\n",
      "Accuracy: 0.697\n",
      "Gridsearch 0: C= 0.001, Acc.: 0.697\n",
      "Train set: X=(95806, 40) y=(95806,)\n",
      "Test set: X=(24466, 40) y=(24466,)\n",
      "Misclassified examples: 6955\n",
      "Accuracy: 0.716\n",
      "Gridsearch 1: C= 0.01, Acc.: 0.716\n",
      "Train set: X=(96272, 40) y=(96272,)\n",
      "Test set: X=(24000, 40) y=(24000,)\n",
      "Misclassified examples: 6179\n",
      "Accuracy: 0.743\n",
      "Gridsearch 2: C= 0.1, Acc.: 0.743\n",
      "Train set: X=(96745, 40) y=(96745,)\n",
      "Test set: X=(23527, 40) y=(23527,)\n",
      "Misclassified examples: 5900\n",
      "Accuracy: 0.749\n",
      "Gridsearch 3: C= 1.0, Acc.: 0.749\n",
      "Train set: X=(97712, 40) y=(97712,)\n",
      "Test set: X=(22560, 40) y=(22560,)\n",
      "Misclassified examples: 5522\n",
      "Accuracy: 0.755\n",
      "Gridsearch 4: C= 10.0, Acc.: 0.755\n",
      "Train set: X=(95090, 40) y=(95090,)\n",
      "Test set: X=(25182, 40) y=(25182,)\n",
      "Misclassified examples: 7541\n",
      "Accuracy: 0.701\n",
      "Gridsearch 5: C= 100.0, Acc.: 0.701\n"
     ]
    }
   ],
   "source": [
    "acc_train_arr = np.array([])\n",
    "acc_test_arr = np.array([])\n",
    "\n",
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "for i in range(len(param_range)):\n",
    "    # train/test datasets\n",
    "    df_feat_X_train, df_feat_X_test, hypno_y_train, hypno_y_test = train_test_split()\n",
    "\n",
    "    # standardize the columns\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(df_feat_all)  # first fit all the dataset\n",
    "    X_train_std = sc.transform(df_feat_X_train)  # then transform train\n",
    "    X_test_std = sc.transform(df_feat_X_test)  # and test\n",
    "\n",
    "    # train the classifier\n",
    "    svm = SVC(kernel=\"rbf\", C=param_range[i])\n",
    "    svm.fit(X_train_std, hypno_y_train)\n",
    "    y_pred = svm.predict(X_test_std)\n",
    "    print(\"Misclassified examples: %d\" % (hypno_y_test != y_pred).sum())\n",
    "    print(\"Accuracy: %.3f\" % accuracy_score(hypno_y_test, y_pred))\n",
    "    acc_train = accuracy_score(hypno_y_test, y_pred)\n",
    "\n",
    "    acc_train_arr = np.append(acc_train_arr, acc_train)\n",
    "\n",
    "    print(f\"Gridsearch {i}: C= {param_range[i]}, Acc.: {np.round(acc_train,3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(param_range, acc_train_arr, \"--\", color=\"yellowgreen\", linewidth=2)\n",
    "plt.plot(param_range, acc_train_arr, \"s\", color=\"darkolivegreen\")\n",
    "plt.grid()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Parameter C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Tuning C hyperparameter, C=10 is optimum\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('hyperparam C.svg')\n",
    "# plt.savefig('hyperparam C.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_arr = acc_train_arr[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9461a3eb0cbef873800a78c94f0b6f375dc71a03d464463d7b611af82b6cd16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
