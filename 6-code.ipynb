{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from mne.filter import resample, filter_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lspopt import spectrogram_lspopt\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "\n",
    "import logging\n",
    "LOGGING_TYPES = dict(DEBUG=logging.DEBUG, INFO=logging.INFO, WARNING=logging.WARNING,\n",
    "                     ERROR=logging.ERROR, CRITICAL=logging.CRITICAL)\n",
    "logger = logging.getLogger('yasa')\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "Chan = ['EEG L']\n",
      "Sampling frequency = 256.0 Hz\n",
      "Data shape = (1, 7608320)\n",
      "Duration: 29720.0 (sec) OR 08:15:20\n"
     ]
    }
   ],
   "source": [
    "# Load the EDF file\n",
    "fname = \"P8_N3\"  # define here\n",
    "lr = \"L\"  # define here\n",
    "location = f\"/Users/amirhosseindaraie/Desktop/data/autoscoring-material/data/Zmax Donders/{fname}\"\n",
    "raw = mne.io.read_raw_edf(f\"{location}/EEG {lr}.edf\", preload=True, verbose=0)\n",
    "raw.pick_types(eeg=True)\n",
    "# fig = raw.plot(use_opengl=False)\n",
    "\n",
    "# Apply a zero-phase bandpass filter between 0.5 ~ 45 Hz\n",
    "raw.filter(0.5, 45)\n",
    "\n",
    "# Plot properties of the filter\n",
    "filt = mne.filter.create_filter(raw._data, 256, 0.5, 40)\n",
    "mne.viz.plot_filter(filt, 256)\n",
    "plt.savefig(\"filter shape.png\", dpi=100, bbox_inches=\"tight\")\n",
    "\n",
    "# Extract the data and convert from V to uV\n",
    "data = raw._data * 1e6\n",
    "sf = raw.info[\"sfreq\"]\n",
    "chan = raw.ch_names\n",
    "\n",
    "# Let's have a look at the data\n",
    "print(\"Chan =\", chan)\n",
    "print(\"Sampling frequency =\", sf, \"Hz\")\n",
    "print(\"Data shape =\", data.shape)\n",
    "\n",
    "\n",
    "def format_seconds_to_hhmmss(seconds):\n",
    "    # Return hhmmss of total seconds parameter\n",
    "    hours = seconds // (60 * 60)\n",
    "    seconds %= 60 * 60\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return \"%02i:%02i:%02i\" % (hours, minutes, seconds)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Duration: {data.shape[1]/sf} (sec) OR {format_seconds_to_hhmmss(data.shape[1]/sf)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_4506/1489955597.py:8: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"max_colwidth\", -1)\n"
     ]
    }
   ],
   "source": [
    "import antropy as ant\n",
    "import scipy.signal as sp_sig\n",
    "import scipy.stats as sp_stats\n",
    "from numpy import apply_along_axis as apply\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"max_colwidth\", -1)\n",
    "\n",
    "# Time vector in seconds\n",
    "times = np.arange(data.size) / sf\n",
    "\n",
    "\n",
    "def sliding_window(data, sf, window, step=None, axis=-1):\n",
    "    \"\"\"Calculate a sliding window of a 1D or 2D EEG signal.\n",
    "    .. versionadded:: 0.1.7\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy array\n",
    "        The 1D or 2D EEG data.\n",
    "    sf : float\n",
    "        The sampling frequency of ``data``.\n",
    "    window : int\n",
    "        The sliding window length, in seconds.\n",
    "    step : int\n",
    "        The sliding window step length, in seconds.\n",
    "        If None (default), ``step`` is set to ``window``,\n",
    "        which results in no overlap between the sliding windows.\n",
    "    axis : int\n",
    "        The axis to slide over. Defaults to the last axis.\n",
    "    Returns\n",
    "    -------\n",
    "    times : numpy array\n",
    "        Time vector, in seconds, corresponding to the START of each sliding\n",
    "        epoch in ``strided``.\n",
    "    strided : numpy array\n",
    "        A matrix where row in last dimension consists of one instance\n",
    "        of the sliding window, shape (n_epochs, ..., n_samples).\n",
    "    Notes\n",
    "    -----\n",
    "    This is a wrapper around the\n",
    "    :py:func:`numpy.lib.stride_tricks.as_strided` function.\n",
    "    Examples\n",
    "    --------\n",
    "    With a 1-D array\n",
    "    >>> import numpy as np\n",
    "    >>> from yasa import sliding_window\n",
    "    >>> data = np.arange(20)\n",
    "    >>> times, epochs = sliding_window(data, sf=1, window=5)\n",
    "    >>> times\n",
    "    array([ 0.,  5., 10., 15.])\n",
    "    >>> epochs\n",
    "    array([[ 0,  1,  2,  3,  4],\n",
    "           [ 5,  6,  7,  8,  9],\n",
    "           [10, 11, 12, 13, 14],\n",
    "           [15, 16, 17, 18, 19]])\n",
    "    >>> sliding_window(data, sf=1, window=5, step=1)[1]\n",
    "    array([[ 0,  1,  2,  3,  4],\n",
    "           [ 2,  3,  4,  5,  6],\n",
    "           [ 4,  5,  6,  7,  8],\n",
    "           [ 6,  7,  8,  9, 10],\n",
    "           [ 8,  9, 10, 11, 12],\n",
    "           [10, 11, 12, 13, 14],\n",
    "           [12, 13, 14, 15, 16],\n",
    "           [14, 15, 16, 17, 18]])\n",
    "    >>> sliding_window(data, sf=1, window=11)[1]\n",
    "    array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
    "    With a N-D array\n",
    "    >>> np.random.seed(42)\n",
    "    >>> # 4 channels x 20 samples\n",
    "    >>> data = np.random.randint(-100, 100, size=(4, 20))\n",
    "    >>> epochs = sliding_window(data, sf=1, window=10)[1]\n",
    "    >>> epochs.shape  # shape (n_epochs, n_channels, n_samples)\n",
    "    (2, 4, 10)\n",
    "    >>> epochs\n",
    "    array([[[  2,  79,  -8, -86,   6, -29,  88, -80,   2,  21],\n",
    "            [-13,  57, -63,  29,  91,  87, -80,  60, -43, -79],\n",
    "            [-50,   7, -46, -37,  30, -50,  34, -80, -28,  66],\n",
    "            [ -9,  10,  87,  98,  71, -93,  74, -66, -20,  63]],\n",
    "           [[-26, -13,  16,  -1,   3,  51,  30,  49, -48, -99],\n",
    "            [-12, -52, -42,  69,  87, -86,  89,  89,  74,  89],\n",
    "            [-83,  31, -12, -41, -87, -92, -11, -48,  29, -17],\n",
    "            [-51,   3,  31, -99,  33, -47,   5, -97, -47,  90]]])\n",
    "    \"\"\"\n",
    "    from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "    assert axis <= data.ndim, \"Axis value out of range.\"\n",
    "    assert isinstance(sf, (int, float)), \"sf must be int or float\"\n",
    "    assert isinstance(window, (int, float)), \"window must be int or float\"\n",
    "    assert isinstance(step, (int, float, type(None))), (\n",
    "        \"step must be int, \" \"float or None.\"\n",
    "    )\n",
    "    if isinstance(sf, float):\n",
    "        assert sf.is_integer(), \"sf must be a whole number.\"\n",
    "        sf = int(sf)\n",
    "    assert isinstance(axis, int), \"axis must be int.\"\n",
    "\n",
    "    # window and step in samples instead of points\n",
    "    window *= sf\n",
    "    step = window if step is None else step * sf\n",
    "\n",
    "    if isinstance(window, float):\n",
    "        assert window.is_integer(), \"window * sf must be a whole number.\"\n",
    "        window = int(window)\n",
    "\n",
    "    if isinstance(step, float):\n",
    "        assert step.is_integer(), \"step * sf must be a whole number.\"\n",
    "        step = int(step)\n",
    "\n",
    "    assert step >= 1, \"Stepsize may not be zero or negative.\"\n",
    "    assert window < data.shape[axis], (\n",
    "        \"Sliding window size may not exceed \" \"size of selected axis\"\n",
    "    )\n",
    "\n",
    "    # Define output shape\n",
    "    shape = list(data.shape)\n",
    "    shape[axis] = np.floor(data.shape[axis] / step - window / step + 1).astype(int)\n",
    "    shape.append(window)\n",
    "\n",
    "    # Calculate strides and time vector\n",
    "    strides = list(data.strides)\n",
    "    strides[axis] *= step\n",
    "    strides.append(data.strides[axis])\n",
    "    strided = as_strided(data, shape=shape, strides=strides)\n",
    "    t = np.arange(strided.shape[-2]) * (step / sf)\n",
    "\n",
    "    # Swap axis: n_epochs, ..., n_samples\n",
    "    if strided.ndim > 2:\n",
    "        strided = np.rollaxis(strided, -2, 0)\n",
    "    return t, strided\n",
    "\n",
    "\n",
    "# Convert the EEG data to 30-sec data\n",
    "times, data_win = sliding_window(data[0], sf, window=30)\n",
    "\n",
    "# Convert times to minutes\n",
    "times /= 60\n",
    "\n",
    "\n",
    "def lziv(x):\n",
    "    \"\"\"Binarize the EEG signal and calculate the Lempel-Ziv complexity.\"\"\"\n",
    "    return ant.lziv_complexity(x > x.mean(), normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>iqr</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>nzc</th>\n",
       "      <th>hmob</th>\n",
       "      <th>hcomp</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>app_entropy</th>\n",
       "      <th>spec_entropy</th>\n",
       "      <th>lziv</th>\n",
       "      <th>dfa</th>\n",
       "      <th>petrosian</th>\n",
       "      <th>katz</th>\n",
       "      <th>higuchi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.728240</td>\n",
       "      <td>-0.458406</td>\n",
       "      <td>0.610417</td>\n",
       "      <td>42.633953</td>\n",
       "      <td>0.580565</td>\n",
       "      <td>2.600725</td>\n",
       "      <td>205</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>12.427032</td>\n",
       "      <td>0.775805</td>\n",
       "      <td>0.211023</td>\n",
       "      <td>0.141362</td>\n",
       "      <td>0.201281</td>\n",
       "      <td>0.363116</td>\n",
       "      <td>1306</td>\n",
       "      <td>1.549203</td>\n",
       "      <td>1.009895</td>\n",
       "      <td>1.942383</td>\n",
       "      <td>1.322072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.409650</td>\n",
       "      <td>0.385982</td>\n",
       "      <td>-0.291012</td>\n",
       "      <td>32.186688</td>\n",
       "      <td>0.114546</td>\n",
       "      <td>2.405869</td>\n",
       "      <td>272</td>\n",
       "      <td>0.083842</td>\n",
       "      <td>9.601425</td>\n",
       "      <td>0.797360</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>0.203777</td>\n",
       "      <td>0.298042</td>\n",
       "      <td>0.416676</td>\n",
       "      <td>1246</td>\n",
       "      <td>1.489831</td>\n",
       "      <td>1.010768</td>\n",
       "      <td>1.945935</td>\n",
       "      <td>1.413717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.266214</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>2.663321</td>\n",
       "      <td>48.649830</td>\n",
       "      <td>0.124992</td>\n",
       "      <td>0.945467</td>\n",
       "      <td>128</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>10.302285</td>\n",
       "      <td>0.784943</td>\n",
       "      <td>0.267274</td>\n",
       "      <td>0.180985</td>\n",
       "      <td>0.267638</td>\n",
       "      <td>0.483593</td>\n",
       "      <td>1279</td>\n",
       "      <td>1.545471</td>\n",
       "      <td>1.010286</td>\n",
       "      <td>2.090015</td>\n",
       "      <td>1.416221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.069446</td>\n",
       "      <td>0.372208</td>\n",
       "      <td>5.369971</td>\n",
       "      <td>34.552458</td>\n",
       "      <td>-2.218553</td>\n",
       "      <td>9.562390</td>\n",
       "      <td>209</td>\n",
       "      <td>0.094153</td>\n",
       "      <td>8.400673</td>\n",
       "      <td>0.799514</td>\n",
       "      <td>0.293044</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>0.220029</td>\n",
       "      <td>0.509003</td>\n",
       "      <td>1456</td>\n",
       "      <td>1.490483</td>\n",
       "      <td>1.010866</td>\n",
       "      <td>1.822021</td>\n",
       "      <td>1.455203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.364001</td>\n",
       "      <td>-0.254080</td>\n",
       "      <td>0.494972</td>\n",
       "      <td>34.939698</td>\n",
       "      <td>-0.358552</td>\n",
       "      <td>2.604883</td>\n",
       "      <td>248</td>\n",
       "      <td>0.049412</td>\n",
       "      <td>14.853697</td>\n",
       "      <td>0.767596</td>\n",
       "      <td>0.183659</td>\n",
       "      <td>0.072636</td>\n",
       "      <td>0.146357</td>\n",
       "      <td>0.283256</td>\n",
       "      <td>1250</td>\n",
       "      <td>1.613247</td>\n",
       "      <td>1.009585</td>\n",
       "      <td>1.825622</td>\n",
       "      <td>1.307613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         std      mean    median        iqr      skew      kurt  nzc      hmob      hcomp  perm_entropy  svd_entropy  sample_entropy  app_entropy  spec_entropy  lziv       dfa  petrosian      katz   higuchi\n",
       "0  50.728240 -0.458406  0.610417  42.633953  0.580565  2.600725  205  0.059614  12.427032  0.775805      0.211023     0.141362        0.201281     0.363116      1306  1.549203  1.009895   1.942383  1.322072\n",
       "1  36.409650  0.385982 -0.291012  32.186688  0.114546  2.405869  272  0.083842  9.601425   0.797360      0.271151     0.203777        0.298042     0.416676      1246  1.489831  1.010768   1.945935  1.413717\n",
       "2  41.266214  0.059199  2.663321  48.649830  0.124992  0.945467  128  0.081633  10.302285  0.784943      0.267274     0.180985        0.267638     0.483593      1279  1.545471  1.010286   2.090015  1.416221\n",
       "3  53.069446  0.372208  5.369971  34.552458 -2.218553  9.562390  209  0.094153  8.400673   0.799514      0.293044     0.139526        0.220029     0.509003      1456  1.490483  1.010866   1.822021  1.455203\n",
       "4  60.364001 -0.254080  0.494972  34.939698 -0.358552  2.604883  248  0.049412  14.853697  0.767596      0.183659     0.072636        0.146357     0.283256      1250  1.613247  1.009585   1.825622  1.307613"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate standard descriptive statistics\n",
    "hmob, hcomp = ant.hjorth_params(data_win, axis=1)\n",
    "\n",
    "# Feature extraction\n",
    "df_feat = {\n",
    "    # Statistical\n",
    "    \"std\": apply(np.std, arr=data_win, axis=1, ddof=1),\n",
    "    \"mean\": apply(np.mean, arr=data_win, axis=1),\n",
    "    \"median\": apply(np.median, arr=data_win, axis=1),\n",
    "    \"iqr\": apply(sp_stats.iqr, arr=data_win, axis=1, rng=(25, 75)),\n",
    "    \"skew\": apply(sp_stats.skew, arr=data_win, axis=1),\n",
    "    \"kurt\": apply(sp_stats.kurtosis, arr=data_win, axis=1),\n",
    "    \"nzc\": apply(ant.num_zerocross, arr=data_win, axis=1),\n",
    "    \"hmob\": hmob,\n",
    "    \"hcomp\": hcomp,\n",
    "    # Entropy\n",
    "    \"perm_entropy\": apply(ant.perm_entropy, axis=1, arr=data_win, normalize=True),\n",
    "    \"svd_entropy\": apply(ant.svd_entropy, 1, data_win, normalize=True),\n",
    "    \"sample_entropy\": apply(ant.sample_entropy, 1, data_win),\n",
    "    \"app_entropy\": apply(ant.app_entropy, 1, data_win, order=2),\n",
    "    \"spec_entropy\": apply(\n",
    "        ant.spectral_entropy,\n",
    "        1,\n",
    "        data_win,\n",
    "        sf,\n",
    "        normalize=True,\n",
    "        method=\"welch\",\n",
    "        nperseg=50,\n",
    "    ),\n",
    "    \"lziv\": apply(ant.lziv_complexity, 1, data_win),\n",
    "    # Fractal dimension\n",
    "    \"dfa\": apply(ant.detrended_fluctuation, 1, data_win),\n",
    "    \"petrosian\": apply(ant.petrosian_fd, 1, data_win),\n",
    "    \"katz\": apply(ant.katz_fd, 1, data_win),\n",
    "    \"higuchi\": apply(ant.higuchi_fd, 1, data_win),\n",
    "}\n",
    "\n",
    "\n",
    "df_feat = pd.DataFrame(df_feat)\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>iqr</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>nzc</th>\n",
       "      <th>hmob</th>\n",
       "      <th>hcomp</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>app_entropy</th>\n",
       "      <th>spec_entropy</th>\n",
       "      <th>lziv</th>\n",
       "      <th>dfa</th>\n",
       "      <th>petrosian</th>\n",
       "      <th>katz</th>\n",
       "      <th>higuchi</th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>sigma</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.728240</td>\n",
       "      <td>-0.458406</td>\n",
       "      <td>0.610417</td>\n",
       "      <td>42.633953</td>\n",
       "      <td>0.580565</td>\n",
       "      <td>2.600725</td>\n",
       "      <td>205</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>12.427032</td>\n",
       "      <td>0.775805</td>\n",
       "      <td>0.211023</td>\n",
       "      <td>0.141362</td>\n",
       "      <td>0.201281</td>\n",
       "      <td>0.363116</td>\n",
       "      <td>1306</td>\n",
       "      <td>1.549203</td>\n",
       "      <td>1.009895</td>\n",
       "      <td>1.942383</td>\n",
       "      <td>1.322072</td>\n",
       "      <td>0.947087</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.409650</td>\n",
       "      <td>0.385982</td>\n",
       "      <td>-0.291012</td>\n",
       "      <td>32.186688</td>\n",
       "      <td>0.114546</td>\n",
       "      <td>2.405869</td>\n",
       "      <td>272</td>\n",
       "      <td>0.083842</td>\n",
       "      <td>9.601425</td>\n",
       "      <td>0.797360</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>0.203777</td>\n",
       "      <td>0.298042</td>\n",
       "      <td>0.416676</td>\n",
       "      <td>1246</td>\n",
       "      <td>1.489831</td>\n",
       "      <td>1.010768</td>\n",
       "      <td>1.945935</td>\n",
       "      <td>1.413717</td>\n",
       "      <td>0.954627</td>\n",
       "      <td>0.024764</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.003815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.266214</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>2.663321</td>\n",
       "      <td>48.649830</td>\n",
       "      <td>0.124992</td>\n",
       "      <td>0.945467</td>\n",
       "      <td>128</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>10.302285</td>\n",
       "      <td>0.784943</td>\n",
       "      <td>0.267274</td>\n",
       "      <td>0.180985</td>\n",
       "      <td>0.267638</td>\n",
       "      <td>0.483593</td>\n",
       "      <td>1279</td>\n",
       "      <td>1.545471</td>\n",
       "      <td>1.010286</td>\n",
       "      <td>2.090015</td>\n",
       "      <td>1.416221</td>\n",
       "      <td>0.954055</td>\n",
       "      <td>0.020523</td>\n",
       "      <td>0.010761</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.004250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.069446</td>\n",
       "      <td>0.372208</td>\n",
       "      <td>5.369971</td>\n",
       "      <td>34.552458</td>\n",
       "      <td>-2.218553</td>\n",
       "      <td>9.562390</td>\n",
       "      <td>209</td>\n",
       "      <td>0.094153</td>\n",
       "      <td>8.400673</td>\n",
       "      <td>0.799514</td>\n",
       "      <td>0.293044</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>0.220029</td>\n",
       "      <td>0.509003</td>\n",
       "      <td>1456</td>\n",
       "      <td>1.490483</td>\n",
       "      <td>1.010866</td>\n",
       "      <td>1.822021</td>\n",
       "      <td>1.455203</td>\n",
       "      <td>0.958963</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>0.006872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.364001</td>\n",
       "      <td>-0.254080</td>\n",
       "      <td>0.494972</td>\n",
       "      <td>34.939698</td>\n",
       "      <td>-0.358552</td>\n",
       "      <td>2.604883</td>\n",
       "      <td>248</td>\n",
       "      <td>0.049412</td>\n",
       "      <td>14.853697</td>\n",
       "      <td>0.767596</td>\n",
       "      <td>0.183659</td>\n",
       "      <td>0.072636</td>\n",
       "      <td>0.146357</td>\n",
       "      <td>0.283256</td>\n",
       "      <td>1250</td>\n",
       "      <td>1.613247</td>\n",
       "      <td>1.009585</td>\n",
       "      <td>1.825622</td>\n",
       "      <td>1.307613</td>\n",
       "      <td>0.989613</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         std      mean    median        iqr      skew      kurt  nzc      hmob      hcomp  perm_entropy  svd_entropy  sample_entropy  app_entropy  spec_entropy  lziv       dfa  petrosian      katz   higuchi     delta     theta     alpha     sigma      beta     gamma\n",
       "0  50.728240 -0.458406  0.610417  42.633953  0.580565  2.600725  205  0.059614  12.427032  0.775805      0.211023     0.141362        0.201281     0.363116      1306  1.549203  1.009895   1.942383  1.322072  0.947087  0.032990  0.009982  0.002576  0.005049  0.002316\n",
       "1  36.409650  0.385982 -0.291012  32.186688  0.114546  2.405869  272  0.083842  9.601425   0.797360      0.271151     0.203777        0.298042     0.416676      1246  1.489831  1.010768   1.945935  1.413717  0.954627  0.024764  0.008382  0.002574  0.005836  0.003815\n",
       "2  41.266214  0.059199  2.663321  48.649830  0.124992  0.945467  128  0.081633  10.302285  0.784943      0.267274     0.180985        0.267638     0.483593      1279  1.545471  1.010286   2.090015  1.416221  0.954055  0.020523  0.010761  0.003061  0.007351  0.004250\n",
       "3  53.069446  0.372208  5.369971  34.552458 -2.218553  9.562390  209  0.094153  8.400673   0.799514      0.293044     0.139526        0.220029     0.509003      1456  1.490483  1.010866   1.822021  1.455203  0.958963  0.012552  0.004894  0.003369  0.013351  0.006872\n",
       "4  60.364001 -0.254080  0.494972  34.939698 -0.358552  2.604883  248  0.049412  14.853697  0.767596      0.183659     0.072636        0.146357     0.283256      1250  1.613247  1.009585   1.825622  1.307613  0.989613  0.006680  0.001312  0.000443  0.001215  0.000737"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.integrate import simps\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Estimate power spectral density using Welch's method\n",
    "freqs, psd = welch(data_win, sf, nperseg=int(4 * sf))\n",
    "\n",
    "\n",
    "def bandpower_from_psd_ndarray(\n",
    "    psd,\n",
    "    freqs,\n",
    "    bands=[\n",
    "        (0.5, 4, \"Delta\"),\n",
    "        (4, 8, \"Theta\"),\n",
    "        (8, 12, \"Alpha\"),\n",
    "        (12, 16, \"Sigma\"),\n",
    "        (16, 30, \"Beta\"),\n",
    "        (30, 40, \"Gamma\"),\n",
    "    ],\n",
    "    relative=True,\n",
    "):\n",
    "    \"\"\"Compute bandpowers in N-dimensional PSD.\n",
    "    This is a np-only implementation of the :py:func:`yasa.bandpower_from_psd` function,\n",
    "    which supports 1-D arrays of shape (n_freqs), or N-dimensional arays (e.g. 2-D (n_chan,\n",
    "    n_freqs) or 3-D (n_chan, n_epochs, n_freqs))\n",
    "    .. versionadded:: 0.2.0\n",
    "    Parameters\n",
    "    ----------\n",
    "    psd : :py:class:`np.ndarray`\n",
    "        Power spectral density of data, in uV^2/Hz. Must be a N-D array of shape (..., n_freqs).\n",
    "        See :py:func:`scipy.signal.welch` for more details.\n",
    "    freqs : :py:class:`np.ndarray`\n",
    "        Array of frequencies. Must be a 1-D array of shape (n_freqs,)\n",
    "    bands : list of tuples\n",
    "        List of frequency bands of interests. Each tuple must contain the lower and upper\n",
    "        frequencies, as well as the band name (e.g. (0.5, 4, 'Delta')).\n",
    "    relative : boolean\n",
    "        If True, bandpower is divided by the total power between the min and\n",
    "        max frequencies defined in ``band`` (default 0.5 to 40 Hz).\n",
    "    Returns\n",
    "    -------\n",
    "    bandpowers : :py:class:`np.ndarray`\n",
    "        Bandpower array of shape *(n_bands, ...)*.\n",
    "    \"\"\"\n",
    "    # Type checks\n",
    "    assert isinstance(bands, list), \"bands must be a list of tuple(s)\"\n",
    "    assert isinstance(relative, bool), \"relative must be a boolean\"\n",
    "\n",
    "    # Safety checks\n",
    "    freqs = np.asarray(freqs)\n",
    "    psd = np.asarray(psd)\n",
    "    assert freqs.ndim == 1, \"freqs must be a 1-D array of shape (n_freqs,)\"\n",
    "    assert psd.shape[-1] == freqs.shape[-1], \"n_freqs must be last axis of psd\"\n",
    "\n",
    "    # Extract frequencies of interest\n",
    "    all_freqs = np.hstack([[b[0], b[1]] for b in bands])\n",
    "    fmin, fmax = min(all_freqs), max(all_freqs)\n",
    "    idx_good_freq = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "    freqs = freqs[idx_good_freq]\n",
    "    res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Trim PSD to frequencies of interest\n",
    "    psd = psd[..., idx_good_freq]\n",
    "\n",
    "    # Check if there are negative values in PSD\n",
    "    if (psd < 0).any():\n",
    "        msg = (\n",
    "            \"There are negative values in PSD. This will result in incorrect \"\n",
    "            \"bandpower values. We highly recommend working with an \"\n",
    "            \"all-positive PSD. For more details, please refer to: \"\n",
    "            \"https://github.com/raphaelvallat/yasa/issues/29\"\n",
    "        )\n",
    "        logger.warning(msg)\n",
    "\n",
    "    # Calculate total power\n",
    "    total_power = simps(psd, dx=res, axis=-1)\n",
    "    total_power = total_power[np.newaxis, ...]\n",
    "\n",
    "    # Initialize empty array\n",
    "    bp = np.zeros((len(bands), *psd.shape[:-1]), dtype=np.float64)\n",
    "\n",
    "    # Enumerate over the frequency bands\n",
    "    labels = []\n",
    "    for i, band in enumerate(bands):\n",
    "        b0, b1, la = band\n",
    "        labels.append(la)\n",
    "        idx_band = np.logical_and(freqs >= b0, freqs <= b1)\n",
    "        bp[i] = simps(psd[..., idx_band], dx=res, axis=-1)\n",
    "\n",
    "    if relative:\n",
    "        bp /= total_power\n",
    "    return bp\n",
    "\n",
    "\n",
    "# Compute bandpowers in N-dimensional PSD\n",
    "bp = bandpower_from_psd_ndarray(psd, freqs)\n",
    "bp = pd.DataFrame(bp.T, columns=[\"delta\", \"theta\", \"alpha\", \"sigma\", \"beta\", \"gamma\"])\n",
    "df_feat = pd.concat([df_feat, bp], axis=1)\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>iqr</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>nzc</th>\n",
       "      <th>hmob</th>\n",
       "      <th>hcomp</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>app_entropy</th>\n",
       "      <th>spec_entropy</th>\n",
       "      <th>lziv</th>\n",
       "      <th>dfa</th>\n",
       "      <th>petrosian</th>\n",
       "      <th>katz</th>\n",
       "      <th>higuchi</th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>sigma</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>dt</th>\n",
       "      <th>da</th>\n",
       "      <th>ds</th>\n",
       "      <th>db</th>\n",
       "      <th>dg</th>\n",
       "      <th>td</th>\n",
       "      <th>ta</th>\n",
       "      <th>ts</th>\n",
       "      <th>tb</th>\n",
       "      <th>tg</th>\n",
       "      <th>ad</th>\n",
       "      <th>at</th>\n",
       "      <th>asi</th>\n",
       "      <th>ab</th>\n",
       "      <th>ag</th>\n",
       "      <th>sd</th>\n",
       "      <th>st</th>\n",
       "      <th>sa</th>\n",
       "      <th>sb</th>\n",
       "      <th>sg</th>\n",
       "      <th>bd</th>\n",
       "      <th>bt</th>\n",
       "      <th>ba</th>\n",
       "      <th>bs</th>\n",
       "      <th>bg</th>\n",
       "      <th>gd</th>\n",
       "      <th>gt</th>\n",
       "      <th>ga</th>\n",
       "      <th>gs</th>\n",
       "      <th>gb</th>\n",
       "      <th>ta_b</th>\n",
       "      <th>ta_ab</th>\n",
       "      <th>gb_da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.728240</td>\n",
       "      <td>-0.458406</td>\n",
       "      <td>0.610417</td>\n",
       "      <td>42.633953</td>\n",
       "      <td>0.580565</td>\n",
       "      <td>2.600725</td>\n",
       "      <td>205</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>12.427032</td>\n",
       "      <td>0.775805</td>\n",
       "      <td>0.211023</td>\n",
       "      <td>0.141362</td>\n",
       "      <td>0.201281</td>\n",
       "      <td>0.363116</td>\n",
       "      <td>1306</td>\n",
       "      <td>1.549203</td>\n",
       "      <td>1.009895</td>\n",
       "      <td>1.942383</td>\n",
       "      <td>1.322072</td>\n",
       "      <td>0.947087</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>28.708670</td>\n",
       "      <td>94.877671</td>\n",
       "      <td>367.638309</td>\n",
       "      <td>187.573489</td>\n",
       "      <td>409.010976</td>\n",
       "      <td>0.034833</td>\n",
       "      <td>3.304844</td>\n",
       "      <td>12.805829</td>\n",
       "      <td>6.533688</td>\n",
       "      <td>14.246950</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.302586</td>\n",
       "      <td>3.874867</td>\n",
       "      <td>1.977004</td>\n",
       "      <td>4.310930</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.078089</td>\n",
       "      <td>0.258073</td>\n",
       "      <td>0.510212</td>\n",
       "      <td>1.112536</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.153053</td>\n",
       "      <td>0.505816</td>\n",
       "      <td>1.959969</td>\n",
       "      <td>2.180537</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.070190</td>\n",
       "      <td>0.231969</td>\n",
       "      <td>0.898847</td>\n",
       "      <td>0.458603</td>\n",
       "      <td>8.510691</td>\n",
       "      <td>2.858811</td>\n",
       "      <td>0.007695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.409650</td>\n",
       "      <td>0.385982</td>\n",
       "      <td>-0.291012</td>\n",
       "      <td>32.186688</td>\n",
       "      <td>0.114546</td>\n",
       "      <td>2.405869</td>\n",
       "      <td>272</td>\n",
       "      <td>0.083842</td>\n",
       "      <td>9.601425</td>\n",
       "      <td>0.797360</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>0.203777</td>\n",
       "      <td>0.298042</td>\n",
       "      <td>0.416676</td>\n",
       "      <td>1246</td>\n",
       "      <td>1.489831</td>\n",
       "      <td>1.010768</td>\n",
       "      <td>1.945935</td>\n",
       "      <td>1.413717</td>\n",
       "      <td>0.954627</td>\n",
       "      <td>0.024764</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>38.548423</td>\n",
       "      <td>113.887024</td>\n",
       "      <td>370.812011</td>\n",
       "      <td>163.564392</td>\n",
       "      <td>250.218235</td>\n",
       "      <td>0.025941</td>\n",
       "      <td>2.954389</td>\n",
       "      <td>9.619382</td>\n",
       "      <td>4.243089</td>\n",
       "      <td>6.491011</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.338480</td>\n",
       "      <td>3.255964</td>\n",
       "      <td>1.436199</td>\n",
       "      <td>2.197074</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.103957</td>\n",
       "      <td>0.307129</td>\n",
       "      <td>0.441098</td>\n",
       "      <td>0.674785</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.235677</td>\n",
       "      <td>0.696282</td>\n",
       "      <td>2.267071</td>\n",
       "      <td>1.529784</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>0.455151</td>\n",
       "      <td>1.481954</td>\n",
       "      <td>0.653687</td>\n",
       "      <td>5.679288</td>\n",
       "      <td>2.331209</td>\n",
       "      <td>0.010022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.266214</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>2.663321</td>\n",
       "      <td>48.649830</td>\n",
       "      <td>0.124992</td>\n",
       "      <td>0.945467</td>\n",
       "      <td>128</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>10.302285</td>\n",
       "      <td>0.784943</td>\n",
       "      <td>0.267274</td>\n",
       "      <td>0.180985</td>\n",
       "      <td>0.267638</td>\n",
       "      <td>0.483593</td>\n",
       "      <td>1279</td>\n",
       "      <td>1.545471</td>\n",
       "      <td>1.010286</td>\n",
       "      <td>2.090015</td>\n",
       "      <td>1.416221</td>\n",
       "      <td>0.954055</td>\n",
       "      <td>0.020523</td>\n",
       "      <td>0.010761</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>46.488090</td>\n",
       "      <td>88.660653</td>\n",
       "      <td>311.704843</td>\n",
       "      <td>129.784474</td>\n",
       "      <td>224.477287</td>\n",
       "      <td>0.021511</td>\n",
       "      <td>1.907169</td>\n",
       "      <td>6.705047</td>\n",
       "      <td>2.791779</td>\n",
       "      <td>4.828705</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>0.524337</td>\n",
       "      <td>3.515707</td>\n",
       "      <td>1.463834</td>\n",
       "      <td>2.531870</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.149141</td>\n",
       "      <td>0.284438</td>\n",
       "      <td>0.416370</td>\n",
       "      <td>0.720160</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.358195</td>\n",
       "      <td>0.683138</td>\n",
       "      <td>2.401711</td>\n",
       "      <td>1.729616</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.207095</td>\n",
       "      <td>0.394965</td>\n",
       "      <td>1.388581</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>4.255613</td>\n",
       "      <td>1.727232</td>\n",
       "      <td>0.012024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.069446</td>\n",
       "      <td>0.372208</td>\n",
       "      <td>5.369971</td>\n",
       "      <td>34.552458</td>\n",
       "      <td>-2.218553</td>\n",
       "      <td>9.562390</td>\n",
       "      <td>209</td>\n",
       "      <td>0.094153</td>\n",
       "      <td>8.400673</td>\n",
       "      <td>0.799514</td>\n",
       "      <td>0.293044</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>0.220029</td>\n",
       "      <td>0.509003</td>\n",
       "      <td>1456</td>\n",
       "      <td>1.490483</td>\n",
       "      <td>1.010866</td>\n",
       "      <td>1.822021</td>\n",
       "      <td>1.455203</td>\n",
       "      <td>0.958963</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>76.400467</td>\n",
       "      <td>195.966201</td>\n",
       "      <td>284.671687</td>\n",
       "      <td>71.827131</td>\n",
       "      <td>139.537012</td>\n",
       "      <td>0.013089</td>\n",
       "      <td>2.564987</td>\n",
       "      <td>3.726046</td>\n",
       "      <td>0.940140</td>\n",
       "      <td>1.826390</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.389866</td>\n",
       "      <td>1.452657</td>\n",
       "      <td>0.366528</td>\n",
       "      <td>0.712046</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.268381</td>\n",
       "      <td>0.688394</td>\n",
       "      <td>0.252316</td>\n",
       "      <td>0.490168</td>\n",
       "      <td>0.013922</td>\n",
       "      <td>1.063671</td>\n",
       "      <td>2.728303</td>\n",
       "      <td>3.963289</td>\n",
       "      <td>1.942678</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>0.547528</td>\n",
       "      <td>1.404403</td>\n",
       "      <td>2.040116</td>\n",
       "      <td>0.514753</td>\n",
       "      <td>1.306668</td>\n",
       "      <td>0.956196</td>\n",
       "      <td>0.020982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.364001</td>\n",
       "      <td>-0.254080</td>\n",
       "      <td>0.494972</td>\n",
       "      <td>34.939698</td>\n",
       "      <td>-0.358552</td>\n",
       "      <td>2.604883</td>\n",
       "      <td>248</td>\n",
       "      <td>0.049412</td>\n",
       "      <td>14.853697</td>\n",
       "      <td>0.767596</td>\n",
       "      <td>0.183659</td>\n",
       "      <td>0.072636</td>\n",
       "      <td>0.146357</td>\n",
       "      <td>0.283256</td>\n",
       "      <td>1250</td>\n",
       "      <td>1.613247</td>\n",
       "      <td>1.009585</td>\n",
       "      <td>1.825622</td>\n",
       "      <td>1.307613</td>\n",
       "      <td>0.989613</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>148.152248</td>\n",
       "      <td>754.316880</td>\n",
       "      <td>2235.510571</td>\n",
       "      <td>814.342235</td>\n",
       "      <td>1341.917638</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>5.091498</td>\n",
       "      <td>15.089279</td>\n",
       "      <td>5.496658</td>\n",
       "      <td>9.057693</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.196406</td>\n",
       "      <td>2.963623</td>\n",
       "      <td>1.079576</td>\n",
       "      <td>1.778984</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.066272</td>\n",
       "      <td>0.337425</td>\n",
       "      <td>0.364276</td>\n",
       "      <td>0.600273</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.181929</td>\n",
       "      <td>0.926290</td>\n",
       "      <td>2.745173</td>\n",
       "      <td>1.647855</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.110403</td>\n",
       "      <td>0.562119</td>\n",
       "      <td>1.665907</td>\n",
       "      <td>0.606850</td>\n",
       "      <td>6.576234</td>\n",
       "      <td>3.162296</td>\n",
       "      <td>0.001971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         std      mean    median        iqr      skew      kurt  nzc      hmob      hcomp  perm_entropy  svd_entropy  sample_entropy  app_entropy  spec_entropy  lziv       dfa  petrosian      katz   higuchi     delta     theta     alpha     sigma      beta     gamma          dt          da           ds          db           dg        td        ta         ts        tb         tg        ad        at       asi        ab        ag        sd        st        sa        sb        sg        bd        bt        ba        bs        bg        gd        gt        ga        gs        gb      ta_b     ta_ab     gb_da\n",
       "0  50.728240 -0.458406  0.610417  42.633953  0.580565  2.600725  205  0.059614  12.427032  0.775805      0.211023     0.141362        0.201281     0.363116      1306  1.549203  1.009895   1.942383  1.322072  0.947087  0.032990  0.009982  0.002576  0.005049  0.002316  28.708670   94.877671   367.638309   187.573489  409.010976   0.034833  3.304844  12.805829  6.533688  14.246950  0.010540  0.302586  3.874867  1.977004  4.310930  0.002720  0.078089  0.258073  0.510212  1.112536  0.005331  0.153053  0.505816  1.959969  2.180537  0.002445  0.070190  0.231969  0.898847  0.458603  8.510691  2.858811  0.007695\n",
       "1  36.409650  0.385982 -0.291012  32.186688  0.114546  2.405869  272  0.083842  9.601425   0.797360      0.271151     0.203777        0.298042     0.416676      1246  1.489831  1.010768   1.945935  1.413717  0.954627  0.024764  0.008382  0.002574  0.005836  0.003815  38.548423   113.887024  370.812011   163.564392  250.218235   0.025941  2.954389  9.619382   4.243089  6.491011   0.008781  0.338480  3.255964  1.436199  2.197074  0.002697  0.103957  0.307129  0.441098  0.674785  0.006114  0.235677  0.696282  2.267071  1.529784  0.003997  0.154059  0.455151  1.481954  0.653687  5.679288  2.331209  0.010022\n",
       "2  41.266214  0.059199  2.663321  48.649830  0.124992  0.945467  128  0.081633  10.302285  0.784943      0.267274     0.180985        0.267638     0.483593      1279  1.545471  1.010286   2.090015  1.416221  0.954055  0.020523  0.010761  0.003061  0.007351  0.004250  46.488090   88.660653   311.704843   129.784474  224.477287   0.021511  1.907169  6.705047   2.791779  4.828705   0.011279  0.524337  3.515707  1.463834  2.531870  0.003208  0.149141  0.284438  0.416370  0.720160  0.007705  0.358195  0.683138  2.401711  1.729616  0.004455  0.207095  0.394965  1.388581  0.578163  4.255613  1.727232  0.012024\n",
       "3  53.069446  0.372208  5.369971  34.552458 -2.218553  9.562390  209  0.094153  8.400673   0.799514      0.293044     0.139526        0.220029     0.509003      1456  1.490483  1.010866   1.822021  1.455203  0.958963  0.012552  0.004894  0.003369  0.013351  0.006872  76.400467   195.966201  284.671687   71.827131   139.537012   0.013089  2.564987  3.726046   0.940140  1.826390   0.005103  0.389866  1.452657  0.366528  0.712046  0.003513  0.268381  0.688394  0.252316  0.490168  0.013922  1.063671  2.728303  3.963289  1.942678  0.007167  0.547528  1.404403  2.040116  0.514753  1.306668  0.956196  0.020982\n",
       "4  60.364001 -0.254080  0.494972  34.939698 -0.358552  2.604883  248  0.049412  14.853697  0.767596      0.183659     0.072636        0.146357     0.283256      1250  1.613247  1.009585   1.825622  1.307613  0.989613  0.006680  0.001312  0.000443  0.001215  0.000737  148.152248  754.316880  2235.510571  814.342235  1341.917638  0.006750  5.091498  15.089279  5.496658  9.057693   0.001326  0.196406  2.963623  1.079576  1.778984  0.000447  0.066272  0.337425  0.364276  0.600273  0.001228  0.181929  0.926290  2.745173  1.647855  0.000745  0.110403  0.562119  1.665907  0.606850  6.576234  3.162296  0.001971"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio of spectral power\n",
    "df_feat.eval(\"dt = delta / theta\", inplace=True)\n",
    "df_feat.eval(\"da = delta / alpha\", inplace=True)\n",
    "df_feat.eval(\"ds = delta / sigma\", inplace=True)\n",
    "df_feat.eval(\"db = delta / beta\", inplace=True)\n",
    "df_feat.eval(\"dg = delta / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"td = theta / delta\", inplace=True)\n",
    "df_feat.eval(\"ta = theta / alpha\", inplace=True)\n",
    "df_feat.eval(\"ts = theta / sigma\", inplace=True)\n",
    "df_feat.eval(\"tb = theta / beta\", inplace=True)\n",
    "df_feat.eval(\"tg = theta / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"ad = alpha / delta\", inplace=True)\n",
    "df_feat.eval(\"at = alpha / theta\", inplace=True)\n",
    "df_feat.eval(\"asi = alpha / sigma\", inplace=True)\n",
    "df_feat.eval(\"ab = alpha / beta\", inplace=True)\n",
    "df_feat.eval(\"ag = alpha / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"sd = sigma / delta\", inplace=True)\n",
    "df_feat.eval(\"st = sigma / theta\", inplace=True)\n",
    "df_feat.eval(\"sa = sigma / alpha\", inplace=True)\n",
    "df_feat.eval(\"sb = sigma / beta\", inplace=True)\n",
    "df_feat.eval(\"sg = sigma / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"bd = beta / delta\", inplace=True)\n",
    "df_feat.eval(\"bt = beta / theta\", inplace=True)\n",
    "df_feat.eval(\"ba = beta / alpha\", inplace=True)\n",
    "df_feat.eval(\"bs = beta / sigma\", inplace=True)\n",
    "df_feat.eval(\"bg = beta / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"gd = gamma / delta\", inplace=True)\n",
    "df_feat.eval(\"gt = gamma / theta\", inplace=True)\n",
    "df_feat.eval(\"ga = gamma / alpha\", inplace=True)\n",
    "df_feat.eval(\"gs = gamma / sigma\", inplace=True)\n",
    "df_feat.eval(\"gb = gamma / beta\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"ta_b = (theta + alpha)/beta\", inplace=True)\n",
    "df_feat.eval(\"ta_ab = (theta + alpha)/(alpha + beta)\", inplace=True)\n",
    "df_feat.eval(\"gb_da = (gamma + beta)/(delta + alpha)\", inplace=True)\n",
    "\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the envelope derivative operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute the envelope derivative operator (EDO), as defined in [1].\n",
    "[1] JM O' Toole, A Temko, NJ Stevenson, “Assessing instantaneous energy in the EEG: a non-negative, frequency-weighted energy operator”, IEEE Int. Conf.  on Eng. in Medicine and Biology, Chicago, August 2014\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def discrete_hilbert(x, DBplot=False):\n",
    "    \"\"\"Discrete Hilbert transform\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: ndarray\n",
    "        input signal\n",
    "    DBplot: bool, optional\n",
    "        plot or not\n",
    "    Returns\n",
    "    -------\n",
    "    x_hilb : ndarray\n",
    "        Hilbert transform of x\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    Nh = np.ceil(N / 2)\n",
    "    k = np.arange(N)\n",
    "\n",
    "    # build the Hilbert transform in the frequency domain:\n",
    "    H = -1j * np.sign(Nh - k) * np.sign(k)\n",
    "    x_hilb = np.fft.ifft(np.fft.fft(x) * H)\n",
    "    x_hilb = np.real(x_hilb)\n",
    "\n",
    "    if DBplot:\n",
    "        plt.figure(10, clear=True)\n",
    "        plt.plot(np.imag(H))\n",
    "\n",
    "    return x_hilb\n",
    "\n",
    "\n",
    "def edo(x, DBplot=False):\n",
    "    \"\"\"Generate Envelope Derivative Operator (EDO) Γ[x(n)] from simple formula in the time domain:\n",
    "    Γ[x(n)] = y(n)² + H[y(n)]²\n",
    "    where y(n) is the derivative of x(n) using the central-finite method and H[.] is the\n",
    "    Hilbert transform.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: ndarray\n",
    "        input signal\n",
    "    DBplot: bool, optional\n",
    "        plot or not\n",
    "    Returns\n",
    "    -------\n",
    "    x_edo : ndarray\n",
    "        EDO of x\n",
    "    \"\"\"\n",
    "    # 1. check if odd length and if so make even:\n",
    "    N_start = len(x)\n",
    "    if (N_start % 2) != 0:\n",
    "        x = np.hstack((x, 0))\n",
    "\n",
    "    N = len(x)\n",
    "    nl = np.arange(1, N - 1)\n",
    "    xx = np.zeros(N)\n",
    "\n",
    "    # 2. calculate the Hilbert transform\n",
    "    h = discrete_hilbert(x)\n",
    "\n",
    "    # 3. implement with the central finite difference equation\n",
    "    xx[nl] = (\n",
    "        (x[nl + 1] ** 2) + (x[nl - 1] ** 2) + (h[nl + 1] ** 2) + (h[nl - 1] ** 2)\n",
    "    ) / 4 - ((x[nl + 1] * x[nl - 1] + h[nl + 1] * h[nl - 1]) / 2)\n",
    "\n",
    "    # trim and zero-pad and the ends:\n",
    "    x_edo = np.pad(xx[2 : (len(xx) - 2)], (2, 2), \"constant\", constant_values=(0, 0))\n",
    "\n",
    "    if DBplot:\n",
    "        plt.figure(2, clear=True)\n",
    "        (hl1,) = plt.plot(x, label=\"test signal\")\n",
    "        (hl2,) = plt.plot(x_edo, label=\"EDO\")\n",
    "        plt.legend(handles=[hl1, hl2], loc=\"upper right\")\n",
    "        plt.pause(0.0001)\n",
    "\n",
    "    return x_edo[0:N_start]\n",
    "\n",
    "\n",
    "def test_edo_random():\n",
    "    \"\"\"Test EDO with a random signal\"\"\"\n",
    "\n",
    "    DBplot = True\n",
    "    x = np.random.randn(102)\n",
    "    x_e = edo(x)\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # plot\n",
    "    # -------------------------------------------------------------------\n",
    "    if DBplot:\n",
    "        plt.figure(2, clear=True)\n",
    "        (hl1,) = plt.plot(x, label=\"test signal\")\n",
    "        (hl2,) = plt.plot(x_e, label=\"EDO\")\n",
    "        plt.legend(handles=[hl1, hl2], loc=\"upper right\")\n",
    "        plt.pause(0.0001)\n",
    "\n",
    "\n",
    "\"\"\" General_nleo: ''General'' Non-Linear Energy Operator (NLEO) expression: \n",
    "Ψ(n)=x(n-l)x(n-p)-x(n-q)x(n-s) for l+p=q+s  (and [l,p]≠[q,s], otherwise Ψ(n)=0)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def gen_nleo(x, l=1, p=2, q=0, s=3):\n",
    "    \"\"\"general form of the nonlinear energy operator (NLEO)\n",
    "    General NLEO expression: Ψ(n) = x(n-l)x(n-p) - x(n-q)x(n-s)\n",
    "    for l+p=q+s  (and [l,p]≠[q,s], otherwise Ψ(n)=0)\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: ndarray\n",
    "        input signal\n",
    "    l: int, optional\n",
    "        parameter of NLEO expression (see above)\n",
    "    p: int, optional\n",
    "        parameter of NLEO expression (see above)\n",
    "    q: int, optional\n",
    "        parameter of NLEO expression (see above)\n",
    "    s: int, optional\n",
    "        parameter of NLEO expression (see above)\n",
    "    Returns\n",
    "    -------\n",
    "    x_nleo : ndarray\n",
    "        NLEO array\n",
    "    Example\n",
    "    -------\n",
    "    import np as np\n",
    "    # generate test signal\n",
    "    N = 256\n",
    "    n = np.arange(N)\n",
    "    w1 = np.pi / (N / 32)\n",
    "    ph1 = -np.pi + 2 * np.pi * np.random.rand(1)\n",
    "    a1 = 1.3\n",
    "    x1 = a1 * np.cos(w1 * n + ph1)\n",
    "    # compute instantaneous energy:\n",
    "    x_nleo = gen_nleo(x1, 1, 2, 0, 3)\n",
    "    # plot:\n",
    "    plt.figure(1, clear=True)\n",
    "    plt.plot(x1, '-o', label='test signal')\n",
    "    plt.plot(x_nleo, '-o', label='Agarwal-Gotman')\n",
    "    plt.legend(loc='upper left')\n",
    "    \"\"\"\n",
    "    # check parameters:\n",
    "    if (l + p) != (q + s) and any(np.sort((l, p)) != np.sort((q, s))):\n",
    "        warning(\"Incorrect parameters for NLEO. May be zero!\")\n",
    "\n",
    "    N = len(x)\n",
    "    x_nleo = np.zeros(N)\n",
    "\n",
    "    iedges = abs(l) + abs(p) + abs(q) + abs(s)\n",
    "    n = np.arange(iedges + 1, (N - iedges - 1))\n",
    "\n",
    "    x_nleo[n] = x[n - l] * x[n - p] - x[n - q] * x[n - s]\n",
    "\n",
    "    return x_nleo\n",
    "\n",
    "\n",
    "def nleo(x, type=\"teager\"):\n",
    "    \"\"\"generate different NLEOs based on the same operator\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: ndarray\n",
    "        input signal\n",
    "    type: {'teager', 'agarwal', 'palmu', 'abs_teager', 'env_only'}\n",
    "        which type of NLEO?\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_nleo : ndarray\n",
    "        NLEO array\n",
    "\n",
    "\n",
    "    Additional Notes\n",
    "    ----------------\n",
    "    {'teager': 'Teager-Kaiser', 'agarwal': 'Agarwal-Gotman', 'palmu': 'Palmu et.al.'}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def teager():\n",
    "        return gen_nleo(x, 0, 0, 1, -1)\n",
    "\n",
    "    def agarwal():\n",
    "        return gen_nleo(x, 1, 2, 0, 3)\n",
    "\n",
    "    def palmu():\n",
    "        return abs(gen_nleo(x, 1, 2, 0, 3))\n",
    "\n",
    "    def abs_teager():\n",
    "        return abs(gen_nleo(x, 0, 0, 1, -1))\n",
    "\n",
    "    def env_only():\n",
    "        return abs(x) ** 2\n",
    "\n",
    "    def default_nleo():\n",
    "        # -------------------------------------------------------------------\n",
    "        # default option\n",
    "        # -------------------------------------------------------------------\n",
    "        print(\"Invalid NLEO name; defaulting to Teager\")\n",
    "        return teager()\n",
    "\n",
    "    # pick which function to execute\n",
    "    which_nleo = {\n",
    "        \"teager\": teager,\n",
    "        \"agarwal\": agarwal,\n",
    "        \"palmu\": palmu,\n",
    "        \"abs_teager\": abs_teager,\n",
    "        \"env_only\": env_only,\n",
    "    }\n",
    "\n",
    "    def get_nleo(name):\n",
    "        return which_nleo.get(name, default_nleo)()\n",
    "\n",
    "    x_nleo = get_nleo(type)\n",
    "    return x_nleo\n",
    "\n",
    "\n",
    "def test_compare_nleos(x=None, DBplot=True):\n",
    "    \"\"\"test all NLEO variants with 1 signal\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: ndarray, optional\n",
    "        input signal (defaults to coloured Gaussian noise)\n",
    "    DBplot: bool\n",
    "        plot or not\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        N = 128\n",
    "        x = np.cumsum(np.random.randn(N))\n",
    "\n",
    "    all_methods = [\"teager\", \"agarwal\", \"palmu\"]\n",
    "    all_methods_strs = {\n",
    "        \"teager\": \"Teager-Kaiser\",\n",
    "        \"agarwal\": \"Agarwal-Gotman\",\n",
    "        \"palmu\": \"Palmu et.al.\",\n",
    "    }\n",
    "    x_nleo = dict.fromkeys(all_methods)\n",
    "\n",
    "    for n in all_methods:\n",
    "        x_nleo[n] = nleo(x, n)\n",
    "\n",
    "    if DBplot:\n",
    "        fig, ax = plt.subplots(nrows=2, ncols=1, num=4, clear=True)\n",
    "        ax[0].plot(x, \"-o\", label=\"test signal\")\n",
    "        for n in all_methods:\n",
    "            ax[1].plot(x_nleo[n], \"-o\", label=all_methods_strs[n])\n",
    "        ax[0].legend(loc=\"upper right\")\n",
    "        ax[1].legend(loc=\"upper left\")\n",
    "        plt.pause(0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_operators_from_signal_ndarray(\n",
    "    x, ops=[\"teager\", \"agarwal\", \"palmu\", \"abs_teager\", \"env_only\", \"edo\"]\n",
    "):\n",
    "    def teager():\n",
    "        return nleo(x, \"teager\")\n",
    "\n",
    "    def agarwal():\n",
    "        return nleo(x, \"agarwal\")\n",
    "\n",
    "    def palmu():\n",
    "        return nleo(x, \"palmu\")\n",
    "\n",
    "    def abs_teager():\n",
    "        return nleo(x, \"abs_teager\")\n",
    "\n",
    "    def env_only():\n",
    "        return nleo(x, \"env_only\")\n",
    "\n",
    "    def edo_f():\n",
    "        return edo(x)\n",
    "\n",
    "    def default_eo():\n",
    "        # -------------------------------------------------------------------\n",
    "        # default option\n",
    "        # -------------------------------------------------------------------\n",
    "        print(\"Invalid EO name; defaulting to Teager\")\n",
    "        return teager()\n",
    "\n",
    "    which_energy_operator = {\n",
    "        \"teager\": teager,\n",
    "        \"agarwal\": agarwal,\n",
    "        \"palmu\": palmu,\n",
    "        \"abs_teager\": abs_teager,\n",
    "        \"env_only\": env_only,\n",
    "        \"edo\": edo_f,\n",
    "    }\n",
    "\n",
    "    def get_energy_operator(name):\n",
    "        return which_energy_operator.get(name, default_eo)()\n",
    "\n",
    "    feat = np.zeros((x.shape[0], len(ops)))\n",
    "\n",
    "    for i, op in enumerate(ops):\n",
    "        x_nleo = get_energy_operator(op)  # Function\n",
    "        feat[:, i] = x_nleo\n",
    "\n",
    "    return feat\n",
    "\n",
    "\n",
    "data_win_mean = apply(np.mean, axis=1, arr=data_win)\n",
    "featEnergy = energy_operators_from_signal_ndarray(\n",
    "    data_win_mean, ops=[\"teager\", \"agarwal\", \"palmu\", \"abs_teager\", \"env_only\", \"edo\"]\n",
    ")\n",
    "featEnergy = pd.DataFrame(\n",
    "    featEnergy, columns=[\"teager\", \"agarwal\", \"palmu\", \"abs_teager\", \"env_only\", \"edo\"]\n",
    ")\n",
    "df_feat = pd.concat([df_feat, featEnergy], axis=1)\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write feature object to a comma-separated values (csv) file\n",
    "df_feat.to_csv(f\"feature/{fname} {lr}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature object as a dataframe\n",
    "df_feat = pd.read_csv(f\"feature/{fname} {lr}.csv\", index_col=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets add some new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth_activity(x):\n",
    "    \"\"\"Column-wise computation of Hjorth activity (variance).\"\"\"\n",
    "    return np.var(x, axis=0)\n",
    "\n",
    "\n",
    "def hjorth_mobility(x):\n",
    "    \"\"\"Column-wise computation of Hjorth mobility\"\"\"\n",
    "    return np.sqrt(np.var(np.gradient(x, axis=0), axis=0) / np.var(x, axis=0))\n",
    "\n",
    "\n",
    "def hjorth_complexity(x):\n",
    "    \"\"\"Column-wise computation of Hjorth complexity\"\"\"\n",
    "    return hjorth_mobility(np.gradient(x, axis=0)) / hjorth_mobility(x)\n",
    "\n",
    "\n",
    "data = data_cosine(N=1024, A=0.1, sampling=1024, freq=200)\n",
    "hjorth_act = hjorth_activity(data)\n",
    "hjorth_com = hjorth_complexity(data)\n",
    "hjorth_mob = hjorth_mobility(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy (E) of the signal is the sum of the squares of amplitude\n",
    "def energy_fn(x):\n",
    "    x /= np.max(x)\n",
    "    return np.mean(x**2)\n",
    "\n",
    "\n",
    "E = np.apply_along_axis(energy_fn, 1, data_win)\n",
    "df_feat[\"E\"] = E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Domain Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpower_from_psd_ndarray(\n",
    "    psd,\n",
    "    freqs,\n",
    "    bands=[\n",
    "        (0.5, 4, \"Delta\"),\n",
    "        (4, 8, \"Theta\"),\n",
    "        (8, 12, \"Alpha\"),\n",
    "        (12, 16, \"Sigma\"),\n",
    "        (16, 30, \"Beta\"),\n",
    "        (30, 40, \"Gamma\"),\n",
    "    ],\n",
    "    relative=True,\n",
    "):\n",
    "    \"\"\"Compute bandpowers in N-dimensional PSD.\n",
    "    This is a np-only implementation of the :py:func:`yasa.bandpower_from_psd` function,\n",
    "    which supports 1-D arrays of shape (n_freqs), or N-dimensional arays (e.g. 2-D (n_chan,\n",
    "    n_freqs) or 3-D (n_chan, n_epochs, n_freqs))\n",
    "    .. versionadded:: 0.2.0\n",
    "    Parameters\n",
    "    ----------\n",
    "    psd : :py:class:`np.ndarray`\n",
    "        Power spectral density of data, in uV^2/Hz. Must be a N-D array of shape (..., n_freqs).\n",
    "        See :py:func:`scipy.signal.welch` for more details.\n",
    "    freqs : :py:class:`numpy.ndarray`\n",
    "        Array of frequencies. Must be a 1-D array of shape (n_freqs,)\n",
    "    bands : list of tuples\n",
    "        List of frequency bands of interests. Each tuple must contain the lower and upper\n",
    "        frequencies, as well as the band name (e.g. (0.5, 4, 'Delta')).\n",
    "    relative : boolean\n",
    "        If True, bandpower is divided by the total power between the min and\n",
    "        max frequencies defined in ``band`` (default 0.5 to 40 Hz).\n",
    "    Returns\n",
    "    -------\n",
    "    bandpowers : :py:class:`numpy.ndarray`\n",
    "        Bandpower array of shape *(n_bands, ...)*.\n",
    "    \"\"\"\n",
    "    # Type checks\n",
    "    assert isinstance(bands, list), \"bands must be a list of tuple(s)\"\n",
    "    assert isinstance(relative, bool), \"relative must be a boolean\"\n",
    "\n",
    "    # Safety checks\n",
    "    freqs = np.asarray(freqs)\n",
    "    psd = np.asarray(psd)\n",
    "    assert freqs.ndim == 1, \"freqs must be a 1-D array of shape (n_freqs,)\"\n",
    "    assert psd.shape[-1] == freqs.shape[-1], \"n_freqs must be last axis of psd\"\n",
    "\n",
    "    # Extract frequencies of interest\n",
    "    all_freqs = np.hstack([[b[0], b[1]] for b in bands])\n",
    "    fmin, fmax = min(all_freqs), max(all_freqs)\n",
    "    idx_good_freq = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "    freqs = freqs[idx_good_freq]\n",
    "    res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Trim PSD to frequencies of interest\n",
    "    psd = psd[..., idx_good_freq]\n",
    "\n",
    "    # Check if there are negative values in PSD\n",
    "    if (psd < 0).any():\n",
    "        msg = (\n",
    "            \"There are negative values in PSD. This will result in incorrect \"\n",
    "            \"bandpower values. We highly recommend working with an \"\n",
    "            \"all-positive PSD. For more details, please refer to: \"\n",
    "            \"https://github.com/raphaelvallat/yasa/issues/29\"\n",
    "        )\n",
    "        logger.warning(msg)\n",
    "\n",
    "    # Calculate total power\n",
    "    total_power = simps(psd, dx=res, axis=-1)\n",
    "    total_power = total_power[np.newaxis, ...]\n",
    "\n",
    "    # Initialize empty array\n",
    "    bp = np.zeros((len(bands), *psd.shape[:-1]), dtype=np.float64)\n",
    "\n",
    "    # Enumerate over the frequency bands\n",
    "    labels = []\n",
    "    for i, band in enumerate(bands):\n",
    "        b0, b1, la = band\n",
    "        labels.append(la)\n",
    "        idx_band = np.logical_and(freqs >= b0, freqs <= b1)\n",
    "        bp[i] = simps(psd[..., idx_band], dx=res, axis=-1)\n",
    "\n",
    "    if relative:\n",
    "        bp /= total_power\n",
    "    return bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(1, 10):\n",
    "#     plt.plot(freqs, psd[int(x), :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Estimate power spectral density using Welch's method\n",
    "freqs, psd = welch(data_win, sf, nperseg=int(4 * sf))\n",
    "\n",
    "# Compute features\n",
    "## Compute featrues for normal singal (to compare w/ psd later)\n",
    "hmob, hcomp = ant.hjorth_params(data_win, axis=1)\n",
    "std_nor = np.apply_along_axis(np.std, 1, data_win, ddof=1)\n",
    "mean_nor = np.apply_along_axis(np.mean, 1, data_win)\n",
    "median_nor = np.apply_along_axis(np.median, 1, data_win)\n",
    "iqr_nor = np.apply_along_axis(sp_stats.iqr, 1, data_win, rng=(25, 75))\n",
    "skew_nor = np.apply_along_axis(sp_stats.skew, 1, data_win)\n",
    "kurt_nor = np.apply_along_axis(sp_stats.kurtosis, 1, data_win)\n",
    "hmob_nor = hmob\n",
    "hcomp_nor = hcomp\n",
    "\n",
    "## Compute featrues for PSD\n",
    "hmob, hcomp = ant.hjorth_params(psd, axis=1)\n",
    "std_psd = np.apply_along_axis(np.std, 1, psd, ddof=1)\n",
    "mean_psd = np.apply_along_axis(np.mean, 1, psd)\n",
    "median_psd = np.apply_along_axis(np.median, 1, psd)\n",
    "iqr_psd = np.apply_along_axis(sp_stats.iqr, 1, psd, rng=(25, 75))\n",
    "skew_psd = np.apply_along_axis(sp_stats.skew, 1, psd)\n",
    "kurt_psd = np.apply_along_axis(sp_stats.kurtosis, 1, psd)\n",
    "hmob_psd = hmob\n",
    "hcomp_psd = hcomp\n",
    "\n",
    "# Add features to features dataframe\n",
    "df_feat[\"E\"] = E\n",
    "df_feat[\"std_psd\"] = std_psd\n",
    "df_feat[\"mean_psd\"] = mean_psd\n",
    "df_feat[\"iqr_psd\"] = iqr_psd\n",
    "df_feat[\"skew_psd\"] = skew_psd\n",
    "df_feat[\"kurt_psd\"] = kurt_psd\n",
    "df_feat[\"hmob_psd\"] = hmob_psd\n",
    "df_feat[\"hcomp_psd\"] = hcomp_psd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0:\n",
    "        return v\n",
    "    return v / norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(std_psd), label=\"PSD STD\")\n",
    "plt.plot(normalize(std_nor), label=\"Signal STD\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"STD\")\n",
    "plt.title(\"Standard Deviation from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"std.png\", format=\"png\")\n",
    "plt.savefig(\"std.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(mean_psd), label=\"PSD mean\")\n",
    "plt.plot(normalize(mean_nor), label=\"Signal mean\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean\")\n",
    "plt.title(\"Mean from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mean.svg\", format=\"svg\")\n",
    "plt.savefig(\"mean.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(median_psd), label=\"PSD median\")\n",
    "plt.plot(normalize(median_nor), label=\"Signal median\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Median\")\n",
    "plt.title(\"Median from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"median.svg\", format=\"svg\")\n",
    "plt.savefig(\"median.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(iqr_psd), label=\"PSD iqr\")\n",
    "plt.plot(normalize(iqr_nor), label=\"Signal iqr\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"IQR\")\n",
    "plt.title(\"IQR from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"iqr.svg\", format=\"svg\")\n",
    "plt.savefig(\"iqr.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(skew_psd), label=\"PSD skew\")\n",
    "plt.plot(normalize(skew_nor), label=\"Signal skew\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Skewness\")\n",
    "plt.title(\"Skewness from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"skew.svg\", format=\"svg\")\n",
    "plt.savefig(\"skew.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(kurt_psd), label=\"PSD kurt\")\n",
    "plt.plot(normalize(kurt_nor), label=\"Signal kurt\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Kurtosis\")\n",
    "plt.title(\"Kurtosis from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"kurt.svg\", format=\"svg\")\n",
    "plt.savefig(\"kurt.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(hmob_psd), label=\"PSD hmob\")\n",
    "plt.plot(normalize(hmob_nor), label=\"Signal hmob\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Hjorth Mobility\")\n",
    "plt.title(\"Hjorth Mobility from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"hjorth_mob.svg\", format=\"svg\")\n",
    "plt.savefig(\"hjorth_mob.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(normalize(hcomp_psd), label=\"PSD hcomp\")\n",
    "plt.plot(normalize(hcomp_nor), label=\"Signal hcomp\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Hjorth Complexity\")\n",
    "plt.title(\"Hjorth Complexity from singal and it's PSD [P8_N3 L]\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"hjorth_comp.svg\", format=\"svg\")\n",
    "plt.savefig(\"hjorth_comp.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_wavelet_energy(data_set):\n",
    "    \"\"\"\n",
    "    Input : 1 * N vector\n",
    "    Output: Float with the wavelet energy of the input vector,\n",
    "    rounded to 3 decimal places.\n",
    "    \"\"\"\n",
    "    # p_sqr = [i ** 2 for i in data_set]\n",
    "    wavelet_energy = np.nansum(np.log2(np.square(data_set)))\n",
    "    return round(wavelet_energy, 3)\n",
    "\n",
    "\n",
    "wavelet_energy = np.apply_along_axis(calc_wavelet_energy, 1, data_win)\n",
    "\n",
    "# Add features to features dataframe\n",
    "df_feat[\"WEn\"] = wavelet_energy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurst Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys\n",
    "\n",
    "\n",
    "def __to_inc(x):\n",
    "    incs = x[1:] - x[:-1]\n",
    "    return incs\n",
    "\n",
    "\n",
    "def __to_pct(x):\n",
    "    pcts = x[1:] / x[:-1] - 1.0\n",
    "    return pcts\n",
    "\n",
    "\n",
    "def __get_RS(series, kind):\n",
    "    \"\"\"\n",
    "    Get rescaled range (using the range of cumulative sum\n",
    "    of deviations instead of the range of a series as in the simplified version\n",
    "    of R/S) from a time-series of values.\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        The kind of series (refer to compute_Hc docstring)\n",
    "    \"\"\"\n",
    "\n",
    "    if kind == \"random_walk\":\n",
    "        incs = __to_inc(series)\n",
    "        mean_inc = (series[-1] - series[0]) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    elif kind == \"price\":\n",
    "        incs = __to_pct(series)\n",
    "        mean_inc = np.sum(incs) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    elif kind == \"change\":\n",
    "        incs = series\n",
    "        mean_inc = np.sum(incs) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    if R == 0 or S == 0:\n",
    "        return 0  # return 0 to skip this interval due undefined R/S\n",
    "\n",
    "    return R / S\n",
    "\n",
    "\n",
    "def __get_simplified_RS(series, kind):\n",
    "    \"\"\"\n",
    "    Simplified version of rescaled range\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        The kind of series (refer to compute_Hc docstring)\n",
    "    \"\"\"\n",
    "\n",
    "    if kind == \"random_walk\":\n",
    "        incs = __to_inc(series)\n",
    "        R = max(series) - min(series)  # range in absolute values\n",
    "        S = np.std(incs, ddof=1)\n",
    "    elif kind == \"price\":\n",
    "        pcts = __to_pct(series)\n",
    "        R = max(series) / min(series) - 1.0  # range in percent\n",
    "        S = np.std(pcts, ddof=1)\n",
    "    elif kind == \"change\":\n",
    "        incs = series\n",
    "        _series = np.hstack([[0.0], np.cumsum(incs)])\n",
    "        R = max(_series) - min(_series)  # range in absolute values\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    if R == 0 or S == 0:\n",
    "        return 0  # return 0 to skip this interval due the undefined R/S ratio\n",
    "\n",
    "    return R / S\n",
    "\n",
    "\n",
    "def compute_Hc(\n",
    "    series, kind=\"random_walk\", min_window=10, max_window=None, simplified=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute H (Hurst exponent) and C according to Hurst equation:\n",
    "    E(R/S) = c * T^H\n",
    "    Refer to:\n",
    "    https://en.wikipedia.org/wiki/Hurst_exponent\n",
    "    https://en.wikipedia.org/wiki/Rescaled_range\n",
    "    https://en.wikipedia.org/wiki/Random_walk\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        Kind of series\n",
    "        possible values are 'random_walk', 'change' and 'price':\n",
    "        - 'random_walk' means that a series is a random walk with random increments;\n",
    "        - 'price' means that a series is a random walk with random multipliers;\n",
    "        - 'change' means that a series consists of random increments\n",
    "            (thus produced random walk is a cumulative sum of increments);\n",
    "    min_window : int, default 10\n",
    "        the minimal window size for R/S calculation\n",
    "    max_window : int, default is the length of series minus 1\n",
    "        the maximal window size for R/S calculation\n",
    "    simplified : bool, default True\n",
    "        whether to use the simplified or the original version of R/S calculation\n",
    "    Returns tuple of\n",
    "        H, c and data\n",
    "        where H and c — parameters or Hurst equation\n",
    "        and data is a list of 2 lists: time intervals and R/S-values for correspoding time interval\n",
    "        for further plotting log(data[0]) on X and log(data[1]) on Y\n",
    "    \"\"\"\n",
    "\n",
    "    if len(series) < 100:\n",
    "        raise ValueError(\"Series length must be greater or equal to 100\")\n",
    "\n",
    "    ndarray_likes = [np.ndarray]\n",
    "    if \"pandas.core.series\" in sys.modules.keys():\n",
    "        ndarray_likes.append(pd.core.series.Series)\n",
    "\n",
    "    # convert series to np array if series is not np array or pandas Series\n",
    "    if type(series) not in ndarray_likes:\n",
    "        series = np.array(series)\n",
    "\n",
    "    if (\n",
    "        \"pandas.core.series\" in sys.modules.keys()\n",
    "        and type(series) == pd.core.series.Series\n",
    "    ):\n",
    "        if series.isnull().values.any():\n",
    "            raise ValueError(\"Series contains NaNs\")\n",
    "        series = series.values  # convert pandas Series to np array\n",
    "    elif np.isnan(np.min(series)):\n",
    "        raise ValueError(\"Series contains NaNs\")\n",
    "\n",
    "    if simplified:\n",
    "        RS_func = __get_simplified_RS\n",
    "    else:\n",
    "        RS_func = __get_RS\n",
    "\n",
    "    err = np.geterr()\n",
    "    np.seterr(all=\"raise\")\n",
    "\n",
    "    max_window = max_window or len(series) - 1\n",
    "    window_sizes = list(\n",
    "        map(\n",
    "            lambda x: int(10**x),\n",
    "            np.arange(math.log10(min_window), math.log10(max_window), 0.25),\n",
    "        )\n",
    "    )\n",
    "    window_sizes.append(len(series))\n",
    "\n",
    "    RS = []\n",
    "    for w in window_sizes:\n",
    "        rs = []\n",
    "        for start in range(0, len(series), w):\n",
    "            if (start + w) > len(series):\n",
    "                break\n",
    "            _ = RS_func(series[start : start + w], kind)\n",
    "            if _ != 0:\n",
    "                rs.append(_)\n",
    "        RS.append(np.mean(rs))\n",
    "\n",
    "    A = np.vstack([np.log10(window_sizes), np.ones(len(RS))]).T\n",
    "    H, c = np.linalg.lstsq(A, np.log10(RS), rcond=-1)[0]\n",
    "    np.seterr(**err)\n",
    "\n",
    "    c = 10**c\n",
    "    return H, c  # , [window_sizes, RS]\n",
    "\n",
    "\n",
    "# H, c, [window_sizes, RS] = compute_Hc(data_win[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hurst_coeffs = np.apply_along_axis(compute_Hc, 1, data_win, kind=\"random_walk\")\n",
    "Hurst_H1 = Hurst_coeffs[:, 0]\n",
    "Hurst_C1 = Hurst_coeffs[:, 1]\n",
    "Hurst_coeffs = np.apply_along_axis(compute_Hc, 1, data_win, kind=\"change\")\n",
    "Hurst_H2 = Hurst_coeffs[:, 0]\n",
    "Hurst_C2 = Hurst_coeffs[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 2 points.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy.stats import iqr as IQR\n",
    "\n",
    "\n",
    "class Outlier:\n",
    "    \"\"\"\n",
    "    Find outlier in a numerical dataset with two different methods:\n",
    "        - `sd_outlier`: z-score based method\n",
    "        - `IQR_outlier`: IQR based method\n",
    "    Also allows to remove/filter-out the detected outliers with `filter` method.\n",
    "    `plot` method allows you to plot the original and filtered dataset and inspect the performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x=None):\n",
    "        self.x = x\n",
    "        self.outliers = None\n",
    "        self.outliersIndices = np.array([])\n",
    "        self.x_filt = None\n",
    "\n",
    "    def sd_outlier(self=None, x=None, axis=None, bar=3, side=\"both\"):\n",
    "        \"\"\"\n",
    "        z-score based method\n",
    "        This method will test if the numbers falls outside the three standard deviations.\n",
    "        Based on this rule, if the value is outlier, the method will return true, if not, return false.\n",
    "        \"\"\"\n",
    "\n",
    "        assert side in [\"gt\", \"lt\", \"both\"], \"Side should be `gt`, `lt` or `both`.\"\n",
    "\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        d_z = stat.zscore(x, axis=axis)\n",
    "\n",
    "        if side == \"gt\":\n",
    "            self.outliers = d_z > bar\n",
    "            return d_z > bar\n",
    "        elif side == \"lt\":\n",
    "            self.outliers = d_z < -bar\n",
    "            return d_z < -bar\n",
    "        elif side == \"both\":\n",
    "            self.outliers = np.abs(d_z) > bar\n",
    "            return np.abs(d_z) > bar\n",
    "\n",
    "    def __Q1(self, x, axis=None):\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        return np.percentile(x, 25, axis=axis)\n",
    "\n",
    "    def __Q3(self, x, axis=None):\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        return np.percentile(x, 75, axis=axis)\n",
    "\n",
    "    def IQR_outlier(self, x=None, axis=None, bar=1.5, side=\"both\"):\n",
    "        \"\"\"\n",
    "        IQR based method\n",
    "        This method will test if the value is less than q1 - 1.5 * iqr or\n",
    "        greater than q3 + 1.5 * iqr.\n",
    "        \"\"\"\n",
    "        self.method = \"IQR_outlier\"\n",
    "\n",
    "        assert side in [\"gt\", \"lt\", \"both\"], \"Side should be `gt`, `lt` or `both`.\"\n",
    "\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        d_IQR = IQR(x, axis=axis)\n",
    "        d_Q1 = self.__Q1(x, axis=axis)\n",
    "        d_Q3 = self.__Q3(x, axis=axis)\n",
    "        IQR_distance = np.multiply(d_IQR, bar)\n",
    "\n",
    "        stat_shape = list(x.shape)\n",
    "\n",
    "        if isinstance(axis, collections.Iterable):\n",
    "            for single_axis in axis:\n",
    "                stat_shape[single_axis] = 1\n",
    "        else:\n",
    "            stat_shape[axis] = 1\n",
    "\n",
    "        if side in [\"gt\", \"both\"]:\n",
    "            upper_range = d_Q3 + IQR_distance\n",
    "            upper_outlier = np.greater(x - upper_range.reshape(stat_shape), 0)\n",
    "        if side in [\"lt\", \"both\"]:\n",
    "            lower_range = d_Q1 - IQR_distance\n",
    "            lower_outlier = np.less(x - lower_range.reshape(stat_shape), 0)\n",
    "\n",
    "        if side == \"gt\":\n",
    "            self.outliers = upper_outlier\n",
    "            return upper_outlier\n",
    "        if side == \"lt\":\n",
    "            self.outliers = lower_outlier\n",
    "            return lower_outlier\n",
    "        if side == \"both\":\n",
    "            self.outliers = np.logical_or(upper_outlier, lower_outlier)\n",
    "            return np.logical_or(upper_outlier, lower_outlier)\n",
    "\n",
    "    def filter(self, x=None):\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        self.outliersIndices = np.where(self.outliers == True)\n",
    "        print(f\"Outliers are detected in {len(self.outliersIndices[0])} points.\")\n",
    "        self.x_filt = np.copy(x)\n",
    "        self.x_filt[self.outliersIndices] = np.mean(x[~self.outliers])\n",
    "        return self.x_filt, self.outliersIndices[0]\n",
    "\n",
    "    def plot(self, plot_original=False):\n",
    "        # Plot the signal and detected outliers\n",
    "        plt.figure()\n",
    "\n",
    "        if plot_original:\n",
    "            # plt.plot(np.asarray(self.x), \"ok\", label=\"Orginal Signal\")\n",
    "            plt.plot(np.asarray(self.x), \"-k\", linewidth=7, label=\"Orginal Signal\")\n",
    "\n",
    "        for outlier in self.outliersIndices[0]:\n",
    "            plt.axvline(outlier, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=4)\n",
    "\n",
    "        if plot_original:\n",
    "            plt.plot(filtered, \"-\", c=\"cyan\", linewidth=1, label=\"Filtered Signal\")\n",
    "        else:\n",
    "            plt.plot(filtered, \"-\", c=\"blue\", linewidth=1, label=\"Filtered Signal\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Test\n",
    "# Finally, if you want to filter out the outliers, use a numpy selector.\n",
    "x = [2, 3, 1, 4, 2, 3, 4, 5, 2, 3, 3, 3, 3, 4, 3, 2, 50, 60]  # data\n",
    "outlier = Outlier(np.asarray(x))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 1 points.\n"
     ]
    }
   ],
   "source": [
    "# detect and remove outliers from Hurst coefficients\n",
    "outlier = Outlier(np.asarray(Hurst_H1))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n",
    "Hurst_H1 = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 5 points.\n"
     ]
    }
   ],
   "source": [
    "# detect and remove outliers from Hurst coefficients\n",
    "outlier = Outlier(np.asarray(Hurst_C1))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n",
    "Hurst_C1 = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 3 points.\n"
     ]
    }
   ],
   "source": [
    "# detect and remove outliers from Hurst coefficients\n",
    "outlier = Outlier(np.asarray(Hurst_C2))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n",
    "Hurst_C2 = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features to features dataframe\n",
    "df_feat[\"Hurst_H1\"] = Hurst_H1\n",
    "df_feat[\"Hurst_H2\"] = Hurst_H2\n",
    "df_feat[\"Hurst_C1\"] = Hurst_C1\n",
    "df_feat[\"Hurst_C2\"] = Hurst_C2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_seq(time_series, tau, embedding_dimension):\n",
    "    \"\"\"Build a set of embedding sequences from given time series `time_series`\n",
    "    with lag `tau` and embedding dimension `embedding_dimension`.\n",
    "    Let time_series = [x(1), x(2), ... , x(N)], then for each i such that\n",
    "    1 < i <  N - (embedding_dimension - 1) * tau,\n",
    "    we build an embedding sequence,\n",
    "    Y(i) = [x(i), x(i + tau), ... , x(i + (embedding_dimension - 1) * tau)].\n",
    "    All embedding sequences are placed in a matrix Y.\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_series\n",
    "        list or numpy.ndarray\n",
    "        a time series\n",
    "    tau\n",
    "        integer\n",
    "        the lag or delay when building embedding sequence\n",
    "    embedding_dimension\n",
    "        integer\n",
    "        the embedding dimension\n",
    "    Returns\n",
    "    -------\n",
    "    Y\n",
    "        2-embedding_dimension list\n",
    "        embedding matrix built\n",
    "    Examples\n",
    "    ---------------\n",
    "    >>> import pyeeg\n",
    "    >>> a=range(0,9)\n",
    "    >>> pyeeg.embed_seq(a,1,4)\n",
    "    array([[0,  1,  2,  3],\n",
    "           [1,  2,  3,  4],\n",
    "           [2,  3,  4,  5],\n",
    "           [3,  4,  5,  6],\n",
    "           [4,  5,  6,  7],\n",
    "           [5,  6,  7,  8]])\n",
    "    >>> pyeeg.embed_seq(a,2,3)\n",
    "    array([[0,  2,  4],\n",
    "           [1,  3,  5],\n",
    "           [2,  4,  6],\n",
    "           [3,  5,  7],\n",
    "           [4,  6,  8]])\n",
    "    >>> pyeeg.embed_seq(a,4,1)\n",
    "    array([[0],\n",
    "           [1],\n",
    "           [2],\n",
    "           [3],\n",
    "           [4],\n",
    "           [5],\n",
    "           [6],\n",
    "           [7],\n",
    "           [8]])\n",
    "    \"\"\"\n",
    "    if not type(time_series) == np.ndarray:\n",
    "        typed_time_series = np.asarray(time_series)\n",
    "    else:\n",
    "        typed_time_series = time_series\n",
    "\n",
    "    shape = (\n",
    "        typed_time_series.size - tau * (embedding_dimension - 1),\n",
    "        embedding_dimension,\n",
    "    )\n",
    "\n",
    "    strides = (typed_time_series.itemsize, tau * typed_time_series.itemsize)\n",
    "\n",
    "    return np.lib.stride_tricks.as_strided(\n",
    "        typed_time_series, shape=shape, strides=strides\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Distance (MD) and Central Tendency Measure (CTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_and_ctm(X, Y):\n",
    "    # features = pd.DataFrame(columns=['radius','mean_distance','central_tendency_measure'])\n",
    "    r = 0.5\n",
    "    d = [math.sqrt(X[i] * X[i] + Y[i] * Y[i]) for i in range(0, len(X))]\n",
    "    delta = [1 if i < r else 0 for i in d]\n",
    "    d = [i for i in d if i < r]\n",
    "\n",
    "    ctm = np.sum(delta[:-2]) / (len(delta) - 2)\n",
    "    mean_distance = np.mean(d)\n",
    "\n",
    "    # features.loc[0] = [r] + [ctm] + [mean_distance]\n",
    "    return r, ctm, mean_distance\n",
    "\n",
    "\n",
    "#### Example\n",
    "y = np.random.randn(7680) * 10 + 100\n",
    "# Second Order Difference Plot (SODP)\n",
    "upper_quartile = np.percentile(y, 80)\n",
    "lower_quartile = np.percentile(y, 20)\n",
    "IQR = (upper_quartile - lower_quartile) * 1.5\n",
    "quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "y = y[np.where((y >= quartileSet[0]) & (y <= quartileSet[1]))]\n",
    "# Plotting SODP\n",
    "X = np.subtract(y[1:], y[0:-1])  # x(n+1)-x(n)\n",
    "Y = np.subtract(y[2:], y[0:-2]).tolist()  # x(n+2)-x(n-1)\n",
    "Y.extend([0])\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(X, Y, \".\")\n",
    "# Calculate MD and CTM\n",
    "_, mean_distance, central_tendency_measure = calc_mean_and_ctm(X, Y)\n",
    "\n",
    "\n",
    "def mean_ctm_wrapper(x):\n",
    "    \"\"\"\n",
    "    A wrapper function for calc_mean_and_ctm().\n",
    "    This function calculates mean and central tendancy measure for a given time series `x`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :py:class:`np.ndarray`\n",
    "        Array of time series data. Must be a 1-D array of shape `(dataPoints,)`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of `mean_distance` and `central_tendency_measure`\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "        >>> y = np.random.randn(7680)*10 + 100\n",
    "        >>> md, ctm = mean_ctm_wrapper(y)\n",
    "        (0.054281767955801107, 0.33950566436214885)\n",
    "    \"\"\"\n",
    "    upper_quartile = np.percentile(x, 80)\n",
    "    lower_quartile = np.percentile(x, 20)\n",
    "    IQR = (upper_quartile - lower_quartile) * 1.5\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    x = x[np.where((x >= quartileSet[0]) & (x <= quartileSet[1]))]\n",
    "    # plotting SODP\n",
    "    X = np.subtract(x[1:], x[0:-1])  # x(n+1)-x(n)\n",
    "    Y = np.subtract(x[2:], x[0:-2]).tolist()  # x(n+2)-x(n-1)\n",
    "    Y.extend([0])\n",
    "    # calculate MD and CTM\n",
    "    _, mean_distance, central_tendency_measure = calc_mean_and_ctm(X, Y)\n",
    "    return mean_distance, central_tendency_measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "mean_ctm = np.apply_along_axis(mean_ctm_wrapper, 1, arr=data_win)\n",
    "df_feat[\"mean_distance\"] = mean_ctm[:, 0]\n",
    "df_feat[\"central_tendency_measure\"] = mean_ctm[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrence Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding: UTF-8\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "def rec_plot(s, eps=0.10, steps=10):\n",
    "    d = pdist(s[:, None])\n",
    "    d = np.floor(d / eps)\n",
    "    d[d > steps] = steps\n",
    "    Z = squareform(d)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def moving_average(s, r=5):\n",
    "    return np.convolve(s, np.ones((r,)) / r, mode=\"valid\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate singal\n",
    "    N = 200\n",
    "    eps = 0.1\n",
    "    steps = 10\n",
    "\n",
    "    # Plot normal dist filtered with moving average\n",
    "    rn = np.random.normal(size=N)\n",
    "    rn_filtered = moving_average(rn)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.plot(rn_filtered)\n",
    "    plt.title(\"Normal\")\n",
    "    plt.subplot(212)\n",
    "    plt.imshow(rec_plot(rn_filtered, eps=eps, steps=steps))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tsallis and Renyi Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Counter(Counter):\n",
    "    def prob(self):\n",
    "        return np.array(list(self.values()))\n",
    "\n",
    "\n",
    "def symbols_to_prob(symbols):\n",
    "    \"\"\"\n",
    "    Return a dict mapping symbols to  probability.\n",
    "    input:\n",
    "    -----\n",
    "        symbols:     iterable of hashable items\n",
    "                     works well if symbols is a zip of iterables\n",
    "    \"\"\"\n",
    "    myCounter = Counter(symbols)\n",
    "\n",
    "    N = float(len(list(symbols)))  # symbols might be a zip object in python 3\n",
    "\n",
    "    for k in myCounter:\n",
    "        myCounter[k] /= N\n",
    "\n",
    "    return myCounter\n",
    "\n",
    "\n",
    "def entropy(data=None, prob=None, tol=1e-5):\n",
    "    \"\"\"\n",
    "    given a probability distribution (prob) or an interable of symbols (data) compute and\n",
    "    return its entropy\n",
    "    inputs:\n",
    "    ------\n",
    "        data:       iterable of symbols\n",
    "        prob:       iterable with probabilities\n",
    "        tol:        if prob is given, 'entropy' checks that the sum is about 1.\n",
    "                    It raises an error if abs(sum(prob)-1) >= tol\n",
    "    \"\"\"\n",
    "\n",
    "    if prob is None and data is None:\n",
    "        raise ValueError(\n",
    "            \"%s.entropy requires either 'prob' or 'data' to be defined\" % __name__\n",
    "        )\n",
    "\n",
    "    if prob is not None and data is not None:\n",
    "        raise ValueError(\n",
    "            \"%s.entropy requires only 'prob' or 'data to be given but not both\"\n",
    "            % __name__\n",
    "        )\n",
    "\n",
    "    if prob is not None and not isinstance(prob, np.ndarray):\n",
    "        raise TypeError(\"'entropy' in '%s' needs 'prob' to be an ndarray\" % __name__)\n",
    "\n",
    "    if prob is not None and abs(prob.sum() - 1) > tol:\n",
    "        raise ValueError(\"parameter 'prob' in '%s.entropy' should sum to 1\" % __name__)\n",
    "\n",
    "    if data is not None:\n",
    "        prob = symbols_to_prob(data).prob()\n",
    "\n",
    "    # compute the log2 of the probability and change any -inf by 0s\n",
    "    logProb = np.log2(prob)\n",
    "    logProb[logProb == -np.inf] = 0\n",
    "\n",
    "    # return dot product of logProb and prob\n",
    "    return -float(np.dot(prob, logProb))\n",
    "\n",
    "\n",
    "def renyi(data=None, a=2):\n",
    "    if data is not None:\n",
    "        prob = symbols_to_prob(data).prob()\n",
    "\n",
    "    # compute the log2 of the probability and change any -inf by 0s\n",
    "    powerProb = prob ** int(a)\n",
    "    logProb = np.log(powerProb)\n",
    "    # return dot product of logProb and prob\n",
    "    return -(a / (1 - a)) * (np.sum(logProb))\n",
    "\n",
    "\n",
    "def tsallis(data=None, q=2):\n",
    "    if data is not None:\n",
    "        prob = symbols_to_prob(data).prob()\n",
    "\n",
    "    # compute the log2 of the probability and change any -inf by 0s\n",
    "    powerProb = prob ** int(q)\n",
    "    # return dot product of logProb and prob\n",
    "    return (1 / (q - 1)) * (1 - np.sum(powerProb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "tsallisEnt = np.apply_along_axis(tsallis, 1, arr=data_win_rnd3)\n",
    "df_feat[\"tsallisEnt\"] = tsallisEnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a figure compraing tsallis and shannon entropy\n",
    "Ent = np.apply_along_axis(entropy, 1, arr=data_win_rnd3)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(\n",
    "    moving_average(normalize(tsallisEnt - np.mean(tsallisEnt)), 2),\n",
    "    label=\"tsallis entropy\",\n",
    "    color=\"black\",\n",
    "    linewidth=3,\n",
    ")\n",
    "plt.plot(\n",
    "    moving_average(normalize(Ent - np.mean(Ent)), 2),\n",
    "    label=\"shannon entropy\",\n",
    "    color=\"lightgreen\",\n",
    "    linewidth=0.8,\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.title(\"Compraing Tsallis and Shannon Entropies\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tsallis_compare.svg\", format=\"svg\")\n",
    "plt.savefig(\"tsallis_compare.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "renyiEnt = np.apply_along_axis(renyi, 1, arr=data_win_rnd3)\n",
    "df_feat[\"renyi\"] = renyiEnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a figure compraing renyi and shannon entropy\n",
    "Ent = np.apply_along_axis(entropy, 1, arr=data_win_rnd3)\n",
    "renyiEnt = -renyiEnt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(\n",
    "    moving_average(normalize(renyiEnt - np.mean(renyiEnt)), 2),\n",
    "    label=\"renyi entropy\",\n",
    "    color=\"black\",\n",
    "    linewidth=3,\n",
    ")\n",
    "plt.plot(\n",
    "    moving_average(normalize(Ent - np.mean(Ent)), 2),\n",
    "    label=\"shannon entropy\",\n",
    "    color=\"cyan\",\n",
    "    linewidth=1,\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.title(\"Compraing Renyi and Shannon Entropies\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"renyi_compare.svg\", format=\"svg\")\n",
    "plt.savefig(\"renyi_compare.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bubble Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manis and Sassi, “A Python Library with Fast Algorithms for Popular Entropy Definitions.”\n",
    "\n",
    "from numpy import histogram, log\n",
    "\n",
    "\n",
    "def bubble_count(x):\n",
    "    \"\"\"\n",
    "    counts the number of swaps when sorting\n",
    "    :param x: the input vector\n",
    "    :return: the total number of swaps\n",
    "    \"\"\"\n",
    "    y = 0\n",
    "    for i in range(len(x) - 1, 0, -1):\n",
    "        for j in range(i):\n",
    "            if x[j] > x[j + 1]:\n",
    "                x[j], x[j + 1] = x[j + 1], x[j]\n",
    "                y += 1\n",
    "    return y\n",
    "\n",
    "\n",
    "def complexity_count_fast(x, m):\n",
    "    \"\"\"\n",
    "    :param x: the input series\n",
    "    :param m: the dimension of the space\n",
    "    :return: the series of complexities for total number of swaps\n",
    "    \"\"\"\n",
    "\n",
    "    if len(x) < m:\n",
    "        return []\n",
    "\n",
    "    y = [bubble_count(x[:m])]\n",
    "    v = sorted(x[:m])\n",
    "\n",
    "    for i in range(m, len(x)):\n",
    "        steps = y[i - m]\n",
    "        steps -= v.index(x[i - m])\n",
    "        v.pop(v.index(x[i - m]))\n",
    "        v.append(x[i])\n",
    "        j = m - 1\n",
    "        while j > 0 and v[j] < v[j - 1]:\n",
    "            v[j], v[j - 1] = v[j - 1], v[j]\n",
    "            steps += 1\n",
    "            j -= 1\n",
    "        y.append(steps)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def renyi_int(data):\n",
    "    \"\"\"\n",
    "    returns renyi entropy (order 2) of an integer series and bin_size=1\n",
    "    (specified for the needs of bubble entropy)\n",
    "    :param data: the input series\n",
    "    :return: metric\n",
    "    \"\"\"\n",
    "    counter = [0] * (max(data) + 1)\n",
    "    for x in data:\n",
    "        counter[x] += 1\n",
    "    r = 0\n",
    "    for c in counter:\n",
    "        p = c / len(data)\n",
    "        r += p * p\n",
    "    return -log(r)\n",
    "\n",
    "\n",
    "def bubble_entropy(x, m=10):\n",
    "    \"\"\"\n",
    "    computes bubble entropy following the definition\n",
    "    :param x: the input signal\n",
    "    :param m: the dimension of the embedding space\n",
    "    :return: metric\n",
    "    \"\"\"\n",
    "    complexity = complexity_count_fast(x, m)\n",
    "    B = renyi_int(complexity) / log(1 + m * (m - 1) / 2)\n",
    "\n",
    "    complexity = complexity_count_fast(x, m + 1)\n",
    "    A = renyi_int(complexity) / log(1 + (m + 1) * m / 2)\n",
    "\n",
    "    return A - B\n",
    "\n",
    "\n",
    "def bubble_entropy_2(x, m=10):\n",
    "    \"\"\"\n",
    "    computes bubble entropy following the definition\n",
    "    :param x: the input signal\n",
    "    :param m: the dimension of the embedding space\n",
    "    :return: metric\n",
    "    \"\"\"\n",
    "    complexity = complexity_count_fast(x, m)\n",
    "    B = renyi_int(complexity) / log(1 + m * (m - 1) / 2)\n",
    "\n",
    "    complexity = complexity_count_fast(x, m + 2)\n",
    "    A = renyi_int(complexity) / log(1 + (m + 2) * (m + 1) / 2)\n",
    "\n",
    "    return A - B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "bubbleEnt1 = np.apply_along_axis(bubble_entropy, 1, arr=data_win_rnd3)\n",
    "df_feat[\"bubbleEnt1\"] = bubbleEnt1\n",
    "\n",
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "bubbleEnt2 = np.apply_along_axis(bubble_entropy_2, 1, arr=data_win_rnd3)\n",
    "df_feat[\"bubbleEnt2\"] = bubbleEnt2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    moving_average(normalize(bubbleEnt1 - np.mean(bubbleEnt1)), 2),\n",
    "    label=\"Bubble entropy 1\",\n",
    "    color=\"dodgerblue\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "fig.suptitle(\"Compraing Bubble Entropy 1 and 2 (Normalized)\")\n",
    "plt.plot(\n",
    "    moving_average(normalize(bubbleEnt2 - np.mean(bubbleEnt2)), 2),\n",
    "    label=\"Bubble entropy 2\",\n",
    "    color=\"darkorchid\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"bubble_entropy.svg\", format=\"svg\")\n",
    "plt.savefig(\"bubble_entropy.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirhosseindaraie/miniconda3/envs/mne/lib/python3.9/site-packages/scipy/stats/_entropy.py:293: RuntimeWarning: divide by zero encountered in log\n",
      "  logs = np.log(n/(2*m) * differences)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import differential_entropy\n",
    "\n",
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "diffEnt = np.apply_along_axis(differential_entropy, 1, arr=data_win_rnd3)\n",
    "diffEntMean = np.mean(diffEnt[~(diffEnt == -np.inf)])\n",
    "diffEnt[diffEnt == -np.inf] = diffEntMean\n",
    "df_feat[\"diffEnt\"] = diffEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    moving_average(normalize(diffEnt - np.mean(diffEnt)), 2),\n",
    "    label=\"Differential Entropy\",\n",
    "    color=\"darkgreen\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.title(\"Differential Entropy (Normalized)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"differential_entropy.svg\", format=\"svg\")\n",
    "plt.savefig(\"differential_entropy.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell took ~11 min to execute\n",
    "\n",
    "# pip install EntropyHub\n",
    "import EntropyHub as enth\n",
    "\n",
    "\n",
    "def fuzzEnt_f(x, m=1, tau=1):\n",
    "    \"\"\"\n",
    "    A wrapper function for EntropyHub.FuzzEn() Function\n",
    "\n",
    "    Input\n",
    "    ------\n",
    "    `sig`: Time series signal, a vector of length > 10.\n",
    "    `m`: Embedding dimension, a positive integer (for embbeding dim).\n",
    "    `tau`: Time delay, a positive integer (for embbeding dim).\n",
    "    `Fx`: Type of fuzzy function for distance transformation, one of the following strings\n",
    "    Return\n",
    "    ------\n",
    "    `Fuzz`: Fuzzy entropy estimates for each embedding dimension 1:m.\n",
    "    `Ps1`: The average fuzzy distances for embedding dimensions 1:m.\n",
    "    `Ps2`: The average fuzzy distances for embedding dimensions 2:m+1.\n",
    "    Example\n",
    "    -------\n",
    "    >>> [Fuzz, Ps1, Ps2] = enth.FuzzEn(x, m=1, tau=1)\n",
    "    Source\n",
    "    ------\n",
    "    https://github.com/MattWillFlood/EntropyHub/blob/main/Guide/EntropyHub%20Guide.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    [Fuzz, Ps1, Ps2] = enth.FuzzEn(x, m=m, tau=tau)\n",
    "    return Fuzz[0]\n",
    "\n",
    "\n",
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "fuzzEnt = np.apply_along_axis(fuzzEnt_f, 1, arr=data_win_rnd3)\n",
    "df_feat[\"fuzzEnt\"] = fuzzEnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    moving_average(normalize(fuzzEnt - np.mean(fuzzEnt)), 2),\n",
    "    label=\"Fuzzy Entropy\",\n",
    "    color=\"mediumblue\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.title(\"Fuzzy Entropy (Normalized)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fuzzy_entropy.svg\", format=\"svg\")\n",
    "plt.savefig(\"fuzzy_entropy.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write feature object to a comma-separated values (csv) file\n",
    "df_feat.to_csv(f\"feature/{fname} {lr}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 79)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Load hypnogram\n",
    "location_hypno = \"/Users/amirhosseindaraie/Desktop/data/synced-hypnos\"\n",
    "hypno_30s = np.loadtxt(f\"{location_hypno}/p8n3_synced.txt\")[:, 0]\n",
    "\n",
    "# Extract sorted F-values\n",
    "# Compute the ANOVA F-value for the provided sample.\n",
    "fvals = pd.Series(\n",
    "    f_classif(X=df_feat, y=hypno_30s)[0], index=df_feat.columns\n",
    ").sort_values()\n",
    "\n",
    "# Plot features ranking\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(y=fvals.index, x=fvals, palette=\"RdYlGn\")\n",
    "plt.xlabel(\"F-values\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_3481/1191782619.py:161: RuntimeWarning: divide by zero encountered in log\n",
      "  d_ij = numpy.sum(numpy.log(neighbor_dists.data), axis=1)\n",
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_3481/1191782619.py:166: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  [m, c] = numpy.linalg.lstsq(X, mean_d)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot hypnogram and a feature\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "hypno = pd.Series(hypno_30s).map({-1: -1, 0: 0, 1: 2, 2: 3, 3: 4, 4: 1}).values\n",
    "hypno_rem = np.ma.masked_not_equal(hypno, 1)\n",
    "\n",
    "# Plot the hypnogram\n",
    "ax1.step(times, -1 * hypno, color=\"k\", lw=1.5)\n",
    "ax1.step(times, -1 * hypno_rem, color=\"r\", lw=2.5)\n",
    "ax1.set_yticks([0, -1, -2, -3, -4])\n",
    "ax1.set_yticklabels([\"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "ax1.set_ylim(-4.5, 0.5)\n",
    "ax1.set_ylabel(\"Sleep stage\")\n",
    "\n",
    "# Plot the non-linear feature\n",
    "ax2.plot(times, df_feat[\"perm_entropy\"])\n",
    "ax2.set_ylabel(\"Permutation Entropy\")\n",
    "# ax2.set_ylabel('Higuchi Fractal Dimension')\n",
    "ax2.set_xlabel(\"Time [minutes]\")\n",
    "\n",
    "ax2.set_xlim(0, times[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9461a3eb0cbef873800a78c94f0b6f375dc71a03d464463d7b611af82b6cd16"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
