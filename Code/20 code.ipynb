{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Plotting, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from mne.filter import resample, filter_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lspopt import spectrogram_lspopt\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "\n",
    "import logging\n",
    "LOGGING_TYPES = dict(DEBUG=logging.DEBUG, INFO=logging.INFO, WARNING=logging.WARNING,\n",
    "                     ERROR=logging.ERROR, CRITICAL=logging.CRITICAL)\n",
    "logger = logging.getLogger('yasa')\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypno</th>\n",
       "      <th>df_feat</th>\n",
       "      <th>eeg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P18_N3 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N3 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P18_N2 R</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P18_N2 R.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P17_N2 L</th>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/synced-h...</td>\n",
       "      <td>feature/P17_N2 L.csv</td>\n",
       "      <td>/Users/amirhosseindaraie/Desktop/data/autoscor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      hypno  \\\n",
       "name                                                          \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/synced-h...   \n",
       "\n",
       "                       df_feat  \\\n",
       "name                             \n",
       "P18_N3 L  feature/P18_N3 L.csv   \n",
       "P18_N2 R  feature/P18_N2 R.csv   \n",
       "P17_N2 L  feature/P17_N2 L.csv   \n",
       "\n",
       "                                                        eeg  \n",
       "name                                                         \n",
       "P18_N3 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P18_N2 R  /Users/amirhosseindaraie/Desktop/data/autoscor...  \n",
       "P17_N2 L  /Users/amirhosseindaraie/Desktop/data/autoscor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load reference_df     \n",
    "reference_df = pd.read_csv(\"reference_df.csv\", index_col=\"name\")\n",
    "reference_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>sb</th>\n",
       "      <th>ag</th>\n",
       "      <th>sg</th>\n",
       "      <th>lziv</th>\n",
       "      <th>iqr</th>\n",
       "      <th>bs</th>\n",
       "      <th>ta_b</th>\n",
       "      <th>gs</th>\n",
       "      <th>alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>mean_psd</th>\n",
       "      <th>E</th>\n",
       "      <th>WEn</th>\n",
       "      <th>ds</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>diffEnt</th>\n",
       "      <th>renyi</th>\n",
       "      <th>skew</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_classif</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiSqr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ab   sb   ag   sg  lziv  iqr   bs  ta_b    gs  alpha  ...  \\\n",
       "method_name                                                         ...   \n",
       "f_classif    2.0  1.0  3.0  4.0   6.0  9.0  7.0   5.0  15.0    8.0  ...   \n",
       "chiSqr       1.0  2.0  4.0  8.0   7.0  6.0  9.0  12.0   3.0   10.0  ...   \n",
       "\n",
       "             median  mean_psd     E   WEn    ds  mean_distance  diffEnt  \\\n",
       "method_name                                                               \n",
       "f_classif      61.0      64.0  66.0  62.0  71.0           63.0     67.0   \n",
       "chiSqr         69.0      66.0  65.0  70.0  62.0           71.0     68.0   \n",
       "\n",
       "             renyi  skew  mean  \n",
       "method_name                     \n",
       "f_classif     69.0  72.0  73.0  \n",
       "chiSqr        67.0  72.0  73.0  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv    \n",
    "rankings_df = pd.read_csv(\"rankings_df aug.csv\", index_col=\"method_name\")\n",
    "rankings_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on 60 nights, test of 1 night\n",
    "(1560*60 x 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import kruskal\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the dataset to train and test + shuffle each night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def confmat_f(confmat):\n",
    "    \"\"\"\n",
    "    Using:\n",
    "    _______\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "\n",
    "    confmat = confusion_matrix(y_test, y_pred)\n",
    "    confmat_f(confmat)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va=\"center\", ha=\"center\")\n",
    "    ax.set(\n",
    "        xticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        xticks=range(5),\n",
    "        yticklabels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"],\n",
    "        yticks=range(5),\n",
    "    )\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.xaxis.labelpad = 15\n",
    "    ax.xaxis.set_tick_params(labeltop=True)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion Matrix\", y=-0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confmat-5.png\")\n",
    "    plt.savefig(\"confmat-5.svg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_test_split(test_prop=0.2, n_feat=40):\n",
    "    \"\"\"\n",
    "    Using:\n",
    "    ______\n",
    "    X_train_std, X_test_std, y_train, y_test, idx_train, idx_test = train_test_split(0.05, n_feat=50)\n",
    "\n",
    "    \"\"\"\n",
    "    idx_all_recordings = np.random.permutation(len(reference_df))\n",
    "    idx_train_recordings = idx_all_recordings[: -int(test_prop * 61)]\n",
    "    idx_test_recordings = idx_all_recordings[-int(test_prop * 61) :]\n",
    "    print(\">>>>>>>> train recordings (index): \")\n",
    "    print(idx_train_recordings)\n",
    "    print(\">>>>>>>> test recordings: \")\n",
    "    print(idx_test_recordings)\n",
    "\n",
    "    df_feat_X_train = np.array([])\n",
    "    df_feat_X_test = np.array([])\n",
    "    hypno_y_train = np.array([])\n",
    "    hypno_y_test = np.array([])\n",
    "\n",
    "    columns = rankings_df.columns[:n_feat]  # for selecting top n_feat columns\n",
    "\n",
    "    # to loop over all recording files:\n",
    "    for i in idx_train_recordings:\n",
    "        ### to load augmented hypnos for train:\n",
    "        name = reference_df.iloc[i].name\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s_loc = hypno_30s_loc.split(\".\")[0] + \" aug.txt\"\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc, delimiter=\"\\n\")\n",
    "\n",
    "        ### to load features of augmented eeg for train:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat_loc = df_feat_loc.split(\".\")[0] + \" aug.csv\"\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top n_feat ranks columns\n",
    "        df_feat = df_feat[columns]\n",
    "\n",
    "        ### shuffle X\n",
    "        permut = np.random.permutation(df_feat.shape[0])\n",
    "        df_feat = df_feat.iloc[permut]\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_train_recordings[0]:\n",
    "            df_feat_X_train = df_feat.to_numpy()\n",
    "        else:\n",
    "            df_feat_X_train = np.vstack([df_feat_X_train, df_feat.to_numpy()])\n",
    "\n",
    "        ### shuffle y\n",
    "        hypno_30s = hypno_30s[permut]\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_train = np.append(hypno_y_train, hypno_30s)\n",
    "\n",
    "    for i in idx_test_recordings:\n",
    "        ### to load features for test:\n",
    "        df_feat_loc = reference_df.iloc[i].df_feat\n",
    "        df_feat = pd.read_csv(df_feat_loc, index_col=False)\n",
    "\n",
    "        ### to load labels for test:\n",
    "        hypno_30s_loc = reference_df.iloc[i].hypno\n",
    "        hypno_30s = np.loadtxt(hypno_30s_loc)[:, 0]\n",
    "\n",
    "        df_feat = df_feat.replace(\n",
    "            [np.inf, -np.inf], 0\n",
    "        )  # Replacing infinite values in features\n",
    "\n",
    "        ### select top n_feat ranks columns\n",
    "        df_feat = df_feat[columns].to_numpy()\n",
    "\n",
    "        df_feat = df_feat[hypno_30s != -1]  # do not process -1/artifact\n",
    "        hypno_30s = hypno_30s[hypno_30s != -1]  # do not process -1/artifact\n",
    "        hypno_30s[hypno_30s == 5] = 4  # replace 5 with 4\n",
    "\n",
    "        ### to load features for train: append df_feat to df_feat_X_train\n",
    "        if i == idx_test_recordings[0]:\n",
    "            df_feat_X_test = df_feat\n",
    "        else:\n",
    "            df_feat_X_test = np.vstack([df_feat_X_test, df_feat])\n",
    "\n",
    "        ### to load labels for train: append hypno to hypno_y_train\n",
    "        hypno_y_test = np.append(hypno_y_test, hypno_30s)\n",
    "\n",
    "    print(f\"Train set: X={df_feat_X_train.shape} y={hypno_y_train.shape}\")\n",
    "    print(f\"Test set: X={df_feat_X_test.shape} y={hypno_y_test.shape}\")\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # we will standardize the columns in dataset before we feed them to a classifier\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(df_feat_X_train)  # first fit all the dataset\n",
    "    X_train_std = sc.transform(df_feat_X_train)  # then transform train\n",
    "    X_test_std = sc.transform(df_feat_X_test)  # and test\n",
    "\n",
    "    return (\n",
    "        X_train_std,\n",
    "        X_test_std,\n",
    "        hypno_y_train,\n",
    "        hypno_y_test,\n",
    "        idx_train_recordings,\n",
    "        idx_test_recordings,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>> train recordings (index): \n",
      "[ 2 21 15 46 38  9 29 11 57 55 27 58 22 19 53 24  7 41 12 26 13 48  1 37\n",
      " 52  0 51 44 25 60  8 42 59 35 36  3  4 34 54 50 49 56 23 39  5 47 40 28\n",
      " 32 33 17 31 14 30 18]\n",
      ">>>>>>>> test recordings: \n",
      "[16  6 43 45 20 10]\n",
      "Train set: X=(108254, 35) y=(108254,)\n",
      "Test set: X=(4491, 35) y=(4491,)\n",
      "Misclassified examples: 1071\n",
      "Accuracy: 0.762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_std, X_test_std, y_train, y_test, train_idx, test_idx = train_test_split(test_prop=0.1, n_feat=35)\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", C=10, random_state=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print(\"Misclassified examples: %d\" % (y_test != y_pred).sum())\n",
    "print(\"Accuracy: %.3f\" % accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.64      0.58       177\n",
      "         1.0       0.29      0.30      0.30       284\n",
      "         2.0       0.92      0.75      0.82      2419\n",
      "         3.0       0.67      0.83      0.74       731\n",
      "         4.0       0.72      0.91      0.81       880\n",
      "\n",
      "    accuracy                           0.76      4491\n",
      "   macro avg       0.63      0.69      0.65      4491\n",
      "weighted avg       0.79      0.76      0.76      4491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_1432/2331383249.py:22: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set(\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "confmat = confusion_matrix(y_test, y_pred)\n",
    "confmat_f(confmat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I want to take the initial (not augmented part of EEG singals and use them as test set). So I don't want to use the augmented EEG on the testing phase of my models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot test results in hypnogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(\n",
    "    data,\n",
    "    sf,\n",
    "    hypno=None,\n",
    "    hypno_pred=None,\n",
    "    win_sec=30,\n",
    "    fmin=0.5,\n",
    "    fmax=25,\n",
    "    trimperc=2.5,\n",
    "    cmap=\"RdBu_r\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a full-night multi-taper spectrogram, optionally with the hypnogram on top.\n",
    "    For more details, please refer to the `Jupyter notebook\n",
    "    <https://github.com/raphaelvallat/yasa/blob/master/notebooks/10_spectrogram.ipynb>`_\n",
    "    .. versionadded:: 0.1.8\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : :py:class:`numpy.ndarray`\n",
    "        Single-channel EEG data. Must be a 1D NumPy array.\n",
    "    sf : float\n",
    "        The sampling frequency of data AND the hypnogram.\n",
    "    hypno : array_like\n",
    "        Sleep stage (hypnogram), optional.\n",
    "        The hypnogram must have the exact same number of samples as ``data``.\n",
    "        To upsample your hypnogram, please refer to :py:func:`yasa.hypno_upsample_to_data`.\n",
    "        .. note::\n",
    "            The default hypnogram format in YASA is a 1D integer\n",
    "            vector where:\n",
    "            - -2 = Unscored\n",
    "            - -1 = Artefact / Movement\n",
    "            - 0 = Wake\n",
    "            - 1 = N1 sleep\n",
    "            - 2 = N2 sleep\n",
    "            - 3 = N3 sleep\n",
    "            - 4 = REM sleep\n",
    "    win_sec : int or float\n",
    "        The length of the sliding window, in seconds, used for multitaper PSD\n",
    "        calculation. Default is 30 seconds. Note that ``data`` must be at least\n",
    "        twice longer than ``win_sec`` (e.g. 60 seconds).\n",
    "    fmin, fmax : int or float\n",
    "        The lower and upper frequency of the spectrogram. Default 0.5 to 25 Hz.\n",
    "    trimperc : int or float\n",
    "        The amount of data to trim on both ends of the distribution when\n",
    "        normalizing the colormap. This parameter directly impacts the\n",
    "        contrast of the spectrogram plot (higher values = higher contrast).\n",
    "        Default is 2.5, meaning that the min and max of the colormap\n",
    "        are defined as the 2.5 and 97.5 percentiles of the spectrogram.\n",
    "    cmap : str\n",
    "        Colormap. Default to 'RdBu_r'.\n",
    "    Returns\n",
    "    -------\n",
    "    fig : :py:class:`matplotlib.figure.Figure`\n",
    "        Matplotlib Figure\n",
    "    Examples\n",
    "    --------\n",
    "    1. Full-night multitaper spectrogram on Cz, no hypnogram\n",
    "    .. plot::\n",
    "        >>> import yasa\n",
    "        >>> import numpy as np\n",
    "        >>> # In the next 5 lines, we're loading the data from GitHub.\n",
    "        >>> import requests\n",
    "        >>> from io import BytesIO\n",
    "        >>> r = requests.get('https://github.com/raphaelvallat/yasa/raw/master/notebooks/data_full_6hrs_100Hz_Cz%2BFz%2BPz.npz', stream=True)\n",
    "        >>> npz = np.load(BytesIO(r.raw.read()))\n",
    "        >>> data = npz.get('data')[0, :]\n",
    "        >>> sf = 100\n",
    "        >>> fig = yasa.plot_spectrogram(data, sf)\n",
    "    2. Full-night multitaper spectrogram on Cz with the hypnogram on top\n",
    "    .. plot::\n",
    "        >>> import yasa\n",
    "        >>> import numpy as np\n",
    "        >>> # In the next lines, we're loading the data from GitHub.\n",
    "        >>> import requests\n",
    "        >>> from io import BytesIO\n",
    "        >>> r = requests.get('https://github.com/raphaelvallat/yasa/raw/master/notebooks/data_full_6hrs_100Hz_Cz%2BFz%2BPz.npz', stream=True)\n",
    "        >>> npz = np.load(BytesIO(r.raw.read()))\n",
    "        >>> data = npz.get('data')[0, :]\n",
    "        >>> sf = 100\n",
    "        >>> # Load the 30-sec hypnogram and upsample to data\n",
    "        >>> hypno = np.loadtxt('https://raw.githubusercontent.com/raphaelvallat/yasa/master/notebooks/data_full_6hrs_100Hz_hypno_30s.txt')\n",
    "        >>> hypno = yasa.hypno_upsample_to_data(hypno, 1/30, data, sf)\n",
    "        >>> fig = yasa.plot_spectrogram(data, sf, hypno, cmap='Spectral_r')\n",
    "    \"\"\"\n",
    "    # Increase font size while preserving original\n",
    "    old_fontsize = plt.rcParams[\"font.size\"]\n",
    "    plt.rcParams.update({\"font.size\": 13})\n",
    "\n",
    "    # Safety checks\n",
    "    assert isinstance(data, np.ndarray), \"Data must be a 1D NumPy array.\"\n",
    "    assert isinstance(sf, (int, float)), \"sf must be int or float.\"\n",
    "    assert data.ndim == 1, \"Data must be a 1D (single-channel) NumPy array.\"\n",
    "    assert isinstance(win_sec, (int, float)), \"win_sec must be int or float.\"\n",
    "    assert isinstance(fmin, (int, float)), \"fmin must be int or float.\"\n",
    "    assert isinstance(fmax, (int, float)), \"fmax must be int or float.\"\n",
    "    assert fmin < fmax, \"fmin must be strictly inferior to fmax.\"\n",
    "    assert fmax < sf / 2, \"fmax must be less than Nyquist (sf / 2).\"\n",
    "\n",
    "    # Calculate multi-taper spectrogram\n",
    "    nperseg = int(win_sec * sf)\n",
    "    assert data.size > 2 * nperseg, \"Data length must be at least 2 * win_sec.\"\n",
    "    f, t, Sxx = spectrogram_lspopt(data, sf, nperseg=nperseg, noverlap=0)\n",
    "    Sxx = 10 * np.log10(Sxx)  # Convert uV^2 / Hz --> dB / Hz\n",
    "\n",
    "    # Select only relevant frequencies (up to 30 Hz)\n",
    "    good_freqs = np.logical_and(f >= fmin, f <= fmax)\n",
    "    Sxx = Sxx[good_freqs, :]\n",
    "    f = f[good_freqs]\n",
    "    t /= 3600  # Convert t to hours\n",
    "\n",
    "    # Normalization\n",
    "    vmin, vmax = np.percentile(Sxx, [0 + trimperc, 100 - trimperc])\n",
    "    norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    if hypno is None:\n",
    "        fig, ax = plt.subplots(nrows=1, figsize=(12, 4))\n",
    "        im = ax.pcolormesh(\n",
    "            t, f, Sxx, norm=norm, cmap=cmap, antialiased=True, shading=\"auto\"\n",
    "        )\n",
    "        ax.set_xlim(0, t.max())\n",
    "        ax.set_ylabel(\"Frequency [Hz]\")\n",
    "        ax.set_xlabel(\"Time [hrs]\")\n",
    "\n",
    "        # Add colorbar\n",
    "        cbar = fig.colorbar(im, ax=ax, shrink=0.95, fraction=0.1, aspect=25)\n",
    "        cbar.ax.set_ylabel(\"Log Power (dB / Hz)\", rotation=270, labelpad=20)\n",
    "        return fig\n",
    "    elif (hypno is not None) and (hypno_pred is None):\n",
    "        hypno = np.asarray(hypno).astype(int)\n",
    "        assert hypno.ndim == 1, \"Hypno must be 1D.\"\n",
    "        assert hypno.size == data.size, \"Hypno must have the same sf as data.\"\n",
    "        t_hyp = np.arange(hypno.size) / (sf * 3600)\n",
    "        # Make sure that REM is displayed after Wake\n",
    "        hypno = (\n",
    "            pd.Series(hypno).map({-2: -2, -1: -1, 0: 0, 1: 2, 2: 3, 3: 4, 4: 1}).values\n",
    "        )\n",
    "        hypno_rem = np.ma.masked_not_equal(hypno, 1)\n",
    "\n",
    "        fig, (ax0, ax1) = plt.subplots(\n",
    "            nrows=2, figsize=(12, 6), gridspec_kw={\"height_ratios\": [1, 2]}\n",
    "        )\n",
    "        plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "        # Hypnogram (top axis)\n",
    "        ax0.step(t_hyp, -1 * hypno, color=\"k\")\n",
    "        ax0.step(t_hyp, -1 * hypno_rem, color=\"r\")\n",
    "        if -2 in hypno and -1 in hypno:\n",
    "            # Both Unscored and Artefacts are present\n",
    "            ax0.set_yticks([2, 1, 0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"Uns\", \"Art\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 2.5)\n",
    "        elif -2 in hypno and -1 not in hypno:\n",
    "            # Only Unscored are present\n",
    "            ax0.set_yticks([2, 0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"Uns\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 2.5)\n",
    "\n",
    "        elif -2 not in hypno and -1 in hypno:\n",
    "            # Only Artefacts are present\n",
    "            ax0.set_yticks([1, 0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"Art\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 1.5)\n",
    "        else:\n",
    "            # No artefacts or Unscored\n",
    "            ax0.set_yticks([0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 0.5)\n",
    "        ax0.set_xlim(0, t_hyp.max())\n",
    "        ax0.set_ylabel(\"Stage\")\n",
    "        ax0.xaxis.set_visible(False)\n",
    "        ax0.spines[\"right\"].set_visible(False)\n",
    "        ax0.spines[\"top\"].set_visible(False)\n",
    "\n",
    "        # Spectrogram (bottom axis)\n",
    "        im = ax1.pcolormesh(\n",
    "            t, f, Sxx, norm=norm, cmap=cmap, antialiased=True, shading=\"auto\"\n",
    "        )\n",
    "        ax1.set_xlim(0, t.max())\n",
    "        ax1.set_ylabel(\"Frequency [Hz]\")\n",
    "        ax1.set_xlabel(\"Time [hrs]\")\n",
    "\n",
    "        # Revert font-size\n",
    "        plt.rcParams.update({\"font.size\": old_fontsize})\n",
    "        return fig\n",
    "    elif (hypno is not None) and (hypno_pred is not None):\n",
    "        hypno_pred = np.asarray(hypno_pred).astype(int)\n",
    "        hypno = np.asarray(hypno).astype(int)\n",
    "        assert hypno.ndim == 1, \"Hypno must be 1D.\"\n",
    "        assert hypno.size == data.size, \"Hypno must have the same sf as data.\"\n",
    "        assert hypno_pred.ndim == 1, \"hypno_pred must be 1D.\"\n",
    "        assert hypno_pred.size == data.size, \"hypno_pred must have the same sf as data.\"\n",
    "        t_hyp = np.arange(hypno.size) / (sf * 3600)\n",
    "        t_hyp_pred = np.arange(hypno_pred.size) / (sf * 3600)\n",
    "        # Make sure that REM is displayed after Wake\n",
    "        hypno = (\n",
    "            pd.Series(hypno).map({-2: -2, -1: -1, 0: 0, 1: 2, 2: 3, 3: 4, 4: 1}).values\n",
    "        )\n",
    "        hypno_pred = (\n",
    "            pd.Series(hypno_pred)\n",
    "            .map({-2: -2, -1: -1, 0: 0, 1: 2, 2: 3, 3: 4, 4: 1})\n",
    "            .values\n",
    "        )\n",
    "        hypno_rem = np.ma.masked_not_equal(hypno, 1)\n",
    "        hypno_pred_rem = np.ma.masked_not_equal(hypno_pred, 1)\n",
    "\n",
    "        fig, (ax0, ax1, ax2) = plt.subplots(\n",
    "            nrows=3, figsize=(12, 6), gridspec_kw={\"height_ratios\": [1, 1, 2]}\n",
    "        )\n",
    "        plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "        # Hypnogram (top axis)\n",
    "        ax0.step(t_hyp, -1 * hypno, color=\"k\")\n",
    "        ax0.step(t_hyp, -1 * hypno_rem, color=\"r\")\n",
    "        if -2 in hypno and -1 in hypno:\n",
    "            # Both Unscored and Artefacts are present\n",
    "            ax0.set_yticks([2, 1, 0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"Uns\", \"Art\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 2.5)\n",
    "        elif -2 in hypno and -1 not in hypno:\n",
    "            # Only Unscored are present\n",
    "            ax0.set_yticks([2, 0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"Uns\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 2.5)\n",
    "\n",
    "        elif -2 not in hypno and -1 in hypno:\n",
    "            # Only Artefacts are present\n",
    "            ax0.set_yticks([1, 0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"Art\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 1.5)\n",
    "        else:\n",
    "            # No artefacts or Unscored\n",
    "            ax0.set_yticks([0, -1, -2, -3, -4])\n",
    "            ax0.set_yticklabels([\"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax0.set_ylim(-4.5, 0.5)\n",
    "        ax0.set_xlim(0, t_hyp.max())\n",
    "        ax0.set_ylabel(\"Original \\nstage\", fontsize=12)\n",
    "        ax0.xaxis.set_visible(False)\n",
    "        ax0.spines[\"right\"].set_visible(False)\n",
    "        ax0.spines[\"top\"].set_visible(False)\n",
    "\n",
    "        # Hypnogram Pred (middle axis)\n",
    "        ax1.step(t_hyp_pred, -1 * hypno_pred, color=\"k\")\n",
    "        ax1.step(t_hyp_pred, -1 * hypno_pred_rem, color=\"r\")\n",
    "        if -2 in hypno_pred and -1 in hypno_pred:\n",
    "            # Both Unscored and Artefacts are present\n",
    "            ax1.set_yticks([2, 1, 0, -1, -2, -3, -4])\n",
    "            ax1.set_yticklabels([\"Uns\", \"Art\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax1.set_ylim(-4.5, 2.5)\n",
    "        elif -2 in hypno_pred and -1 not in hypno_pred:\n",
    "            # Only Unscored are present\n",
    "            ax1.set_yticks([2, 0, -1, -2, -3, -4])\n",
    "            ax1.set_yticklabels([\"Uns\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax1.set_ylim(-4.5, 2.5)\n",
    "\n",
    "        elif -2 not in hypno_pred and -1 in hypno_pred:\n",
    "            # Only Artefacts are present\n",
    "            ax1.set_yticks([1, 0, -1, -2, -3, -4])\n",
    "            ax1.set_yticklabels([\"Art\", \"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax1.set_ylim(-4.5, 1.5)\n",
    "        else:\n",
    "            # No artefacts or Unscored\n",
    "            ax1.set_yticks([0, -1, -2, -3, -4])\n",
    "            ax1.set_yticklabels([\"W\", \"R\", \"N1\", \"N2\", \"N3\"])\n",
    "            ax1.set_ylim(-4.5, 0.5)\n",
    "        ax1.set_xlim(0, t_hyp_pred.max())\n",
    "        ax1.set_ylabel(\"Predicted \\nstage\", fontsize=12)\n",
    "        ax1.xaxis.set_visible(False)\n",
    "        ax1.spines[\"right\"].set_visible(False)\n",
    "        ax1.spines[\"top\"].set_visible(False)\n",
    "\n",
    "        # Spectrogram (bottom axis)\n",
    "        im = ax2.pcolormesh(\n",
    "            t, f, Sxx, norm=norm, cmap=cmap, antialiased=True, shading=\"auto\"\n",
    "        )\n",
    "        ax2.set_xlim(0, t.max())\n",
    "        ax2.set_ylabel(\"Frequency [Hz]\")\n",
    "        ax2.set_xlabel(\"Time [hrs]\")\n",
    "\n",
    "        # Revert font-size\n",
    "        plt.rcParams.update({\"font.size\": old_fontsize})\n",
    "        return fig\n",
    "\n",
    "\n",
    "def format_seconds_to_hhmmss(seconds):\n",
    "    hours = seconds // (60 * 60)\n",
    "    seconds %= 60 * 60\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return \"%02i:%02i:%02i\" % (hours, minutes, seconds)\n",
    "\n",
    "\n",
    "def set_log_level(verbose=None):\n",
    "    \"\"\"Convenience function for setting the logging level.\n",
    "    This function comes from the PySurfer package. See :\n",
    "    https://github.com/nipy/PySurfer/blob/master/surfer/utils.py\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool, str, int, or None\n",
    "        The verbosity of messages to print. If a str, it can be either\n",
    "        PROFILER, DEBUG, INFO, WARNING, ERROR, or CRITICAL.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"yasa\")\n",
    "    if isinstance(verbose, bool):\n",
    "        verbose = \"INFO\" if verbose else \"WARNING\"\n",
    "    if isinstance(verbose, str):\n",
    "        if verbose.upper() in LOGGING_TYPES:\n",
    "            verbose = verbose.upper()\n",
    "            verbose = LOGGING_TYPES[verbose]\n",
    "            logger.setLevel(verbose)\n",
    "        else:\n",
    "            raise ValueError(\"verbose must be in %s\" % \", \".join(LOGGING_TYPES))\n",
    "\n",
    "\n",
    "def hypno_upsample_to_data(hypno, sf_hypno, data, sf_data=None, verbose=True):\n",
    "    \"\"\"Upsample an hypnogram to a given sampling frequency and fit the\n",
    "    resulting hypnogram to corresponding EEG data, such that the hypnogram\n",
    "    and EEG data have the exact same number of samples.\n",
    "    .. versionadded:: 0.1.5\n",
    "    Parameters\n",
    "    ----------\n",
    "    hypno : array_like\n",
    "        The sleep staging (hypnogram) 1D array.\n",
    "    sf_hypno : float\n",
    "        The current sampling frequency of the hypnogram, in Hz, e.g.\n",
    "        * 1/30 = 1 value per each 30 seconds of EEG data,\n",
    "        * 1 = 1 value per second of EEG data\n",
    "    data : array_like or :py:class:`mne.io.BaseRaw`\n",
    "        1D or 2D EEG data. Can also be a :py:class:`mne.io.BaseRaw`, in which\n",
    "        case ``data`` and ``sf_data`` will be automatically extracted.\n",
    "    sf_data : float\n",
    "        The sampling frequency of ``data``, in Hz (e.g. 100 Hz, 256 Hz, ...).\n",
    "        Can be omitted if ``data`` is a :py:class:`mne.io.BaseRaw`.\n",
    "    verbose : bool or str\n",
    "        Verbose level. Default (False) will only print warning and error\n",
    "        messages. The logging levels are 'debug', 'info', 'warning', 'error',\n",
    "        and 'critical'. For most users the choice is between 'info'\n",
    "        (or ``verbose=True``) and warning (``verbose=False``).\n",
    "    Returns\n",
    "    -------\n",
    "    hypno : array_like\n",
    "        The hypnogram, upsampled to ``sf_data`` and cropped/padded to ``max(data.shape)``.\n",
    "    Warns\n",
    "    -----\n",
    "    UserWarning\n",
    "        If the upsampled ``hypno`` is shorter / longer than ``max(data.shape)``\n",
    "        and therefore needs to be padded/cropped respectively. This output can be disabled by\n",
    "        passing ``verbose='ERROR'``.\n",
    "    \"\"\"\n",
    "    set_log_level(verbose)\n",
    "    if isinstance(data, mne.io.BaseRaw):\n",
    "        sf_data = data.info[\"sfreq\"]\n",
    "        data = data.times\n",
    "\n",
    "    # Upsample the hypnogram to a given sampling frequency\n",
    "    repeats = sf_data / sf_hypno\n",
    "    assert sf_hypno <= sf_data, \"sf_hypno must be less than sf_data.\"\n",
    "    assert repeats.is_integer(), \"sf_hypno / sf_data must be a whole number.\"\n",
    "    assert isinstance(hypno, (list, np.ndarray, pd.Series))\n",
    "    hypno_up = np.repeat(np.asarray(hypno), repeats)\n",
    "\n",
    "    # Crop or pad the hypnogram to fit the length of data.\n",
    "    # Check if data is an MNE raw object\n",
    "    hypno = hypno_up\n",
    "    sf = sf_data\n",
    "    if isinstance(data, mne.io.BaseRaw):\n",
    "        sf = data.info[\"sfreq\"]\n",
    "        data = data.times  # 1D array and does not require to preload data\n",
    "    data = np.asarray(data)\n",
    "    hypno = np.asarray(hypno)\n",
    "    assert hypno.ndim == 1, \"Hypno must be 1D.\"\n",
    "    npts_hyp = hypno.size\n",
    "    npts_data = max(data.shape)  # Support for 2D data\n",
    "    if npts_hyp < npts_data:\n",
    "        # Hypnogram is shorter than data\n",
    "        npts_diff = npts_data - npts_hyp\n",
    "        if sf is not None:\n",
    "            dur_diff = npts_diff / sf\n",
    "            logger.warning(\n",
    "                \"Hypnogram is SHORTER than data by %.2f seconds. \"\n",
    "                \"Padding hypnogram with last value to match data.size.\" % dur_diff\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"Hypnogram is SHORTER than data by %i samples. \"\n",
    "                \"Padding hypnogram with last value to match data.size.\" % npts_diff\n",
    "            )\n",
    "        hypno = np.pad(hypno, (0, npts_diff), mode=\"edge\")\n",
    "    elif npts_hyp > npts_data:\n",
    "        # Hypnogram is longer than data\n",
    "        npts_diff = npts_hyp - npts_data\n",
    "        if sf is not None:\n",
    "            dur_diff = npts_diff / sf\n",
    "            logger.warning(\n",
    "                \"Hypnogram is LONGER than data by %.2f seconds. \"\n",
    "                \"Cropping hypnogram to match data.size.\" % dur_diff\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"Hypnogram is LONGER than data by %i samples. \"\n",
    "                \"Cropping hypnogram to match data.size.\" % npts_diff\n",
    "            )\n",
    "        hypno = hypno[0:npts_data]\n",
    "\n",
    "    return hypno\n",
    "\n",
    "\n",
    "def transition_matrix(hypno):\n",
    "    \"\"\"Create a state-transition matrix from an hypnogram.\n",
    "    .. versionadded:: 0.1.9\n",
    "    Parameters\n",
    "    ----------\n",
    "    hypno : array_like\n",
    "        Hypnogram. The dtype of ``hypno`` must be integer\n",
    "        (e.g. [0, 2, 2, 1, 1, 1, ...]). The sampling frequency must be the\n",
    "        original one, i.e. 1 value per 30 seconds if the staging was done in\n",
    "        30 seconds epochs. Using an upsampled hypnogram will result in an\n",
    "        incorrect transition matrix.\n",
    "        For best results, we recommend using an hypnogram cropped to\n",
    "        either the time in bed (TIB) or the sleep period time (SPT), without\n",
    "        any artefact / unscored epochs.\n",
    "    Returns\n",
    "    -------\n",
    "    counts : :py:class:`pandas.DataFrame`\n",
    "        Counts transition matrix (number of transitions from stage A to\n",
    "        stage B). The pre-transition states are the rows and the\n",
    "        post-transition states are the columns.\n",
    "    probs : :py:class:`pandas.DataFrame`\n",
    "        Conditional probability transition matrix, i.e.\n",
    "        given that current state is A, what is the probability that\n",
    "        the next state is B.\n",
    "        ``probs`` is a `right stochastic matrix\n",
    "        <https://en.wikipedia.org/wiki/Stochastic_matrix>`_,\n",
    "        i.e. each row sums to 1.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from yasa import transition_matrix\n",
    "    >>> a = [0, 0, 0, 1, 1, 0, 1, 2, 2, 3, 3, 2, 3, 3, 0, 2, 2, 1, 2, 2, 3, 3]\n",
    "    >>> counts, probs = transition_matrix(a)\n",
    "    >>> counts\n",
    "           0  1  2  3\n",
    "    Stage\n",
    "    0      2  2  1  0\n",
    "    1      1  1  2  0\n",
    "    2      0  1  3  3\n",
    "    3      1  0  1  3\n",
    "    >>> probs.round(2)\n",
    "              0     1     2     3\n",
    "    Stage\n",
    "    0      0.40  0.40  0.20  0.00\n",
    "    1      0.25  0.25  0.50  0.00\n",
    "    2      0.00  0.14  0.43  0.43\n",
    "    3      0.20  0.00  0.20  0.60\n",
    "    Several metrics of sleep fragmentation can be calculated from the\n",
    "    probability matrix. For example, the stability of sleep stages can be\n",
    "    calculated by taking the average of the diagonal values (excluding Wake\n",
    "    and N1 sleep):\n",
    "    >>> np.diag(probs.loc[2:, 2:]).mean().round(3)\n",
    "    0.514\n",
    "    Finally, we can plot the transition matrix using :py:func:`seaborn.heatmap`\n",
    "    .. plot::\n",
    "        >>> import numpy as np\n",
    "        >>> import seaborn as sns\n",
    "        >>> import matplotlib.pyplot as plt\n",
    "        >>> from yasa import transition_matrix\n",
    "        >>> # Calculate probability matrix\n",
    "        >>> a = [1, 1, 1, 0, 0, 2, 2, 0, 2, 0, 1, 1, 0, 0]\n",
    "        >>> _, probs = transition_matrix(a)\n",
    "        >>> # Start the plot\n",
    "        >>> grid_kws = {\"height_ratios\": (.9, .05), \"hspace\": .1}\n",
    "        >>> f, (ax, cbar_ax) = plt.subplots(2, gridspec_kw=grid_kws,\n",
    "        ...                                 figsize=(5, 5))\n",
    "        >>> sns.heatmap(probs, ax=ax, square=False, vmin=0, vmax=1, cbar=True,\n",
    "        ...             cbar_ax=cbar_ax, cmap='YlOrRd', annot=True, fmt='.2f',\n",
    "        ...             cbar_kws={\"orientation\": \"horizontal\", \"fraction\": 0.1,\n",
    "        ...                       \"label\": \"Transition probability\"})\n",
    "        >>> ax.set_xlabel(\"To sleep stage\")\n",
    "        >>> ax.xaxis.tick_top()\n",
    "        >>> ax.set_ylabel(\"From sleep stage\")\n",
    "        >>> ax.xaxis.set_label_position('top')\n",
    "    \"\"\"\n",
    "    x = np.asarray(hypno, dtype=int)\n",
    "    unique, inverse = np.unique(x, return_inverse=True)  # unique is sorted\n",
    "    n = unique.size\n",
    "    # Integer transition counts\n",
    "    counts = np.zeros((n, n), dtype=int)\n",
    "    np.add.at(counts, (inverse[:-1], inverse[1:]), 1)\n",
    "    # Conditional probabilities\n",
    "    probs = counts / counts.sum(axis=-1, keepdims=True)\n",
    "    # Convert to a Pandas DataFrame\n",
    "    counts = pd.DataFrame(counts, index=unique, columns=unique)\n",
    "    probs = pd.DataFrame(probs, index=unique, columns=unique)\n",
    "    counts.index.name = \"From Stage\"\n",
    "    probs.index.name = \"From Stage\"\n",
    "    counts.columns.name = \"To Stage\"\n",
    "    probs.columns.name = \"To Stage\"\n",
    "    return counts, probs\n",
    "\n",
    "\n",
    "def sliding_window(data, sf, window, step=None, axis=-1):\n",
    "    \"\"\"Calculate a sliding window of a 1D or 2D EEG signal.\n",
    "    .. versionadded:: 0.1.7\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy array\n",
    "        The 1D or 2D EEG data.\n",
    "    sf : float\n",
    "        The sampling frequency of ``data``.\n",
    "    window : int\n",
    "        The sliding window length, in seconds.\n",
    "    step : int\n",
    "        The sliding window step length, in seconds.\n",
    "        If None (default), ``step`` is set to ``window``,\n",
    "        which results in no overlap between the sliding windows.\n",
    "    axis : int\n",
    "        The axis to slide over. Defaults to the last axis.\n",
    "    Returns\n",
    "    -------\n",
    "    times : numpy array\n",
    "        Time vector, in seconds, corresponding to the START of each sliding\n",
    "        epoch in ``strided``.\n",
    "    strided : numpy array\n",
    "        A matrix where row in last dimension consists of one instance\n",
    "        of the sliding window, shape (n_epochs, ..., n_samples).\n",
    "    Notes\n",
    "    -----\n",
    "    This is a wrapper around the\n",
    "    :py:func:`numpy.lib.stride_tricks.as_strided` function.\n",
    "    Examples\n",
    "    --------\n",
    "    With a 1-D array\n",
    "    >>> import numpy as np\n",
    "    >>> from yasa import sliding_window\n",
    "    >>> data = np.arange(20)\n",
    "    >>> times, epochs = sliding_window(data, sf=1, window=5)\n",
    "    >>> times\n",
    "    array([ 0.,  5., 10., 15.])\n",
    "    >>> epochs\n",
    "    array([[ 0,  1,  2,  3,  4],\n",
    "           [ 5,  6,  7,  8,  9],\n",
    "           [10, 11, 12, 13, 14],\n",
    "           [15, 16, 17, 18, 19]])\n",
    "    >>> sliding_window(data, sf=1, window=5, step=1)[1]\n",
    "    array([[ 0,  1,  2,  3,  4],\n",
    "           [ 2,  3,  4,  5,  6],\n",
    "           [ 4,  5,  6,  7,  8],\n",
    "           [ 6,  7,  8,  9, 10],\n",
    "           [ 8,  9, 10, 11, 12],\n",
    "           [10, 11, 12, 13, 14],\n",
    "           [12, 13, 14, 15, 16],\n",
    "           [14, 15, 16, 17, 18]])\n",
    "    >>> sliding_window(data, sf=1, window=11)[1]\n",
    "    array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
    "    With a N-D array\n",
    "    >>> np.random.seed(42)\n",
    "    >>> # 4 channels x 20 samples\n",
    "    >>> data = np.random.randint(-100, 100, size=(4, 20))\n",
    "    >>> epochs = sliding_window(data, sf=1, window=10)[1]\n",
    "    >>> epochs.shape  # shape (n_epochs, n_channels, n_samples)\n",
    "    (2, 4, 10)\n",
    "    >>> epochs\n",
    "    array([[[  2,  79,  -8, -86,   6, -29,  88, -80,   2,  21],\n",
    "            [-13,  57, -63,  29,  91,  87, -80,  60, -43, -79],\n",
    "            [-50,   7, -46, -37,  30, -50,  34, -80, -28,  66],\n",
    "            [ -9,  10,  87,  98,  71, -93,  74, -66, -20,  63]],\n",
    "           [[-26, -13,  16,  -1,   3,  51,  30,  49, -48, -99],\n",
    "            [-12, -52, -42,  69,  87, -86,  89,  89,  74,  89],\n",
    "            [-83,  31, -12, -41, -87, -92, -11, -48,  29, -17],\n",
    "            [-51,   3,  31, -99,  33, -47,   5, -97, -47,  90]]])\n",
    "    \"\"\"\n",
    "    from numpy.lib.stride_tricks import as_strided\n",
    "    assert axis <= data.ndim, \"Axis value out of range.\"\n",
    "    assert isinstance(sf, (int, float)), 'sf must be int or float'\n",
    "    assert isinstance(window, (int, float)), 'window must be int or float'\n",
    "    assert isinstance(step, (int, float, type(None))), ('step must be int, '\n",
    "                                                        'float or None.')\n",
    "    if isinstance(sf, float):\n",
    "        assert sf.is_integer(), 'sf must be a whole number.'\n",
    "        sf = int(sf)\n",
    "    assert isinstance(axis, int), 'axis must be int.'\n",
    "\n",
    "    # window and step in samples instead of points\n",
    "    window *= sf\n",
    "    step = window if step is None else step * sf\n",
    "\n",
    "    if isinstance(window, float):\n",
    "        assert window.is_integer(), 'window * sf must be a whole number.'\n",
    "        window = int(window)\n",
    "\n",
    "    if isinstance(step, float):\n",
    "        assert step.is_integer(), 'step * sf must be a whole number.'\n",
    "        step = int(step)\n",
    "\n",
    "    assert step >= 1, \"Stepsize may not be zero or negative.\"\n",
    "    assert window < data.shape[axis], (\"Sliding window size may not exceed \"\n",
    "                                       \"size of selected axis\")\n",
    "\n",
    "    # Define output shape\n",
    "    shape = list(data.shape)\n",
    "    shape[axis] = np.floor(data.shape[axis] / step - window / step + 1\n",
    "                           ).astype(int)\n",
    "    shape.append(window)\n",
    "\n",
    "    # Calculate strides and time vector\n",
    "    strides = list(data.strides)\n",
    "    strides[axis] *= step\n",
    "    strides.append(data.strides[axis])\n",
    "    strided = as_strided(data, shape=shape, strides=strides)\n",
    "    t = np.arange(strided.shape[-2]) * (step / sf)\n",
    "\n",
    "    # Swap axis: n_epochs, ..., n_samples\n",
    "    if strided.ndim > 2:\n",
    "        strided = np.rollaxis(strided, -2, 0)\n",
    "    return t, strided\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_1432/1461644518.py:12: RuntimeWarning: Number of records from the header does not match the file size (perhaps the recording was not stopped before exiting). Inferring from the file size.\n",
      "  raw = mne.io.read_raw_edf(eeg_loc, preload=True, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0 + 769\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "16\n",
      "769 : 769 + 703\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "16\n",
      "6\n",
      "1472 : 1472 + 780\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "16\n",
      "6\n",
      "43\n",
      "2252 : 2252 + 830\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "16\n",
      "6\n",
      "43\n",
      "45\n",
      "3082 : 3082 + 750\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "16\n",
      "6\n",
      "43\n",
      "45\n",
      "20\n",
      "3832 : 3832 + 659\n"
     ]
    }
   ],
   "source": [
    "# Plot test recordings with their AI prediction results\n",
    "for i, idx in enumerate(test_idx):  # recording index that I want to plot\n",
    "    name = reference_df.iloc[idx].name\n",
    "\n",
    "    ### To load labels for test:\n",
    "    hypno_30s_loc = reference_df.iloc[idx].hypno\n",
    "    hypno_30s = np.loadtxt(hypno_30s_loc)[:, 0]\n",
    "    hypno_30s[hypno_30s == 5] = 4  # replace 5 with 4\n",
    "\n",
    "    ### To load eeg:\n",
    "    eeg_loc = reference_df.iloc[idx].eeg\n",
    "    raw = mne.io.read_raw_edf(eeg_loc, preload=True, verbose=0)\n",
    "    raw.pick_types(eeg=True)\n",
    "    raw.filter(0.5, 45)\n",
    "    sf = 256\n",
    "    data = raw._data * 1e6  # : extract the data and convert from V to uV\n",
    "\n",
    "    ### To omit artifacts epochs from EEG and original hypnos\n",
    "    times, data_win = sliding_window(\n",
    "        data[0], sf, window=30\n",
    "    )  # # Convert the EEG data to 30-sec data\n",
    "    data_win = data_win[hypno_30s != -1]\n",
    "    hypno_30s = hypno_30s[hypno_30s != -1]  # do not process -1 (artifact)\n",
    "    data = data_win.flatten().reshape(1, -1)\n",
    "\n",
    "    ### To slice predicted hypno labels from y_pred\n",
    "    hypno_begin_idx = 0  # start index of predication labels for this session in y_pred\n",
    "    for j in range(0, i):\n",
    "        print(test_idx[j])\n",
    "        hypno_30s_loc_dummy = reference_df.iloc[test_idx[j]].hypno\n",
    "        hypno_30s_dummy = np.loadtxt(hypno_30s_loc_dummy)[:, 0]\n",
    "        hypno_30s_dummy = hypno_30s_dummy[hypno_30s_dummy != -1]\n",
    "        hypno_begin_idx += len(hypno_30s_dummy)\n",
    "    print(f\"{hypno_begin_idx} : {hypno_begin_idx} + {len(hypno_30s)}\")\n",
    "\n",
    "    hypno_30s_pred = y_pred[hypno_begin_idx : hypno_begin_idx + len(hypno_30s)]\n",
    "\n",
    "    ### Plot hypno, hypno_pred and spectrogram all in one plot\n",
    "    hypno = hypno_upsample_to_data(\n",
    "        hypno=hypno_30s, sf_hypno=(1 / 30), data=data[0], sf_data=sf\n",
    "    )\n",
    "    hypno_pred = hypno_upsample_to_data(\n",
    "        hypno=hypno_30s_pred,\n",
    "        sf_hypno=(1 / 30),\n",
    "        data=data[0],\n",
    "        sf_data=sf,\n",
    "    )\n",
    "\n",
    "    fig = plot_spectrogram(\n",
    "        data[0], sf, hypno=hypno, hypno_pred=hypno_pred, fmax=30, trimperc=5\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Predicted and original hypnogram and spectrogram of {name} - {format_seconds_to_hhmmss(data.shape[1]/sf)} \\n Prediction using SVM RBF C=10 with 35 top features (Trained on 54 recordings). Acc.: {accuracy_score(y_test, y_pred)*100:.2f}\",\n",
    "        fontsize=16,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'pred-spectro-hypno {name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9461a3eb0cbef873800a78c94f0b6f375dc71a03d464463d7b611af82b6cd16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
