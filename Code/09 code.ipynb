{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from mne.filter import resample, filter_data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lspopt import spectrogram_lspopt\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "\n",
    "import logging\n",
    "LOGGING_TYPES = dict(DEBUG=logging.DEBUG, INFO=logging.INFO, WARNING=logging.WARNING,\n",
    "                     ERROR=logging.ERROR, CRITICAL=logging.CRITICAL)\n",
    "logger = logging.getLogger('yasa')\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 1691 samples (6.605 sec)\n",
      "\n",
      "Duration: 28490.0 (sec) OR 07:54:50\n"
     ]
    }
   ],
   "source": [
    "# Load the EDF file\n",
    "fname = \"P18_N3\"  # define here\n",
    "lr = \"L\"  # define here\n",
    "location = f\"/Users/amirhosseindaraie/Desktop/data/autoscoring-material/data/Zmax Donders/{fname}\"\n",
    "raw = mne.io.read_raw_edf(f\"{location}/EEG {lr}.edf\", preload=True, verbose=0)\n",
    "raw.pick_types(eeg=True)\n",
    "\n",
    "# Apply a zero-phase bandpass filter between 0.5 ~ 45 Hz\n",
    "raw.filter(0.5, 45)\n",
    "\n",
    "# Extract the data and convert from V to uV\n",
    "data = raw._data * 1e6\n",
    "sf = raw.info[\"sfreq\"]\n",
    "chan = raw.ch_names\n",
    "\n",
    "\n",
    "def format_seconds_to_hhmmss(seconds):\n",
    "    # Return hhmmss of total seconds parameter\n",
    "    hours = seconds // (60 * 60)\n",
    "    seconds %= 60 * 60\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return \"%02i:%02i:%02i\" % (hours, minutes, seconds)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Duration: {data.shape[1]/sf} (sec) OR {format_seconds_to_hhmmss(data.shape[1]/sf)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_54515/1489955597.py:8: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"max_colwidth\", -1)\n"
     ]
    }
   ],
   "source": [
    "import antropy as ant\n",
    "import scipy.signal as sp_sig\n",
    "import scipy.stats as sp_stats\n",
    "from numpy import apply_along_axis as apply\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"max_colwidth\", -1)\n",
    "\n",
    "# Time vector in seconds\n",
    "times = np.arange(data.size) / sf\n",
    "\n",
    "\n",
    "def sliding_window(data, sf, window, step=None, axis=-1):\n",
    "    \"\"\"Calculate a sliding window of a 1D or 2D EEG signal.\n",
    "    .. versionadded:: 0.1.7\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy array\n",
    "        The 1D or 2D EEG data.\n",
    "    sf : float\n",
    "        The sampling frequency of ``data``.\n",
    "    window : int\n",
    "        The sliding window length, in seconds.\n",
    "    step : int\n",
    "        The sliding window step length, in seconds.\n",
    "        If None (default), ``step`` is set to ``window``,\n",
    "        which results in no overlap between the sliding windows.\n",
    "    axis : int\n",
    "        The axis to slide over. Defaults to the last axis.\n",
    "    Returns\n",
    "    -------\n",
    "    times : numpy array\n",
    "        Time vector, in seconds, corresponding to the START of each sliding\n",
    "        epoch in ``strided``.\n",
    "    strided : numpy array\n",
    "        A matrix where row in last dimension consists of one instance\n",
    "        of the sliding window, shape (n_epochs, ..., n_samples).\n",
    "    Notes\n",
    "    -----\n",
    "    This is a wrapper around the\n",
    "    :py:func:`numpy.lib.stride_tricks.as_strided` function.\n",
    "    Examples\n",
    "    --------\n",
    "    With a 1-D array\n",
    "    >>> import numpy as np\n",
    "    >>> from yasa import sliding_window\n",
    "    >>> data = np.arange(20)\n",
    "    >>> times, epochs = sliding_window(data, sf=1, window=5)\n",
    "    >>> times\n",
    "    array([ 0.,  5., 10., 15.])\n",
    "    >>> epochs\n",
    "    array([[ 0,  1,  2,  3,  4],\n",
    "           [ 5,  6,  7,  8,  9],\n",
    "           [10, 11, 12, 13, 14],\n",
    "           [15, 16, 17, 18, 19]])\n",
    "    >>> sliding_window(data, sf=1, window=5, step=1)[1]\n",
    "    array([[ 0,  1,  2,  3,  4],\n",
    "           [ 2,  3,  4,  5,  6],\n",
    "           [ 4,  5,  6,  7,  8],\n",
    "           [ 6,  7,  8,  9, 10],\n",
    "           [ 8,  9, 10, 11, 12],\n",
    "           [10, 11, 12, 13, 14],\n",
    "           [12, 13, 14, 15, 16],\n",
    "           [14, 15, 16, 17, 18]])\n",
    "    >>> sliding_window(data, sf=1, window=11)[1]\n",
    "    array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
    "    With a N-D array\n",
    "    >>> np.random.seed(42)\n",
    "    >>> # 4 channels x 20 samples\n",
    "    >>> data = np.random.randint(-100, 100, size=(4, 20))\n",
    "    >>> epochs = sliding_window(data, sf=1, window=10)[1]\n",
    "    >>> epochs.shape  # shape (n_epochs, n_channels, n_samples)\n",
    "    (2, 4, 10)\n",
    "    >>> epochs\n",
    "    array([[[  2,  79,  -8, -86,   6, -29,  88, -80,   2,  21],\n",
    "            [-13,  57, -63,  29,  91,  87, -80,  60, -43, -79],\n",
    "            [-50,   7, -46, -37,  30, -50,  34, -80, -28,  66],\n",
    "            [ -9,  10,  87,  98,  71, -93,  74, -66, -20,  63]],\n",
    "           [[-26, -13,  16,  -1,   3,  51,  30,  49, -48, -99],\n",
    "            [-12, -52, -42,  69,  87, -86,  89,  89,  74,  89],\n",
    "            [-83,  31, -12, -41, -87, -92, -11, -48,  29, -17],\n",
    "            [-51,   3,  31, -99,  33, -47,   5, -97, -47,  90]]])\n",
    "    \"\"\"\n",
    "    from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "    assert axis <= data.ndim, \"Axis value out of range.\"\n",
    "    assert isinstance(sf, (int, float)), \"sf must be int or float\"\n",
    "    assert isinstance(window, (int, float)), \"window must be int or float\"\n",
    "    assert isinstance(step, (int, float, type(None))), (\n",
    "        \"step must be int, \" \"float or None.\"\n",
    "    )\n",
    "    if isinstance(sf, float):\n",
    "        assert sf.is_integer(), \"sf must be a whole number.\"\n",
    "        sf = int(sf)\n",
    "    assert isinstance(axis, int), \"axis must be int.\"\n",
    "\n",
    "    # window and step in samples instead of points\n",
    "    window *= sf\n",
    "    step = window if step is None else step * sf\n",
    "\n",
    "    if isinstance(window, float):\n",
    "        assert window.is_integer(), \"window * sf must be a whole number.\"\n",
    "        window = int(window)\n",
    "\n",
    "    if isinstance(step, float):\n",
    "        assert step.is_integer(), \"step * sf must be a whole number.\"\n",
    "        step = int(step)\n",
    "\n",
    "    assert step >= 1, \"Stepsize may not be zero or negative.\"\n",
    "    assert window < data.shape[axis], (\n",
    "        \"Sliding window size may not exceed \" \"size of selected axis\"\n",
    "    )\n",
    "\n",
    "    # Define output shape\n",
    "    shape = list(data.shape)\n",
    "    shape[axis] = np.floor(data.shape[axis] / step - window / step + 1).astype(int)\n",
    "    shape.append(window)\n",
    "\n",
    "    # Calculate strides and time vector\n",
    "    strides = list(data.strides)\n",
    "    strides[axis] *= step\n",
    "    strides.append(data.strides[axis])\n",
    "    strided = as_strided(data, shape=shape, strides=strides)\n",
    "    t = np.arange(strided.shape[-2]) * (step / sf)\n",
    "\n",
    "    # Swap axis: n_epochs, ..., n_samples\n",
    "    if strided.ndim > 2:\n",
    "        strided = np.rollaxis(strided, -2, 0)\n",
    "    return t, strided\n",
    "\n",
    "\n",
    "# Convert the EEG data to 30-sec data\n",
    "times, data_win = sliding_window(data[0], sf, window=30)\n",
    "\n",
    "# Convert times to minutes\n",
    "times /= 60\n",
    "\n",
    "\n",
    "def lziv(x):\n",
    "    \"\"\"Binarize the EEG signal and calculate the Lempel-Ziv complexity.\"\"\"\n",
    "    return ant.lziv_complexity(x > x.mean(), normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>iqr</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>nzc</th>\n",
       "      <th>hmob</th>\n",
       "      <th>hcomp</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>app_entropy</th>\n",
       "      <th>spec_entropy</th>\n",
       "      <th>lziv</th>\n",
       "      <th>dfa</th>\n",
       "      <th>petrosian</th>\n",
       "      <th>katz</th>\n",
       "      <th>higuchi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.882200</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>2.306805</td>\n",
       "      <td>44.005194</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>1.379865</td>\n",
       "      <td>192</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>9.403449</td>\n",
       "      <td>0.807286</td>\n",
       "      <td>0.268363</td>\n",
       "      <td>0.177962</td>\n",
       "      <td>0.293946</td>\n",
       "      <td>0.355766</td>\n",
       "      <td>1485</td>\n",
       "      <td>1.486522</td>\n",
       "      <td>1.011184</td>\n",
       "      <td>2.136577</td>\n",
       "      <td>1.398110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.845872</td>\n",
       "      <td>0.738753</td>\n",
       "      <td>1.611624</td>\n",
       "      <td>50.347797</td>\n",
       "      <td>1.052544</td>\n",
       "      <td>6.475114</td>\n",
       "      <td>309</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>8.252569</td>\n",
       "      <td>0.808290</td>\n",
       "      <td>0.268092</td>\n",
       "      <td>0.157969</td>\n",
       "      <td>0.243013</td>\n",
       "      <td>0.341539</td>\n",
       "      <td>1629</td>\n",
       "      <td>1.428058</td>\n",
       "      <td>1.011227</td>\n",
       "      <td>1.831358</td>\n",
       "      <td>1.390486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.866452</td>\n",
       "      <td>-0.206621</td>\n",
       "      <td>2.344649</td>\n",
       "      <td>24.914854</td>\n",
       "      <td>-0.837093</td>\n",
       "      <td>3.476886</td>\n",
       "      <td>473</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>7.322419</td>\n",
       "      <td>0.832472</td>\n",
       "      <td>0.345790</td>\n",
       "      <td>0.409602</td>\n",
       "      <td>0.472739</td>\n",
       "      <td>0.538437</td>\n",
       "      <td>1418</td>\n",
       "      <td>1.437477</td>\n",
       "      <td>1.012296</td>\n",
       "      <td>2.184215</td>\n",
       "      <td>1.640853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.180801</td>\n",
       "      <td>-2.024212</td>\n",
       "      <td>-0.236644</td>\n",
       "      <td>15.448310</td>\n",
       "      <td>-0.809879</td>\n",
       "      <td>6.938453</td>\n",
       "      <td>504</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>20.826391</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.149264</td>\n",
       "      <td>0.066868</td>\n",
       "      <td>0.096754</td>\n",
       "      <td>0.377652</td>\n",
       "      <td>1208</td>\n",
       "      <td>1.677114</td>\n",
       "      <td>1.011405</td>\n",
       "      <td>1.779120</td>\n",
       "      <td>1.511126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.467643</td>\n",
       "      <td>2.259023</td>\n",
       "      <td>4.616672</td>\n",
       "      <td>76.773250</td>\n",
       "      <td>-0.332790</td>\n",
       "      <td>1.408277</td>\n",
       "      <td>234</td>\n",
       "      <td>0.092555</td>\n",
       "      <td>9.321508</td>\n",
       "      <td>0.813432</td>\n",
       "      <td>0.292107</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.303413</td>\n",
       "      <td>0.444736</td>\n",
       "      <td>1684</td>\n",
       "      <td>1.499897</td>\n",
       "      <td>1.011453</td>\n",
       "      <td>1.995400</td>\n",
       "      <td>1.503711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         std      mean    median        iqr      skew      kurt  nzc      hmob      hcomp  perm_entropy  svd_entropy  sample_entropy  app_entropy  spec_entropy  lziv       dfa  petrosian      katz   higuchi\n",
       "0  54.882200 -0.003694  2.306805  44.005194  0.015072  1.379865  192  0.082981  9.403449   0.807286      0.268363     0.177962        0.293946     0.355766      1485  1.486522  1.011184   2.136577  1.398110\n",
       "1  75.845872  0.738753  1.611624  50.347797  1.052544  6.475114  309  0.084321  8.252569   0.808290      0.268092     0.157969        0.243013     0.341539      1629  1.428058  1.011227   1.831358  1.390486\n",
       "2  28.866452 -0.206621  2.344649  24.914854 -0.837093  3.476886  473  0.119000  7.322419   0.832472      0.345790     0.409602        0.472739     0.538437      1418  1.437477  1.012296   2.184215  1.640853\n",
       "3  67.180801 -2.024212 -0.236644  15.448310 -0.809879  6.938453  504  0.037268  20.826391  0.812461      0.149264     0.066868        0.096754     0.377652      1208  1.677114  1.011405   1.779120  1.511126\n",
       "4  72.467643  2.259023  4.616672  76.773250 -0.332790  1.408277  234  0.092555  9.321508   0.813432      0.292107     0.230731        0.303413     0.444736      1684  1.499897  1.011453   1.995400  1.503711"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell took ~2min for ~8 hours of sleep data\n",
    "\n",
    "# Calculate standard descriptive statistics\n",
    "hmob, hcomp = ant.hjorth_params(data_win, axis=1)\n",
    "\n",
    "# Feature extraction\n",
    "df_feat = {\n",
    "    # Statistical\n",
    "    \"std\": apply(np.std, arr=data_win, axis=1, ddof=1),\n",
    "    \"mean\": apply(np.mean, arr=data_win, axis=1),\n",
    "    \"median\": apply(np.median, arr=data_win, axis=1),\n",
    "    \"iqr\": apply(sp_stats.iqr, arr=data_win, axis=1, rng=(25, 75)),\n",
    "    \"skew\": apply(sp_stats.skew, arr=data_win, axis=1),\n",
    "    \"kurt\": apply(sp_stats.kurtosis, arr=data_win, axis=1),\n",
    "    \"nzc\": apply(ant.num_zerocross, arr=data_win, axis=1),\n",
    "    \"hmob\": hmob,\n",
    "    \"hcomp\": hcomp,\n",
    "    # Entropy\n",
    "    \"perm_entropy\": apply(ant.perm_entropy, axis=1, arr=data_win, normalize=True),\n",
    "    \"svd_entropy\": apply(ant.svd_entropy, 1, data_win, normalize=True),\n",
    "    \"sample_entropy\": apply(ant.sample_entropy, 1, data_win),\n",
    "    \"app_entropy\": apply(ant.app_entropy, 1, data_win, order=2),\n",
    "    \"spec_entropy\": apply(\n",
    "        ant.spectral_entropy,\n",
    "        1,\n",
    "        data_win,\n",
    "        sf,\n",
    "        normalize=True,\n",
    "        method=\"welch\",\n",
    "        nperseg=50,\n",
    "    ),\n",
    "    \"lziv\": apply(ant.lziv_complexity, 1, data_win),\n",
    "    # Fractal dimension\n",
    "    \"dfa\": apply(ant.detrended_fluctuation, 1, data_win),\n",
    "    \"petrosian\": apply(ant.petrosian_fd, 1, data_win),\n",
    "    \"katz\": apply(ant.katz_fd, 1, data_win),\n",
    "    \"higuchi\": apply(ant.higuchi_fd, 1, data_win),\n",
    "}\n",
    "\n",
    "\n",
    "df_feat = pd.DataFrame(df_feat)\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>iqr</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>nzc</th>\n",
       "      <th>hmob</th>\n",
       "      <th>hcomp</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>app_entropy</th>\n",
       "      <th>spec_entropy</th>\n",
       "      <th>lziv</th>\n",
       "      <th>dfa</th>\n",
       "      <th>petrosian</th>\n",
       "      <th>katz</th>\n",
       "      <th>higuchi</th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>sigma</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.882200</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>2.306805</td>\n",
       "      <td>44.005194</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>1.379865</td>\n",
       "      <td>192</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>9.403449</td>\n",
       "      <td>0.807286</td>\n",
       "      <td>0.268363</td>\n",
       "      <td>0.177962</td>\n",
       "      <td>0.293946</td>\n",
       "      <td>0.355766</td>\n",
       "      <td>1485</td>\n",
       "      <td>1.486522</td>\n",
       "      <td>1.011184</td>\n",
       "      <td>2.136577</td>\n",
       "      <td>1.398110</td>\n",
       "      <td>0.943567</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.002913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.845872</td>\n",
       "      <td>0.738753</td>\n",
       "      <td>1.611624</td>\n",
       "      <td>50.347797</td>\n",
       "      <td>1.052544</td>\n",
       "      <td>6.475114</td>\n",
       "      <td>309</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>8.252569</td>\n",
       "      <td>0.808290</td>\n",
       "      <td>0.268092</td>\n",
       "      <td>0.157969</td>\n",
       "      <td>0.243013</td>\n",
       "      <td>0.341539</td>\n",
       "      <td>1629</td>\n",
       "      <td>1.428058</td>\n",
       "      <td>1.011227</td>\n",
       "      <td>1.831358</td>\n",
       "      <td>1.390486</td>\n",
       "      <td>0.881081</td>\n",
       "      <td>0.095164</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.002525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.866452</td>\n",
       "      <td>-0.206621</td>\n",
       "      <td>2.344649</td>\n",
       "      <td>24.914854</td>\n",
       "      <td>-0.837093</td>\n",
       "      <td>3.476886</td>\n",
       "      <td>473</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>7.322419</td>\n",
       "      <td>0.832472</td>\n",
       "      <td>0.345790</td>\n",
       "      <td>0.409602</td>\n",
       "      <td>0.472739</td>\n",
       "      <td>0.538437</td>\n",
       "      <td>1418</td>\n",
       "      <td>1.437477</td>\n",
       "      <td>1.012296</td>\n",
       "      <td>2.184215</td>\n",
       "      <td>1.640853</td>\n",
       "      <td>0.951900</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.013815</td>\n",
       "      <td>0.009016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.180801</td>\n",
       "      <td>-2.024212</td>\n",
       "      <td>-0.236644</td>\n",
       "      <td>15.448310</td>\n",
       "      <td>-0.809879</td>\n",
       "      <td>6.938453</td>\n",
       "      <td>504</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>20.826391</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.149264</td>\n",
       "      <td>0.066868</td>\n",
       "      <td>0.096754</td>\n",
       "      <td>0.377652</td>\n",
       "      <td>1208</td>\n",
       "      <td>1.677114</td>\n",
       "      <td>1.011405</td>\n",
       "      <td>1.779120</td>\n",
       "      <td>1.511126</td>\n",
       "      <td>0.982728</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.002525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.467643</td>\n",
       "      <td>2.259023</td>\n",
       "      <td>4.616672</td>\n",
       "      <td>76.773250</td>\n",
       "      <td>-0.332790</td>\n",
       "      <td>1.408277</td>\n",
       "      <td>234</td>\n",
       "      <td>0.092555</td>\n",
       "      <td>9.321508</td>\n",
       "      <td>0.813432</td>\n",
       "      <td>0.292107</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.303413</td>\n",
       "      <td>0.444736</td>\n",
       "      <td>1684</td>\n",
       "      <td>1.499897</td>\n",
       "      <td>1.011453</td>\n",
       "      <td>1.995400</td>\n",
       "      <td>1.503711</td>\n",
       "      <td>0.948788</td>\n",
       "      <td>0.029935</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>0.006639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         std      mean    median        iqr      skew      kurt  nzc      hmob      hcomp  perm_entropy  svd_entropy  sample_entropy  app_entropy  spec_entropy  lziv       dfa  petrosian      katz   higuchi     delta     theta     alpha     sigma      beta     gamma\n",
       "0  54.882200 -0.003694  2.306805  44.005194  0.015072  1.379865  192  0.082981  9.403449   0.807286      0.268363     0.177962        0.293946     0.355766      1485  1.486522  1.011184   2.136577  1.398110  0.943567  0.043672  0.004745  0.001304  0.003798  0.002913\n",
       "1  75.845872  0.738753  1.611624  50.347797  1.052544  6.475114  309  0.084321  8.252569   0.808290      0.268092     0.157969        0.243013     0.341539      1629  1.428058  1.011227   1.831358  1.390486  0.881081  0.095164  0.014046  0.003701  0.003483  0.002525\n",
       "2  28.866452 -0.206621  2.344649  24.914854 -0.837093  3.476886  473  0.119000  7.322419   0.832472      0.345790     0.409602        0.472739     0.538437      1418  1.437477  1.012296   2.184215  1.640853  0.951900  0.018425  0.004580  0.002265  0.013815  0.009016\n",
       "3  67.180801 -2.024212 -0.236644  15.448310 -0.809879  6.938453  504  0.037268  20.826391  0.812461      0.149264     0.066868        0.096754     0.377652      1208  1.677114  1.011405   1.779120  1.511126  0.982728  0.006495  0.002767  0.001265  0.004220  0.002525\n",
       "4  72.467643  2.259023  4.616672  76.773250 -0.332790  1.408277  234  0.092555  9.321508   0.813432      0.292107     0.230731        0.303413     0.444736      1684  1.499897  1.011453   1.995400  1.503711  0.948788  0.029935  0.005475  0.001840  0.007322  0.006639"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.integrate import simps\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Estimate power spectral density using Welch's method\n",
    "freqs, psd = welch(data_win, sf, nperseg=int(4 * sf))\n",
    "\n",
    "\n",
    "def bandpower_from_psd_ndarray(\n",
    "    psd,\n",
    "    freqs,\n",
    "    bands=[\n",
    "        (0.5, 4, \"Delta\"),\n",
    "        (4, 8, \"Theta\"),\n",
    "        (8, 12, \"Alpha\"),\n",
    "        (12, 16, \"Sigma\"),\n",
    "        (16, 30, \"Beta\"),\n",
    "        (30, 40, \"Gamma\"),\n",
    "    ],\n",
    "    relative=True,\n",
    "):\n",
    "    \"\"\"Compute bandpowers in N-dimensional PSD.\n",
    "    This is a np-only implementation of the :py:func:`yasa.bandpower_from_psd` function,\n",
    "    which supports 1-D arrays of shape (n_freqs), or N-dimensional arays (e.g. 2-D (n_chan,\n",
    "    n_freqs) or 3-D (n_chan, n_epochs, n_freqs))\n",
    "    .. versionadded:: 0.2.0\n",
    "    Parameters\n",
    "    ----------\n",
    "    psd : :py:class:`np.ndarray`\n",
    "        Power spectral density of data, in uV^2/Hz. Must be a N-D array of shape (..., n_freqs).\n",
    "        See :py:func:`scipy.signal.welch` for more details.\n",
    "    freqs : :py:class:`np.ndarray`\n",
    "        Array of frequencies. Must be a 1-D array of shape (n_freqs,)\n",
    "    bands : list of tuples\n",
    "        List of frequency bands of interests. Each tuple must contain the lower and upper\n",
    "        frequencies, as well as the band name (e.g. (0.5, 4, 'Delta')).\n",
    "    relative : boolean\n",
    "        If True, bandpower is divided by the total power between the min and\n",
    "        max frequencies defined in ``band`` (default 0.5 to 40 Hz).\n",
    "    Returns\n",
    "    -------\n",
    "    bandpowers : :py:class:`np.ndarray`\n",
    "        Bandpower array of shape *(n_bands, ...)*.\n",
    "    \"\"\"\n",
    "    # Type checks\n",
    "    assert isinstance(bands, list), \"bands must be a list of tuple(s)\"\n",
    "    assert isinstance(relative, bool), \"relative must be a boolean\"\n",
    "\n",
    "    # Safety checks\n",
    "    freqs = np.asarray(freqs)\n",
    "    psd = np.asarray(psd)\n",
    "    assert freqs.ndim == 1, \"freqs must be a 1-D array of shape (n_freqs,)\"\n",
    "    assert psd.shape[-1] == freqs.shape[-1], \"n_freqs must be last axis of psd\"\n",
    "\n",
    "    # Extract frequencies of interest\n",
    "    all_freqs = np.hstack([[b[0], b[1]] for b in bands])\n",
    "    fmin, fmax = min(all_freqs), max(all_freqs)\n",
    "    idx_good_freq = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "    freqs = freqs[idx_good_freq]\n",
    "    res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Trim PSD to frequencies of interest\n",
    "    psd = psd[..., idx_good_freq]\n",
    "\n",
    "    # Check if there are negative values in PSD\n",
    "    if (psd < 0).any():\n",
    "        msg = (\n",
    "            \"There are negative values in PSD. This will result in incorrect \"\n",
    "            \"bandpower values. We highly recommend working with an \"\n",
    "            \"all-positive PSD. For more details, please refer to: \"\n",
    "            \"https://github.com/raphaelvallat/yasa/issues/29\"\n",
    "        )\n",
    "        logger.warning(msg)\n",
    "\n",
    "    # Calculate total power\n",
    "    total_power = simps(psd, dx=res, axis=-1)\n",
    "    total_power = total_power[np.newaxis, ...]\n",
    "\n",
    "    # Initialize empty array\n",
    "    bp = np.zeros((len(bands), *psd.shape[:-1]), dtype=np.float64)\n",
    "\n",
    "    # Enumerate over the frequency bands\n",
    "    labels = []\n",
    "    for i, band in enumerate(bands):\n",
    "        b0, b1, la = band\n",
    "        labels.append(la)\n",
    "        idx_band = np.logical_and(freqs >= b0, freqs <= b1)\n",
    "        bp[i] = simps(psd[..., idx_band], dx=res, axis=-1)\n",
    "\n",
    "    if relative:\n",
    "        bp /= total_power\n",
    "    return bp\n",
    "\n",
    "\n",
    "# Compute bandpowers in N-dimensional PSD\n",
    "bp = bandpower_from_psd_ndarray(psd, freqs)\n",
    "bp = pd.DataFrame(bp.T, columns=[\"delta\", \"theta\", \"alpha\", \"sigma\", \"beta\", \"gamma\"])\n",
    "df_feat = pd.concat([df_feat, bp], axis=1)\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>iqr</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>nzc</th>\n",
       "      <th>hmob</th>\n",
       "      <th>hcomp</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>sample_entropy</th>\n",
       "      <th>app_entropy</th>\n",
       "      <th>spec_entropy</th>\n",
       "      <th>lziv</th>\n",
       "      <th>dfa</th>\n",
       "      <th>petrosian</th>\n",
       "      <th>katz</th>\n",
       "      <th>higuchi</th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>sigma</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>dt</th>\n",
       "      <th>da</th>\n",
       "      <th>ds</th>\n",
       "      <th>db</th>\n",
       "      <th>dg</th>\n",
       "      <th>td</th>\n",
       "      <th>ta</th>\n",
       "      <th>ts</th>\n",
       "      <th>tb</th>\n",
       "      <th>tg</th>\n",
       "      <th>ad</th>\n",
       "      <th>at</th>\n",
       "      <th>asi</th>\n",
       "      <th>ab</th>\n",
       "      <th>ag</th>\n",
       "      <th>sd</th>\n",
       "      <th>st</th>\n",
       "      <th>sa</th>\n",
       "      <th>sb</th>\n",
       "      <th>sg</th>\n",
       "      <th>bd</th>\n",
       "      <th>bt</th>\n",
       "      <th>ba</th>\n",
       "      <th>bs</th>\n",
       "      <th>bg</th>\n",
       "      <th>gd</th>\n",
       "      <th>gt</th>\n",
       "      <th>ga</th>\n",
       "      <th>gs</th>\n",
       "      <th>gb</th>\n",
       "      <th>ta_b</th>\n",
       "      <th>ta_ab</th>\n",
       "      <th>gb_da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.882200</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>2.306805</td>\n",
       "      <td>44.005194</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>1.379865</td>\n",
       "      <td>192</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>9.403449</td>\n",
       "      <td>0.807286</td>\n",
       "      <td>0.268363</td>\n",
       "      <td>0.177962</td>\n",
       "      <td>0.293946</td>\n",
       "      <td>0.355766</td>\n",
       "      <td>1485</td>\n",
       "      <td>1.486522</td>\n",
       "      <td>1.011184</td>\n",
       "      <td>2.136577</td>\n",
       "      <td>1.398110</td>\n",
       "      <td>0.943567</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>21.605609</td>\n",
       "      <td>198.834382</td>\n",
       "      <td>723.597811</td>\n",
       "      <td>248.410628</td>\n",
       "      <td>323.970098</td>\n",
       "      <td>0.046284</td>\n",
       "      <td>9.202906</td>\n",
       "      <td>33.491202</td>\n",
       "      <td>11.497507</td>\n",
       "      <td>14.994722</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.108661</td>\n",
       "      <td>3.639199</td>\n",
       "      <td>1.249334</td>\n",
       "      <td>1.629346</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.274786</td>\n",
       "      <td>0.343299</td>\n",
       "      <td>0.447721</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.086975</td>\n",
       "      <td>0.800426</td>\n",
       "      <td>2.912910</td>\n",
       "      <td>1.304172</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.066690</td>\n",
       "      <td>0.613743</td>\n",
       "      <td>2.233533</td>\n",
       "      <td>0.766770</td>\n",
       "      <td>12.746841</td>\n",
       "      <td>5.666939</td>\n",
       "      <td>0.007077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.845872</td>\n",
       "      <td>0.738753</td>\n",
       "      <td>1.611624</td>\n",
       "      <td>50.347797</td>\n",
       "      <td>1.052544</td>\n",
       "      <td>6.475114</td>\n",
       "      <td>309</td>\n",
       "      <td>0.084321</td>\n",
       "      <td>8.252569</td>\n",
       "      <td>0.808290</td>\n",
       "      <td>0.268092</td>\n",
       "      <td>0.157969</td>\n",
       "      <td>0.243013</td>\n",
       "      <td>0.341539</td>\n",
       "      <td>1629</td>\n",
       "      <td>1.428058</td>\n",
       "      <td>1.011227</td>\n",
       "      <td>1.831358</td>\n",
       "      <td>1.390486</td>\n",
       "      <td>0.881081</td>\n",
       "      <td>0.095164</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>9.258548</td>\n",
       "      <td>62.727287</td>\n",
       "      <td>238.091497</td>\n",
       "      <td>252.972890</td>\n",
       "      <td>348.984682</td>\n",
       "      <td>0.108008</td>\n",
       "      <td>6.775068</td>\n",
       "      <td>25.715858</td>\n",
       "      <td>27.323172</td>\n",
       "      <td>37.693242</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>3.795661</td>\n",
       "      <td>4.032900</td>\n",
       "      <td>5.563523</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.038887</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>1.062503</td>\n",
       "      <td>1.465759</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.036599</td>\n",
       "      <td>0.247961</td>\n",
       "      <td>0.941174</td>\n",
       "      <td>1.379534</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.026530</td>\n",
       "      <td>0.179742</td>\n",
       "      <td>0.682241</td>\n",
       "      <td>0.724883</td>\n",
       "      <td>31.356072</td>\n",
       "      <td>6.230219</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.866452</td>\n",
       "      <td>-0.206621</td>\n",
       "      <td>2.344649</td>\n",
       "      <td>24.914854</td>\n",
       "      <td>-0.837093</td>\n",
       "      <td>3.476886</td>\n",
       "      <td>473</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>7.322419</td>\n",
       "      <td>0.832472</td>\n",
       "      <td>0.345790</td>\n",
       "      <td>0.409602</td>\n",
       "      <td>0.472739</td>\n",
       "      <td>0.538437</td>\n",
       "      <td>1418</td>\n",
       "      <td>1.437477</td>\n",
       "      <td>1.012296</td>\n",
       "      <td>2.184215</td>\n",
       "      <td>1.640853</td>\n",
       "      <td>0.951900</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.013815</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>51.663010</td>\n",
       "      <td>207.852751</td>\n",
       "      <td>420.227703</td>\n",
       "      <td>68.905277</td>\n",
       "      <td>105.581494</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>4.023241</td>\n",
       "      <td>8.134015</td>\n",
       "      <td>1.333745</td>\n",
       "      <td>2.043657</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.248556</td>\n",
       "      <td>2.021757</td>\n",
       "      <td>0.331510</td>\n",
       "      <td>0.507963</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.122941</td>\n",
       "      <td>0.494619</td>\n",
       "      <td>0.163971</td>\n",
       "      <td>0.251248</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.749769</td>\n",
       "      <td>3.016500</td>\n",
       "      <td>6.098629</td>\n",
       "      <td>1.532270</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>1.968648</td>\n",
       "      <td>3.980127</td>\n",
       "      <td>0.652626</td>\n",
       "      <td>1.665255</td>\n",
       "      <td>1.250651</td>\n",
       "      <td>0.023869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.180801</td>\n",
       "      <td>-2.024212</td>\n",
       "      <td>-0.236644</td>\n",
       "      <td>15.448310</td>\n",
       "      <td>-0.809879</td>\n",
       "      <td>6.938453</td>\n",
       "      <td>504</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>20.826391</td>\n",
       "      <td>0.812461</td>\n",
       "      <td>0.149264</td>\n",
       "      <td>0.066868</td>\n",
       "      <td>0.096754</td>\n",
       "      <td>0.377652</td>\n",
       "      <td>1208</td>\n",
       "      <td>1.677114</td>\n",
       "      <td>1.011405</td>\n",
       "      <td>1.779120</td>\n",
       "      <td>1.511126</td>\n",
       "      <td>0.982728</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>151.295862</td>\n",
       "      <td>355.211728</td>\n",
       "      <td>777.011653</td>\n",
       "      <td>232.864582</td>\n",
       "      <td>389.258515</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>2.347795</td>\n",
       "      <td>5.135710</td>\n",
       "      <td>1.539134</td>\n",
       "      <td>2.572830</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.425931</td>\n",
       "      <td>2.187461</td>\n",
       "      <td>0.655566</td>\n",
       "      <td>1.095849</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.194715</td>\n",
       "      <td>0.457151</td>\n",
       "      <td>0.299693</td>\n",
       "      <td>0.500969</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.649716</td>\n",
       "      <td>1.525400</td>\n",
       "      <td>3.336753</td>\n",
       "      <td>1.671609</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.388677</td>\n",
       "      <td>0.912534</td>\n",
       "      <td>1.996133</td>\n",
       "      <td>0.598226</td>\n",
       "      <td>2.194699</td>\n",
       "      <td>1.325649</td>\n",
       "      <td>0.006844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.467643</td>\n",
       "      <td>2.259023</td>\n",
       "      <td>4.616672</td>\n",
       "      <td>76.773250</td>\n",
       "      <td>-0.332790</td>\n",
       "      <td>1.408277</td>\n",
       "      <td>234</td>\n",
       "      <td>0.092555</td>\n",
       "      <td>9.321508</td>\n",
       "      <td>0.813432</td>\n",
       "      <td>0.292107</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.303413</td>\n",
       "      <td>0.444736</td>\n",
       "      <td>1684</td>\n",
       "      <td>1.499897</td>\n",
       "      <td>1.011453</td>\n",
       "      <td>1.995400</td>\n",
       "      <td>1.503711</td>\n",
       "      <td>0.948788</td>\n",
       "      <td>0.029935</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>31.694711</td>\n",
       "      <td>173.287419</td>\n",
       "      <td>515.506576</td>\n",
       "      <td>129.575775</td>\n",
       "      <td>142.912270</td>\n",
       "      <td>0.031551</td>\n",
       "      <td>5.467392</td>\n",
       "      <td>16.264751</td>\n",
       "      <td>4.088246</td>\n",
       "      <td>4.509026</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.182903</td>\n",
       "      <td>2.974864</td>\n",
       "      <td>0.747751</td>\n",
       "      <td>0.824712</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.061483</td>\n",
       "      <td>0.336150</td>\n",
       "      <td>0.251356</td>\n",
       "      <td>0.277227</td>\n",
       "      <td>0.007717</td>\n",
       "      <td>0.244604</td>\n",
       "      <td>1.337344</td>\n",
       "      <td>3.978418</td>\n",
       "      <td>1.102924</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>0.221777</td>\n",
       "      <td>1.212544</td>\n",
       "      <td>3.607154</td>\n",
       "      <td>0.906681</td>\n",
       "      <td>4.835997</td>\n",
       "      <td>2.766983</td>\n",
       "      <td>0.014630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         std      mean    median        iqr      skew      kurt  nzc      hmob      hcomp  perm_entropy  svd_entropy  sample_entropy  app_entropy  spec_entropy  lziv       dfa  petrosian      katz   higuchi     delta     theta     alpha     sigma      beta     gamma          dt          da          ds          db          dg        td        ta         ts         tb         tg        ad        at       asi        ab        ag        sd        st        sa        sb        sg        bd        bt        ba        bs        bg        gd        gt        ga        gs        gb       ta_b     ta_ab     gb_da\n",
       "0  54.882200 -0.003694  2.306805  44.005194  0.015072  1.379865  192  0.082981  9.403449   0.807286      0.268363     0.177962        0.293946     0.355766      1485  1.486522  1.011184   2.136577  1.398110  0.943567  0.043672  0.004745  0.001304  0.003798  0.002913  21.605609   198.834382  723.597811  248.410628  323.970098  0.046284  9.202906  33.491202  11.497507  14.994722  0.005029  0.108661  3.639199  1.249334  1.629346  0.001382  0.029859  0.274786  0.343299  0.447721  0.004026  0.086975  0.800426  2.912910  1.304172  0.003087  0.066690  0.613743  2.233533  0.766770  12.746841  5.666939  0.007077\n",
       "1  75.845872  0.738753  1.611624  50.347797  1.052544  6.475114  309  0.084321  8.252569   0.808290      0.268092     0.157969        0.243013     0.341539      1629  1.428058  1.011227   1.831358  1.390486  0.881081  0.095164  0.014046  0.003701  0.003483  0.002525  9.258548    62.727287   238.091497  252.972890  348.984682  0.108008  6.775068  25.715858  27.323172  37.693242  0.015942  0.147600  3.795661  4.032900  5.563523  0.004200  0.038887  0.263459  1.062503  1.465759  0.003953  0.036599  0.247961  0.941174  1.379534  0.002865  0.026530  0.179742  0.682241  0.724883  31.356072  6.230219  0.006711\n",
       "2  28.866452 -0.206621  2.344649  24.914854 -0.837093  3.476886  473  0.119000  7.322419   0.832472      0.345790     0.409602        0.472739     0.538437      1418  1.437477  1.012296   2.184215  1.640853  0.951900  0.018425  0.004580  0.002265  0.013815  0.009016  51.663010   207.852751  420.227703  68.905277   105.581494  0.019356  4.023241  8.134015   1.333745   2.043657   0.004811  0.248556  2.021757  0.331510  0.507963  0.002380  0.122941  0.494619  0.163971  0.251248  0.014513  0.749769  3.016500  6.098629  1.532270  0.009471  0.489319  1.968648  3.980127  0.652626  1.665255   1.250651  0.023869\n",
       "3  67.180801 -2.024212 -0.236644  15.448310 -0.809879  6.938453  504  0.037268  20.826391  0.812461      0.149264     0.066868        0.096754     0.377652      1208  1.677114  1.011405   1.779120  1.511126  0.982728  0.006495  0.002767  0.001265  0.004220  0.002525  151.295862  355.211728  777.011653  232.864582  389.258515  0.006610  2.347795  5.135710   1.539134   2.572830   0.002815  0.425931  2.187461  0.655566  1.095849  0.001287  0.194715  0.457151  0.299693  0.500969  0.004294  0.649716  1.525400  3.336753  1.671609  0.002569  0.388677  0.912534  1.996133  0.598226  2.194699   1.325649  0.006844\n",
       "4  72.467643  2.259023  4.616672  76.773250 -0.332790  1.408277  234  0.092555  9.321508   0.813432      0.292107     0.230731        0.303413     0.444736      1684  1.499897  1.011453   1.995400  1.503711  0.948788  0.029935  0.005475  0.001840  0.007322  0.006639  31.694711   173.287419  515.506576  129.575775  142.912270  0.031551  5.467392  16.264751  4.088246   4.509026   0.005771  0.182903  2.974864  0.747751  0.824712  0.001940  0.061483  0.336150  0.251356  0.277227  0.007717  0.244604  1.337344  3.978418  1.102924  0.006997  0.221777  1.212544  3.607154  0.906681  4.835997   2.766983  0.014630"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio of spectral power\n",
    "df_feat.eval(\"dt = delta / theta\", inplace=True)\n",
    "df_feat.eval(\"da = delta / alpha\", inplace=True)\n",
    "df_feat.eval(\"ds = delta / sigma\", inplace=True)\n",
    "df_feat.eval(\"db = delta / beta\", inplace=True)\n",
    "df_feat.eval(\"dg = delta / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"td = theta / delta\", inplace=True)\n",
    "df_feat.eval(\"ta = theta / alpha\", inplace=True)\n",
    "df_feat.eval(\"ts = theta / sigma\", inplace=True)\n",
    "df_feat.eval(\"tb = theta / beta\", inplace=True)\n",
    "df_feat.eval(\"tg = theta / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"ad = alpha / delta\", inplace=True)\n",
    "df_feat.eval(\"at = alpha / theta\", inplace=True)\n",
    "df_feat.eval(\"asi = alpha / sigma\", inplace=True)\n",
    "df_feat.eval(\"ab = alpha / beta\", inplace=True)\n",
    "df_feat.eval(\"ag = alpha / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"sd = sigma / delta\", inplace=True)\n",
    "df_feat.eval(\"st = sigma / theta\", inplace=True)\n",
    "df_feat.eval(\"sa = sigma / alpha\", inplace=True)\n",
    "df_feat.eval(\"sb = sigma / beta\", inplace=True)\n",
    "df_feat.eval(\"sg = sigma / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"bd = beta / delta\", inplace=True)\n",
    "df_feat.eval(\"bt = beta / theta\", inplace=True)\n",
    "df_feat.eval(\"ba = beta / alpha\", inplace=True)\n",
    "df_feat.eval(\"bs = beta / sigma\", inplace=True)\n",
    "df_feat.eval(\"bg = beta / gamma\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"gd = gamma / delta\", inplace=True)\n",
    "df_feat.eval(\"gt = gamma / theta\", inplace=True)\n",
    "df_feat.eval(\"ga = gamma / alpha\", inplace=True)\n",
    "df_feat.eval(\"gs = gamma / sigma\", inplace=True)\n",
    "df_feat.eval(\"gb = gamma / beta\", inplace=True)\n",
    "\n",
    "df_feat.eval(\"ta_b = (theta + alpha)/beta\", inplace=True)\n",
    "df_feat.eval(\"ta_ab = (theta + alpha)/(alpha + beta)\", inplace=True)\n",
    "df_feat.eval(\"gb_da = (gamma + beta)/(delta + alpha)\", inplace=True)\n",
    "\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth_activity(x):\n",
    "    \"\"\"Column-wise computation of Hjorth activity (variance).\"\"\"\n",
    "    return np.var(x, axis=0)\n",
    "\n",
    "\n",
    "def hjorth_mobility(x):\n",
    "    \"\"\"Column-wise computation of Hjorth mobility\"\"\"\n",
    "    return np.sqrt(np.var(np.gradient(x, axis=0), axis=0) / np.var(x, axis=0))\n",
    "\n",
    "\n",
    "def hjorth_complexity(x):\n",
    "    \"\"\"Column-wise computation of Hjorth complexity\"\"\"\n",
    "    return hjorth_mobility(np.gradient(x, axis=0)) / hjorth_mobility(x)\n",
    "\n",
    "# Energy (E) of the signal is the sum of the squares of amplitude\n",
    "def energy_fn(x):\n",
    "    x /= np.max(x)\n",
    "    return np.mean(x**2)\n",
    "\n",
    "def calc_wavelet_energy(data_set):\n",
    "    \"\"\"\n",
    "    Input : 1 * N vector\n",
    "    Output: Float with the wavelet energy of the input vector,\n",
    "    rounded to 3 decimal places.\n",
    "    \"\"\"\n",
    "    # p_sqr = [i ** 2 for i in data_set]\n",
    "    wavelet_energy = np.nansum(np.log2(np.square(data_set)))\n",
    "    return round(wavelet_energy, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.apply_along_axis(energy_fn, 1, data_win)\n",
    "df_feat[\"E\"] = E\n",
    "\n",
    "from scipy.integrate import simps\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Estimate power spectral density using Welch's method\n",
    "freqs, psd = welch(data_win, sf, nperseg=int(4 * sf))\n",
    "\n",
    "# Compute features\n",
    "## Compute featrues for normal singal (to compare w/ psd later)\n",
    "hmob, hcomp = ant.hjorth_params(data_win, axis=1)\n",
    "std_nor = np.apply_along_axis(np.std, 1, data_win, ddof=1)\n",
    "mean_nor = np.apply_along_axis(np.mean, 1, data_win)\n",
    "median_nor = np.apply_along_axis(np.median, 1, data_win)\n",
    "iqr_nor = np.apply_along_axis(sp_stats.iqr, 1, data_win, rng=(25, 75))\n",
    "skew_nor = np.apply_along_axis(sp_stats.skew, 1, data_win)\n",
    "kurt_nor = np.apply_along_axis(sp_stats.kurtosis, 1, data_win)\n",
    "hmob_nor = hmob\n",
    "hcomp_nor = hcomp\n",
    "\n",
    "## Compute featrues for PSD\n",
    "hmob, hcomp = ant.hjorth_params(psd, axis=1)\n",
    "std_psd = np.apply_along_axis(np.std, 1, psd, ddof=1)\n",
    "mean_psd = np.apply_along_axis(np.mean, 1, psd)\n",
    "median_psd = np.apply_along_axis(np.median, 1, psd)\n",
    "iqr_psd = np.apply_along_axis(sp_stats.iqr, 1, psd, rng=(25, 75))\n",
    "skew_psd = np.apply_along_axis(sp_stats.skew, 1, psd)\n",
    "kurt_psd = np.apply_along_axis(sp_stats.kurtosis, 1, psd)\n",
    "hmob_psd = hmob\n",
    "hcomp_psd = hcomp\n",
    "\n",
    "# Add features to features dataframe\n",
    "df_feat[\"E\"] = E\n",
    "df_feat[\"std_psd\"] = std_psd\n",
    "df_feat[\"mean_psd\"] = mean_psd\n",
    "df_feat[\"iqr_psd\"] = iqr_psd\n",
    "df_feat[\"skew_psd\"] = skew_psd\n",
    "df_feat[\"kurt_psd\"] = kurt_psd\n",
    "df_feat[\"hmob_psd\"] = hmob_psd\n",
    "df_feat[\"hcomp_psd\"] = hcomp_psd\n",
    "\n",
    "wavelet_energy = np.apply_along_axis(calc_wavelet_energy, 1, data_win)\n",
    "\n",
    "# Add features to features dataframe\n",
    "df_feat[\"WEn\"] = wavelet_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys\n",
    "\n",
    "\n",
    "def __to_inc(x):\n",
    "    incs = x[1:] - x[:-1]\n",
    "    return incs\n",
    "\n",
    "\n",
    "def __to_pct(x):\n",
    "    pcts = x[1:] / x[:-1] - 1.0\n",
    "    return pcts\n",
    "\n",
    "\n",
    "def __get_RS(series, kind):\n",
    "    \"\"\"\n",
    "    Get rescaled range (using the range of cumulative sum\n",
    "    of deviations instead of the range of a series as in the simplified version\n",
    "    of R/S) from a time-series of values.\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        The kind of series (refer to compute_Hc docstring)\n",
    "    \"\"\"\n",
    "\n",
    "    if kind == \"random_walk\":\n",
    "        incs = __to_inc(series)\n",
    "        mean_inc = (series[-1] - series[0]) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    elif kind == \"price\":\n",
    "        incs = __to_pct(series)\n",
    "        mean_inc = np.sum(incs) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    elif kind == \"change\":\n",
    "        incs = series\n",
    "        mean_inc = np.sum(incs) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    if R == 0 or S == 0:\n",
    "        return 0  # return 0 to skip this interval due undefined R/S\n",
    "\n",
    "    return R / S\n",
    "\n",
    "\n",
    "def __get_simplified_RS(series, kind):\n",
    "    \"\"\"\n",
    "    Simplified version of rescaled range\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        The kind of series (refer to compute_Hc docstring)\n",
    "    \"\"\"\n",
    "\n",
    "    if kind == \"random_walk\":\n",
    "        incs = __to_inc(series)\n",
    "        R = max(series) - min(series)  # range in absolute values\n",
    "        S = np.std(incs, ddof=1)\n",
    "    elif kind == \"price\":\n",
    "        pcts = __to_pct(series)\n",
    "        R = max(series) / min(series) - 1.0  # range in percent\n",
    "        S = np.std(pcts, ddof=1)\n",
    "    elif kind == \"change\":\n",
    "        incs = series\n",
    "        _series = np.hstack([[0.0], np.cumsum(incs)])\n",
    "        R = max(_series) - min(_series)  # range in absolute values\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    if R == 0 or S == 0:\n",
    "        return 0  # return 0 to skip this interval due the undefined R/S ratio\n",
    "\n",
    "    return R / S\n",
    "\n",
    "\n",
    "def compute_Hc(\n",
    "    series, kind=\"random_walk\", min_window=10, max_window=None, simplified=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute H (Hurst exponent) and C according to Hurst equation:\n",
    "    E(R/S) = c * T^H\n",
    "    Refer to:\n",
    "    https://en.wikipedia.org/wiki/Hurst_exponent\n",
    "    https://en.wikipedia.org/wiki/Rescaled_range\n",
    "    https://en.wikipedia.org/wiki/Random_walk\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        Kind of series\n",
    "        possible values are 'random_walk', 'change' and 'price':\n",
    "        - 'random_walk' means that a series is a random walk with random increments;\n",
    "        - 'price' means that a series is a random walk with random multipliers;\n",
    "        - 'change' means that a series consists of random increments\n",
    "            (thus produced random walk is a cumulative sum of increments);\n",
    "    min_window : int, default 10\n",
    "        the minimal window size for R/S calculation\n",
    "    max_window : int, default is the length of series minus 1\n",
    "        the maximal window size for R/S calculation\n",
    "    simplified : bool, default True\n",
    "        whether to use the simplified or the original version of R/S calculation\n",
    "    Returns tuple of\n",
    "        H, c and data\n",
    "        where H and c  parameters or Hurst equation\n",
    "        and data is a list of 2 lists: time intervals and R/S-values for correspoding time interval\n",
    "        for further plotting log(data[0]) on X and log(data[1]) on Y\n",
    "    \"\"\"\n",
    "\n",
    "    if len(series) < 100:\n",
    "        raise ValueError(\"Series length must be greater or equal to 100\")\n",
    "\n",
    "    ndarray_likes = [np.ndarray]\n",
    "    if \"pandas.core.series\" in sys.modules.keys():\n",
    "        ndarray_likes.append(pd.core.series.Series)\n",
    "\n",
    "    # convert series to np array if series is not np array or pandas Series\n",
    "    if type(series) not in ndarray_likes:\n",
    "        series = np.array(series)\n",
    "\n",
    "    if (\n",
    "        \"pandas.core.series\" in sys.modules.keys()\n",
    "        and type(series) == pd.core.series.Series\n",
    "    ):\n",
    "        if series.isnull().values.any():\n",
    "            raise ValueError(\"Series contains NaNs\")\n",
    "        series = series.values  # convert pandas Series to np array\n",
    "    elif np.isnan(np.min(series)):\n",
    "        raise ValueError(\"Series contains NaNs\")\n",
    "\n",
    "    if simplified:\n",
    "        RS_func = __get_simplified_RS\n",
    "    else:\n",
    "        RS_func = __get_RS\n",
    "\n",
    "    err = np.geterr()\n",
    "    np.seterr(all=\"raise\")\n",
    "\n",
    "    max_window = max_window or len(series) - 1\n",
    "    window_sizes = list(\n",
    "        map(\n",
    "            lambda x: int(10**x),\n",
    "            np.arange(math.log10(min_window), math.log10(max_window), 0.25),\n",
    "        )\n",
    "    )\n",
    "    window_sizes.append(len(series))\n",
    "\n",
    "    RS = []\n",
    "    for w in window_sizes:\n",
    "        rs = []\n",
    "        for start in range(0, len(series), w):\n",
    "            if (start + w) > len(series):\n",
    "                break\n",
    "            _ = RS_func(series[start : start + w], kind)\n",
    "            if _ != 0:\n",
    "                rs.append(_)\n",
    "        RS.append(np.mean(rs))\n",
    "\n",
    "    A = np.vstack([np.log10(window_sizes), np.ones(len(RS))]).T\n",
    "    H, c = np.linalg.lstsq(A, np.log10(RS), rcond=-1)[0]\n",
    "    np.seterr(**err)\n",
    "\n",
    "    c = 10**c\n",
    "    return H, c  # , [window_sizes, RS]\n",
    "\n",
    "\n",
    "# H, c, [window_sizes, RS] = compute_Hc(data_win[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hurst_coeffs = np.apply_along_axis(compute_Hc, 1, data_win, kind=\"random_walk\")\n",
    "Hurst_H1 = Hurst_coeffs[:, 0]\n",
    "Hurst_C1 = Hurst_coeffs[:, 1]\n",
    "Hurst_coeffs = np.apply_along_axis(compute_Hc, 1, data_win, kind=\"change\")\n",
    "Hurst_H2 = Hurst_coeffs[:, 0]\n",
    "Hurst_C2 = Hurst_coeffs[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy.stats import iqr as IQR\n",
    "\n",
    "\n",
    "class Outlier:\n",
    "    \"\"\"\n",
    "    Find outlier in a numerical dataset with two different methods:\n",
    "        - `sd_outlier`: z-score based method\n",
    "        - `IQR_outlier`: IQR based method\n",
    "    Also allows to remove/filter-out the detected outliers with `filter` method.\n",
    "    `plot` method allows you to plot the original and filtered dataset and inspect the performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x=None):\n",
    "        self.x = x\n",
    "        self.outliers = None\n",
    "        self.outliersIndices = np.array([])\n",
    "        self.x_filt = None\n",
    "\n",
    "    def sd_outlier(self=None, x=None, axis=None, bar=3, side=\"both\"):\n",
    "        \"\"\"\n",
    "        z-score based method\n",
    "        This method will test if the numbers falls outside the three standard deviations.\n",
    "        Based on this rule, if the value is outlier, the method will return true, if not, return false.\n",
    "        \"\"\"\n",
    "\n",
    "        assert side in [\"gt\", \"lt\", \"both\"], \"Side should be `gt`, `lt` or `both`.\"\n",
    "\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        d_z = stat.zscore(x, axis=axis)\n",
    "\n",
    "        if side == \"gt\":\n",
    "            self.outliers = d_z > bar\n",
    "            return d_z > bar\n",
    "        elif side == \"lt\":\n",
    "            self.outliers = d_z < -bar\n",
    "            return d_z < -bar\n",
    "        elif side == \"both\":\n",
    "            self.outliers = np.abs(d_z) > bar\n",
    "            return np.abs(d_z) > bar\n",
    "\n",
    "    def __Q1(self, x, axis=None):\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        return np.percentile(x, 25, axis=axis)\n",
    "\n",
    "    def __Q3(self, x, axis=None):\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        return np.percentile(x, 75, axis=axis)\n",
    "\n",
    "    def IQR_outlier(self, x=None, axis=None, bar=1.5, side=\"both\"):\n",
    "        \"\"\"\n",
    "        IQR based method\n",
    "        This method will test if the value is less than q1 - 1.5 * iqr or\n",
    "        greater than q3 + 1.5 * iqr.\n",
    "        \"\"\"\n",
    "        self.method = \"IQR_outlier\"\n",
    "\n",
    "        assert side in [\"gt\", \"lt\", \"both\"], \"Side should be `gt`, `lt` or `both`.\"\n",
    "\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        d_IQR = IQR(x, axis=axis)\n",
    "        d_Q1 = self.__Q1(x, axis=axis)\n",
    "        d_Q3 = self.__Q3(x, axis=axis)\n",
    "        IQR_distance = np.multiply(d_IQR, bar)\n",
    "\n",
    "        stat_shape = list(x.shape)\n",
    "\n",
    "        if isinstance(axis, collections.Iterable):\n",
    "            for single_axis in axis:\n",
    "                stat_shape[single_axis] = 1\n",
    "        else:\n",
    "            stat_shape[axis] = 1\n",
    "\n",
    "        if side in [\"gt\", \"both\"]:\n",
    "            upper_range = d_Q3 + IQR_distance\n",
    "            upper_outlier = np.greater(x - upper_range.reshape(stat_shape), 0)\n",
    "        if side in [\"lt\", \"both\"]:\n",
    "            lower_range = d_Q1 - IQR_distance\n",
    "            lower_outlier = np.less(x - lower_range.reshape(stat_shape), 0)\n",
    "\n",
    "        if side == \"gt\":\n",
    "            self.outliers = upper_outlier\n",
    "            return upper_outlier\n",
    "        if side == \"lt\":\n",
    "            self.outliers = lower_outlier\n",
    "            return lower_outlier\n",
    "        if side == \"both\":\n",
    "            self.outliers = np.logical_or(upper_outlier, lower_outlier)\n",
    "            return np.logical_or(upper_outlier, lower_outlier)\n",
    "\n",
    "    def filter(self, x=None):\n",
    "        if (x is None) and (self.x is not None):\n",
    "            x = self.x\n",
    "        elif (x is None) and (self.x is None):\n",
    "            raise ValueError(\"Enter x input!\")\n",
    "\n",
    "        self.outliersIndices = np.where(self.outliers == True)\n",
    "        print(f\"Outliers are detected in {len(self.outliersIndices[0])} points.\")\n",
    "        self.x_filt = np.copy(x)\n",
    "        self.x_filt[self.outliersIndices] = np.mean(x[~self.outliers])\n",
    "        return self.x_filt, self.outliersIndices[0]\n",
    "\n",
    "    def plot(self, plot_original=False):\n",
    "        # Plot the signal and detected outliers\n",
    "        plt.figure()\n",
    "\n",
    "        if plot_original:\n",
    "            # plt.plot(np.asarray(self.x), \"ok\", label=\"Orginal Signal\")\n",
    "            plt.plot(np.asarray(self.x), \"-k\", linewidth=7, label=\"Orginal Signal\")\n",
    "\n",
    "        for outlier in self.outliersIndices[0]:\n",
    "            plt.axvline(outlier, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=4)\n",
    "\n",
    "        if plot_original:\n",
    "            plt.plot(filtered, \"-\", c=\"cyan\", linewidth=1, label=\"Filtered Signal\")\n",
    "        else:\n",
    "            plt.plot(filtered, \"-\", c=\"blue\", linewidth=1, label=\"Filtered Signal\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 1 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/x03my2dj70s46m109bn58l2m0000gn/T/ipykernel_54515/3522087127.py:86: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  if isinstance(axis, collections.Iterable):\n"
     ]
    }
   ],
   "source": [
    "# detect and remove outliers from Hurst coefficients\n",
    "outlier = Outlier(np.asarray(Hurst_H1))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n",
    "Hurst_H1 = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 0 points.\n"
     ]
    }
   ],
   "source": [
    "# detect and remove outliers from Hurst coefficients\n",
    "outlier = Outlier(np.asarray(Hurst_H2))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n",
    "Hurst_H2 = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 7 points.\n"
     ]
    }
   ],
   "source": [
    "# detect and remove outliers from Hurst coefficients\n",
    "outlier = Outlier(np.asarray(Hurst_C1))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n",
    "Hurst_C1 = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers are detected in 15 points.\n"
     ]
    }
   ],
   "source": [
    "# detect and remove outliers from Hurst coefficients\n",
    "outlier = Outlier(np.asarray(Hurst_C2))\n",
    "outlier.IQR_outlier(axis=0, bar=1.5, side=\"both\")\n",
    "filtered, outlierIndices = outlier.filter()\n",
    "outlier.plot(plot_original=True)\n",
    "Hurst_C2 = filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_and_ctm(X, Y):\n",
    "    # features = pd.DataFrame(columns=['radius','mean_distance','central_tendency_measure'])\n",
    "    r = 0.5\n",
    "    d = [math.sqrt(X[i] * X[i] + Y[i] * Y[i]) for i in range(0, len(X))]\n",
    "    delta = [1 if i < r else 0 for i in d]\n",
    "    d = [i for i in d if i < r]\n",
    "\n",
    "    ctm = np.sum(delta[:-2]) / (len(delta) - 2)\n",
    "    mean_distance = np.mean(d)\n",
    "\n",
    "    # features.loc[0] = [r] + [ctm] + [mean_distance]\n",
    "    return r, ctm, mean_distance\n",
    "\n",
    "\n",
    "def mean_ctm_wrapper(x):\n",
    "    \"\"\"\n",
    "    A wrapper function for calc_mean_and_ctm().\n",
    "    This function calculates mean and central tendancy measure for a given time series `x`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :py:class:`np.ndarray`\n",
    "        Array of time series data. Must be a 1-D array of shape `(dataPoints,)`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of `mean_distance` and `central_tendency_measure`\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "        >>> y = np.random.randn(7680)*10 + 100\n",
    "        >>> md, ctm = mean_ctm_wrapper(y)\n",
    "        (0.054281767955801107, 0.33950566436214885)\n",
    "    \"\"\"\n",
    "    upper_quartile = np.percentile(x, 80)\n",
    "    lower_quartile = np.percentile(x, 20)\n",
    "    IQR = (upper_quartile - lower_quartile) * 1.5\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    x = x[np.where((x >= quartileSet[0]) & (x <= quartileSet[1]))]\n",
    "    # plotting SODP\n",
    "    X = np.subtract(x[1:], x[0:-1])  # x(n+1)-x(n)\n",
    "    Y = np.subtract(x[2:], x[0:-2]).tolist()  # x(n+2)-x(n-1)\n",
    "    Y.extend([0])\n",
    "    # calculate MD and CTM\n",
    "    _, mean_distance, central_tendency_measure = calc_mean_and_ctm(X, Y)\n",
    "    return mean_distance, central_tendency_measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "mean_ctm = np.apply_along_axis(mean_ctm_wrapper, 1, arr=data_win)\n",
    "df_feat[\"mean_distance\"] = mean_ctm[:, 0]\n",
    "df_feat[\"central_tendency_measure\"] = mean_ctm[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Counter(Counter):\n",
    "    def prob(self):\n",
    "        return np.array(list(self.values()))\n",
    "\n",
    "\n",
    "def symbols_to_prob(symbols):\n",
    "    \"\"\"\n",
    "    Return a dict mapping symbols to  probability.\n",
    "    input:\n",
    "    -----\n",
    "        symbols:     iterable of hashable items\n",
    "                     works well if symbols is a zip of iterables\n",
    "    \"\"\"\n",
    "    myCounter = Counter(symbols)\n",
    "\n",
    "    N = float(len(list(symbols)))  # symbols might be a zip object in python 3\n",
    "\n",
    "    for k in myCounter:\n",
    "        myCounter[k] /= N\n",
    "\n",
    "    return myCounter\n",
    "\n",
    "\n",
    "def entropy(data=None, prob=None, tol=1e-5):\n",
    "    \"\"\"\n",
    "    given a probability distribution (prob) or an interable of symbols (data) compute and\n",
    "    return its entropy\n",
    "    inputs:\n",
    "    ------\n",
    "        data:       iterable of symbols\n",
    "        prob:       iterable with probabilities\n",
    "        tol:        if prob is given, 'entropy' checks that the sum is about 1.\n",
    "                    It raises an error if abs(sum(prob)-1) >= tol\n",
    "    \"\"\"\n",
    "\n",
    "    if prob is None and data is None:\n",
    "        raise ValueError(\n",
    "            \"%s.entropy requires either 'prob' or 'data' to be defined\" % __name__\n",
    "        )\n",
    "\n",
    "    if prob is not None and data is not None:\n",
    "        raise ValueError(\n",
    "            \"%s.entropy requires only 'prob' or 'data to be given but not both\"\n",
    "            % __name__\n",
    "        )\n",
    "\n",
    "    if prob is not None and not isinstance(prob, np.ndarray):\n",
    "        raise TypeError(\"'entropy' in '%s' needs 'prob' to be an ndarray\" % __name__)\n",
    "\n",
    "    if prob is not None and abs(prob.sum() - 1) > tol:\n",
    "        raise ValueError(\"parameter 'prob' in '%s.entropy' should sum to 1\" % __name__)\n",
    "\n",
    "    if data is not None:\n",
    "        prob = symbols_to_prob(data).prob()\n",
    "\n",
    "    # compute the log2 of the probability and change any -inf by 0s\n",
    "    logProb = np.log2(prob)\n",
    "    logProb[logProb == -np.inf] = 0\n",
    "\n",
    "    # return dot product of logProb and prob\n",
    "    return -float(np.dot(prob, logProb))\n",
    "\n",
    "\n",
    "def renyi(data=None, a=2):\n",
    "    if data is not None:\n",
    "        prob = symbols_to_prob(data).prob()\n",
    "\n",
    "    # compute the log2 of the probability and change any -inf by 0s\n",
    "    powerProb = prob ** int(a)\n",
    "    logProb = np.log(powerProb)\n",
    "    # return dot product of logProb and prob\n",
    "    return -(a / (1 - a)) * (np.sum(logProb))\n",
    "\n",
    "\n",
    "def tsallis(data=None, q=2):\n",
    "    if data is not None:\n",
    "        prob = symbols_to_prob(data).prob()\n",
    "\n",
    "    # compute the log2 of the probability and change any -inf by 0s\n",
    "    powerProb = prob ** int(q)\n",
    "    # return dot product of logProb and prob\n",
    "    return (1 / (q - 1)) * (1 - np.sum(powerProb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "tsallisEnt = np.apply_along_axis(tsallis, 1, arr=data_win_rnd3)\n",
    "df_feat[\"tsallisEnt\"] = tsallisEnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "renyiEnt = np.apply_along_axis(renyi, 1, arr=data_win_rnd3)\n",
    "df_feat[\"renyi\"] = renyiEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manis and Sassi, A Python Library with Fast Algorithms for Popular Entropy Definitions.\n",
    "\n",
    "from numpy import histogram, log\n",
    "\n",
    "\n",
    "def bubble_count(x):\n",
    "    \"\"\"\n",
    "    counts the number of swaps when sorting\n",
    "    :param x: the input vector\n",
    "    :return: the total number of swaps\n",
    "    \"\"\"\n",
    "    y = 0\n",
    "    for i in range(len(x) - 1, 0, -1):\n",
    "        for j in range(i):\n",
    "            if x[j] > x[j + 1]:\n",
    "                x[j], x[j + 1] = x[j + 1], x[j]\n",
    "                y += 1\n",
    "    return y\n",
    "\n",
    "\n",
    "def complexity_count_fast(x, m):\n",
    "    \"\"\"\n",
    "    :param x: the input series\n",
    "    :param m: the dimension of the space\n",
    "    :return: the series of complexities for total number of swaps\n",
    "    \"\"\"\n",
    "\n",
    "    if len(x) < m:\n",
    "        return []\n",
    "\n",
    "    y = [bubble_count(x[:m])]\n",
    "    v = sorted(x[:m])\n",
    "\n",
    "    for i in range(m, len(x)):\n",
    "        steps = y[i - m]\n",
    "        steps -= v.index(x[i - m])\n",
    "        v.pop(v.index(x[i - m]))\n",
    "        v.append(x[i])\n",
    "        j = m - 1\n",
    "        while j > 0 and v[j] < v[j - 1]:\n",
    "            v[j], v[j - 1] = v[j - 1], v[j]\n",
    "            steps += 1\n",
    "            j -= 1\n",
    "        y.append(steps)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def renyi_int(data):\n",
    "    \"\"\"\n",
    "    returns renyi entropy (order 2) of an integer series and bin_size=1\n",
    "    (specified for the needs of bubble entropy)\n",
    "    :param data: the input series\n",
    "    :return: metric\n",
    "    \"\"\"\n",
    "    counter = [0] * (max(data) + 1)\n",
    "    for x in data:\n",
    "        counter[x] += 1\n",
    "    r = 0\n",
    "    for c in counter:\n",
    "        p = c / len(data)\n",
    "        r += p * p\n",
    "    return -log(r)\n",
    "\n",
    "\n",
    "def bubble_entropy(x, m=10):\n",
    "    \"\"\"\n",
    "    computes bubble entropy following the definition\n",
    "    :param x: the input signal\n",
    "    :param m: the dimension of the embedding space\n",
    "    :return: metric\n",
    "    \"\"\"\n",
    "    complexity = complexity_count_fast(x, m)\n",
    "    B = renyi_int(complexity) / log(1 + m * (m - 1) / 2)\n",
    "\n",
    "    complexity = complexity_count_fast(x, m + 1)\n",
    "    A = renyi_int(complexity) / log(1 + (m + 1) * m / 2)\n",
    "\n",
    "    return A - B\n",
    "\n",
    "\n",
    "def bubble_entropy_2(x, m=10):\n",
    "    \"\"\"\n",
    "    computes bubble entropy following the definition\n",
    "    :param x: the input signal\n",
    "    :param m: the dimension of the embedding space\n",
    "    :return: metric\n",
    "    \"\"\"\n",
    "    complexity = complexity_count_fast(x, m)\n",
    "    B = renyi_int(complexity) / log(1 + m * (m - 1) / 2)\n",
    "\n",
    "    complexity = complexity_count_fast(x, m + 2)\n",
    "    A = renyi_int(complexity) / log(1 + (m + 2) * (m + 1) / 2)\n",
    "\n",
    "    return A - B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell took ~40 seconds from ~8 hours of sleep data\n",
    "\n",
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "bubbleEnt1 = np.apply_along_axis(bubble_entropy, 1, arr=data_win_rnd3)\n",
    "df_feat[\"bubbleEnt1\"] = bubbleEnt1\n",
    "\n",
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "bubbleEnt2 = np.apply_along_axis(bubble_entropy_2, 1, arr=data_win_rnd3)\n",
    "df_feat[\"bubbleEnt2\"] = bubbleEnt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirhosseindaraie/miniconda3/envs/mne/lib/python3.9/site-packages/scipy/stats/_entropy.py:293: RuntimeWarning: divide by zero encountered in log\n",
      "  logs = np.log(n/(2*m) * differences)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import differential_entropy\n",
    "\n",
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "diffEnt = np.apply_along_axis(differential_entropy, 1, arr=data_win_rnd3)\n",
    "diffEntMean = np.mean(diffEnt[~(diffEnt == -np.inf)])\n",
    "diffEnt[diffEnt == -np.inf] = diffEntMean\n",
    "df_feat[\"diffEnt\"] = diffEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    diffEnt - np.mean(diffEnt),\n",
    "    label=\"Differential Entropy\",\n",
    "    color=\"darkgreen\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.title(\"Differential Entropy (Normalized)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell took ~11 min to execute\n",
    "\n",
    "# pip install EntropyHub\n",
    "import EntropyHub as enth\n",
    "\n",
    "\n",
    "def fuzzEnt_f(x, m=1, tau=1):\n",
    "    \"\"\"\n",
    "    A wrapper function for EntropyHub.FuzzEn() Function\n",
    "\n",
    "    Input\n",
    "    ------\n",
    "    `sig`: Time series signal, a vector of length > 10.\n",
    "    `m`: Embedding dimension, a positive integer (for embbeding dim).\n",
    "    `tau`: Time delay, a positive integer (for embbeding dim).\n",
    "    `Fx`: Type of fuzzy function for distance transformation, one of the following strings\n",
    "    Return\n",
    "    ------\n",
    "    `Fuzz`: Fuzzy entropy estimates for each embedding dimension 1:m.\n",
    "    `Ps1`: The average fuzzy distances for embedding dimensions 1:m.\n",
    "    `Ps2`: The average fuzzy distances for embedding dimensions 2:m+1.\n",
    "    Example\n",
    "    -------\n",
    "    >>> [Fuzz, Ps1, Ps2] = enth.FuzzEn(x, m=1, tau=1)\n",
    "    Source\n",
    "    ------\n",
    "    https://github.com/MattWillFlood/EntropyHub/blob/main/Guide/EntropyHub%20Guide.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    [Fuzz, Ps1, Ps2] = enth.FuzzEn(x, m=m, tau=tau)\n",
    "    return Fuzz[0]\n",
    "\n",
    "\n",
    "# Calculate feature for all epochs. Then add them to FeaturesDataFrame\n",
    "data_win_rnd3 = np.around(data_win, decimals=3)\n",
    "fuzzEnt = np.apply_along_axis(fuzzEnt_f, 1, arr=data_win_rnd3)\n",
    "df_feat[\"fuzzEnt\"] = fuzzEnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write feature object to a comma-separated values (csv) file\n",
    "df_feat.to_csv(f\"feature/{fname} {lr}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
